{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) An expert can understand a set of one features as a concept, whereas for a black-box model a concept in unsupervised setting will be a set of absolutely different features (correlated ones and so on)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "import joblib\n",
    "import sklearn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os.path as osp\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from imblearn.under_sampling import RandomUnderSampler \n",
    "import tensorflow as tf\n",
    "\n",
    "from tabcbm.models.architectures import construct_encoder, construct_decoder\n",
    "from tabcbm.models.architectures import construct_end_to_end_model\n",
    "from tabcbm.models.tabcbm import TabCBM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the training set:  (120935, 40)\n",
      "Shape of the test set:  (51830, 40)\n",
      "Shape of the trainigb targets:  (120935,)\n"
     ]
    }
   ],
   "source": [
    "# Reading already preprocessed train and test data \n",
    "\n",
    "data_dir = 'D:\\\\PycharmProjects\\\\AMMISproject\\\\data\\\\processed_data'\n",
    "dataset = 'dataco'\n",
    "\n",
    "x_train_std = joblib.load(osp.join(data_dir, dataset, 'x_train_std.joblib'))\n",
    "x_test_std = joblib.load(osp.join(data_dir, dataset, 'x_test_std.joblib'))\n",
    "\n",
    "x_train = joblib.load(osp.join(data_dir, dataset, 'x_train.joblib'))\n",
    "x_test = joblib.load(osp.join(data_dir, dataset, 'x_test.joblib'))\n",
    "\n",
    "y_train = joblib.load(osp.join(data_dir, dataset, 'y_train.joblib'))\n",
    "y_test = joblib.load(osp.join(data_dir, dataset, 'y_test.joblib'))\n",
    "\n",
    "print('Shape of the training set: ', x_train_std.shape)\n",
    "print('Shape of the test set: ', x_test_std.shape)\n",
    "print('Shape of the trainigb targets: ', y_train.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(103416, 40)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rus = RandomUnderSampler(sampling_strategy='all', random_state=0)\n",
    "\n",
    "x_train_reduced, y_train_reduced = rus.fit_resample(x_train_std, y_train) \n",
    "x_train_reduced.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the concepts \n",
    "\n",
    "aggregated_concepts = {\n",
    "    'Shipment': ['Type', 'Days for shipment (scheduled)', 'Shipping Mode', 'Distance (km)'],\n",
    "    'Customer': ['Customer Zipcode', 'Customer Segment'],\n",
    "    'Department': ['Department Name', 'Market'],\n",
    "    'Store': ['Store Latitude', 'Store Longitude'],\n",
    "    'Order': ['Order Id', 'order date (DateOrders)', 'Order Longitude', 'Order Latitude',\n",
    "              'Benefit per order', 'Order Item Total', 'Order Status', 'Sales', \n",
    "              'Order Item Discount', 'order_year', 'order_month', 'order_day'],\n",
    "    'Product': ['Category Name']\n",
    "}\n",
    "\n",
    "# In the preprocessed data the naming of the columns differs, so we have to define\n",
    "# expanded features and put them as a value of a corresponding concept\n",
    "extended_concepts = {}\n",
    "for concept, features in aggregated_concepts.items():\n",
    "    extended_features = []\n",
    "    for value in features:\n",
    "            [extended_features.append(column) for column in x_train_std.columns if value in column]\n",
    "   \n",
    "    extended_concepts[concept] = extended_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating masks for each concept \n",
    "\n",
    "concepts_num = len(aggregated_concepts)\n",
    "all_features = x_train_std.columns\n",
    "\n",
    "total_features_num = len(all_features) \n",
    "\n",
    "concepts_masks = pd.DataFrame(0, columns=all_features, index=list(aggregated_concepts.keys()))\n",
    "\n",
    "for concept, features in extended_concepts.items():\n",
    "    for feature in features:\n",
    "        concepts_masks.loc[concept, feature] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create main components for TabCBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train_reduced\n",
    "y_train = y_train_reduced\n",
    "\n",
    "x_test = x_test_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape:  (40,)\n",
      "Number of outputs:  2\n"
     ]
    }
   ],
   "source": [
    "# Parameters defining the architecture we will use\n",
    "\n",
    "input_shape = x_train_std.shape[1:]\n",
    "num_outputs = len(set(y_train))\n",
    "encoder_units = [16, 16]\n",
    "decoder_units = [16]\n",
    "latent_dims = 16\n",
    "learning_rate = 0.001\n",
    "validation_size = 0.1\n",
    "\n",
    "print('Input shape: ', input_shape)\n",
    "print('Number of outputs: ', num_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabcbm_params = dict(\n",
    "    input_shape = x_train_std.shape[1:]\n",
    "    num_outputs = len(set(y_train))\n",
    "    encoder_units = [16, 16]\n",
    "    decoder_units = [16]\n",
    "    latent_dims = 16\n",
    "    learning_rate = 0.001\n",
    "    validation_size = 0.1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_end_to_end_tabsbm(**kwargs):\n",
    "    input_shape = kwargs['input_shape']\n",
    "\n",
    "    encoder = construct_encoder(input_shape, **kwargs)\n",
    "\n",
    "    decoder_inputs = tf.keras.Input(shape=[latent_dims])\n",
    "    decoder_graph = construct_decoder(**kwargs)\n",
    "    decoder = tf.keras.Model(\n",
    "        decoder_inputs,\n",
    "        decoder_graph(decoder_inputs),\n",
    "        name=\"decoder\",\n",
    "    )\n",
    "    \n",
    "    end_to_end_model, encoder, decoder = construct_end_to_end_model(input_shape,\n",
    "                                                                encoder,\n",
    "                                                                decoder,\n",
    "                                                                num_outputs,\n",
    "                                                                learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next, we build the feature to latent code encoder model (i.e., phi)\n",
    "encoder = construct_encoder(input_shape, encoder_units, latent_dims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then, we build the concept to label model  (i.e., the label predictor f)\n",
    "\n",
    "decoder_inputs = tf.keras.Input(shape=[latent_dims])\n",
    "decoder_graph = construct_decoder(decoder_units, num_outputs)\n",
    "decoder = tf.keras.Model(\n",
    "    decoder_inputs,\n",
    "    decoder_graph(decoder_inputs),\n",
    "    name=\"decoder\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"complete_model\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"complete_model\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_27 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">38</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ encoder (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,168</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ decoder (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">289</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_27 (\u001b[38;5;33mInputLayer\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m38\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ encoder (\u001b[38;5;33mFunctional\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │         \u001b[38;5;34m1,168\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ decoder (\u001b[38;5;33mFunctional\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │           \u001b[38;5;34m289\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,457</span> (5.69 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,457\u001b[0m (5.69 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,457</span> (5.69 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,457\u001b[0m (5.69 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - binary_accuracy: 0.5918 - loss: 0.6500 - val_binary_accuracy: 0.5024 - val_loss: 0.6650\n",
      "Epoch 2/30\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 953us/step - binary_accuracy: 0.7366 - loss: 0.5406 - val_binary_accuracy: 0.4760 - val_loss: 0.7055\n",
      "Epoch 3/30\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.7357 - loss: 0.5331 - val_binary_accuracy: 0.5165 - val_loss: 0.6475\n",
      "Epoch 4/30\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 961us/step - binary_accuracy: 0.7362 - loss: 0.5335 - val_binary_accuracy: 0.5002 - val_loss: 0.6736\n",
      "Epoch 5/30\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.7376 - loss: 0.5307 - val_binary_accuracy: 0.5123 - val_loss: 0.6643\n",
      "Epoch 6/30\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 858us/step - binary_accuracy: 0.7372 - loss: 0.5303 - val_binary_accuracy: 0.4914 - val_loss: 0.7058\n",
      "Epoch 7/30\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 981us/step - binary_accuracy: 0.7387 - loss: 0.5292 - val_binary_accuracy: 0.5251 - val_loss: 0.6387\n",
      "Epoch 8/30\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 850us/step - binary_accuracy: 0.7412 - loss: 0.5303 - val_binary_accuracy: 0.5165 - val_loss: 0.6671\n",
      "Epoch 9/30\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 953us/step - binary_accuracy: 0.7396 - loss: 0.5302 - val_binary_accuracy: 0.5192 - val_loss: 0.6532\n",
      "Epoch 10/30\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 931us/step - binary_accuracy: 0.7390 - loss: 0.5287 - val_binary_accuracy: 0.5160 - val_loss: 0.6715\n",
      "Epoch 11/30\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 990us/step - binary_accuracy: 0.7391 - loss: 0.5292 - val_binary_accuracy: 0.4874 - val_loss: 0.7030\n",
      "Epoch 12/30\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 986us/step - binary_accuracy: 0.7431 - loss: 0.5250 - val_binary_accuracy: 0.4991 - val_loss: 0.6816\n",
      "Epoch 13/30\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 987us/step - binary_accuracy: 0.7394 - loss: 0.5279 - val_binary_accuracy: 0.5114 - val_loss: 0.6972\n",
      "Epoch 14/30\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 907us/step - binary_accuracy: 0.7418 - loss: 0.5262 - val_binary_accuracy: 0.5016 - val_loss: 0.6730\n",
      "Epoch 15/30\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 984us/step - binary_accuracy: 0.7383 - loss: 0.5298 - val_binary_accuracy: 0.4948 - val_loss: 0.6963\n",
      "Epoch 16/30\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 901us/step - binary_accuracy: 0.7412 - loss: 0.5265 - val_binary_accuracy: 0.5022 - val_loss: 0.6927\n",
      "Epoch 17/30\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.7389 - loss: 0.5277 - val_binary_accuracy: 0.5191 - val_loss: 0.6795\n",
      "Epoch 18/30\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 931us/step - binary_accuracy: 0.7408 - loss: 0.5280 - val_binary_accuracy: 0.5162 - val_loss: 0.6756\n",
      "Epoch 19/30\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 883us/step - binary_accuracy: 0.7399 - loss: 0.5277 - val_binary_accuracy: 0.5164 - val_loss: 0.6642\n",
      "Epoch 20/30\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.7410 - loss: 0.5263 - val_binary_accuracy: 0.5198 - val_loss: 0.6672\n",
      "Epoch 21/30\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 888us/step - binary_accuracy: 0.7413 - loss: 0.5264 - val_binary_accuracy: 0.5196 - val_loss: 0.6628\n",
      "Epoch 22/30\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 957us/step - binary_accuracy: 0.7415 - loss: 0.5266 - val_binary_accuracy: 0.5022 - val_loss: 0.6928\n",
      "Epoch 23/30\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 974us/step - binary_accuracy: 0.7386 - loss: 0.5289 - val_binary_accuracy: 0.5015 - val_loss: 0.7097\n",
      "Epoch 24/30\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 982us/step - binary_accuracy: 0.7392 - loss: 0.5290 - val_binary_accuracy: 0.5103 - val_loss: 0.6770\n",
      "Epoch 25/30\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 921us/step - binary_accuracy: 0.7394 - loss: 0.5271 - val_binary_accuracy: 0.5192 - val_loss: 0.6896\n",
      "Epoch 26/30\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.7408 - loss: 0.5261 - val_binary_accuracy: 0.5162 - val_loss: 0.6780\n",
      "Epoch 27/30\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 986us/step - binary_accuracy: 0.7414 - loss: 0.5254 - val_binary_accuracy: 0.5187 - val_loss: 0.6575\n",
      "Epoch 28/30\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 913us/step - binary_accuracy: 0.7408 - loss: 0.5240 - val_binary_accuracy: 0.5266 - val_loss: 0.6139\n",
      "Epoch 29/30\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 920us/step - binary_accuracy: 0.7414 - loss: 0.5258 - val_binary_accuracy: 0.5203 - val_loss: 0.6660\n",
      "Epoch 30/30\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 950us/step - binary_accuracy: 0.7414 - loss: 0.5261 - val_binary_accuracy: 0.5134 - val_loss: 0.6682\n"
     ]
    }
   ],
   "source": [
    "# We then put them both together to make an end-to-end model we can pretrain\n",
    "\n",
    "end_to_end_model, encoder, decoder = construct_end_to_end_model(input_shape,\n",
    "                                                                encoder,\n",
    "                                                                decoder,\n",
    "                                                                num_outputs,\n",
    "                                                                learning_rate)\n",
    "\n",
    "end_to_end_model.summary()\n",
    "\n",
    "pretrain_epochs = 30\n",
    "batch_size = 512\n",
    "pretrain_hist = end_to_end_model.fit(\n",
    "    x=x_train,\n",
    "    y=y_train,\n",
    "    epochs=pretrain_epochs,\n",
    "    batch_size=batch_size,\n",
    "    validation_split=validation_size,\n",
    "    verbose=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 959us/step\n",
      "Pretrained model task accuracy: 69.96%\n"
     ]
    }
   ],
   "source": [
    "# Evaluate pretrained model\n",
    "\n",
    "# We will accumulate all metrics/results in the same dictionary\n",
    "results = {}\n",
    "\n",
    "end_to_end_preds = end_to_end_model.predict(\n",
    "    x_test,\n",
    "    batch_size=batch_size,\n",
    ")\n",
    "\n",
    "# We assume that we have outputed logits\n",
    "if np.min(end_to_end_preds) < 0.0 or np.max(end_to_end_preds) > 1:\n",
    "    end_to_end_preds = tf.math.sigmoid(end_to_end_preds).numpy()\n",
    "end_to_end_preds = (end_to_end_preds >= 0.5).astype(np.int32)\n",
    "results['pre_train_acc'] = sklearn.metrics.accuracy_score(\n",
    "    y_test,\n",
    "    end_to_end_preds,\n",
    ")\n",
    "results['pre_train_auc'] = sklearn.metrics.roc_auc_score(\n",
    "    y_test,\n",
    "    end_to_end_preds,\n",
    ")\n",
    "print(f\"Pretrained model task accuracy: {results['pre_train_acc']*100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construct TabCBM\n",
    "\n",
    "For this, we will first compute the empirical covariance matrix in order for us to learn useful masks using a similar approach to that proposed by SEFS:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.00000000e+00 -1.36071957e-03  7.91785450e-03 ... -3.70337549e-03\n",
      "   3.40013685e-03 -6.15914871e-04]\n",
      " [-1.36071957e-03  1.00000000e+00  3.39125553e-03 ...  3.68143779e-03\n",
      "  -1.50537796e-03 -7.14249036e-03]\n",
      " [ 7.91785450e-03  3.39125553e-03  1.00000000e+00 ...  6.07207893e-03\n",
      "   2.14358816e-03  1.68781787e-03]\n",
      " ...\n",
      " [-3.70337549e-03  3.68143779e-03  6.07207893e-03 ...  1.00000000e+00\n",
      "  -1.98689043e-01 -1.37803989e-01]\n",
      " [ 3.40013685e-03 -1.50537796e-03  2.14358816e-03 ... -1.98689043e-01\n",
      "   1.00000000e+00 -2.08158793e-01]\n",
      " [-6.15914871e-04 -7.14249036e-03  1.68781787e-03 ... -1.37803989e-01\n",
      "  -2.08158793e-01  1.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "# Construct the training set's empirical covariance matrix\n",
    "# NOTE: This step can be very computationally expensive/intractable in large\n",
    "#       datasets. In those cases, one may ignore the covariance matrix when\n",
    "#       performing TabCBM's pretraining at the potential cost of performance or\n",
    "#       more accurate concept discovery.\n",
    "cov_mat = np.corrcoef(x_train.T)\n",
    "print(cov_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of concepts we want to discover\n",
    "n_concepts = 6\n",
    "\n",
    "# Set the weights for the different regularisers in the loss\n",
    "coherence_reg_weight = 0.1  # $lambda_{co}\n",
    "diversity_reg_weight = 5  # $lambda_{div}\n",
    "feature_selection_reg_weight = 5  # $lambda_{spec}\n",
    "gate_estimator_weight = 10  # Gate prediction regularizer for SEFS's pre-text task\n",
    "\n",
    "# Select how many neighbors to use for the coherency loss (must be less than the batch size!)\n",
    "top_k = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a dictionary with the parameters to use for TabCBM as we will have\n",
    "# to use the same parameters twice:\n",
    "tab_cbm_params = dict(\n",
    "    features_to_concepts_model=encoder,  # The $\\phi$ sub-model\n",
    "    concepts_to_labels_model=decoder,  # The $f$ sub-model\n",
    "    latent_dims=latent_dims,  # The dimensionality of the concept embeddings $m$\n",
    "    n_concepts=n_concepts,  # The number of concepts to discover $k^\\prime$\n",
    "    cov_mat=cov_mat,  # The empirical covariance matrix\n",
    "    loss_fn=end_to_end_model.loss,  # The downstream task loss function\n",
    "    # Then we provide all the regularizers weights\n",
    "    coherence_reg_weight=coherence_reg_weight,\n",
    "    diversity_reg_weight=diversity_reg_weight,\n",
    "    feature_selection_reg_weight=feature_selection_reg_weight,\n",
    "    gate_estimator_weight=gate_estimator_weight,\n",
    "    top_k=top_k,\n",
    "\n",
    "    # And indicate that we will not be providing any supervised concepts! Change\n",
    "    # this is training concepts (e.g., `c_train`) are provided/known during\n",
    "    # training\n",
    "    n_supervised_concepts=0,\n",
    "    concept_prediction_weight=0,\n",
    "\n",
    "    # The accuracy metric to use for logging performance\n",
    "    acc_metric=(\n",
    "        lambda y_true, y_pred: tf.math.reduce_mean(\n",
    "            tf.keras.metrics.sparse_categorical_accuracy(\n",
    "                y_true,\n",
    "                y_pred,\n",
    "            )\n",
    "        )\n",
    "    ),\n",
    "\n",
    "    # ANd architectural details of the self-supervised reconstruction modules\n",
    "    concept_generator_units=[64],\n",
    "    rec_model_units=[64],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARNING] Assuming independence between features in TabCBM training.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PycharmProjects\\AMMISproject\\venv\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"tab_cbm_3\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"tab_cbm_3\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ decoder (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">289</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ encoder (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,168</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ sequential_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">11,516</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ concept_generators_0            │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)                    │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ rec_values_model_0 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>) │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ rec_mask_model (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)     │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ concept_generators_1            │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)                    │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ concept_generators_2            │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)                    │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ concept_generators_3            │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)                    │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ concept_generators_4            │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)                    │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ concept_generators_5            │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)                    │                        │               │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ decoder (\u001b[38;5;33mFunctional\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │           \u001b[38;5;34m289\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ encoder (\u001b[38;5;33mFunctional\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │         \u001b[38;5;34m1,168\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ sequential_7 (\u001b[38;5;33mSequential\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │        \u001b[38;5;34m11,516\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ concept_generators_0            │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "│ (\u001b[38;5;33mSequential\u001b[0m)                    │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ rec_values_model_0 (\u001b[38;5;33mSequential\u001b[0m) │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ rec_mask_model (\u001b[38;5;33mSequential\u001b[0m)     │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ concept_generators_1            │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "│ (\u001b[38;5;33mSequential\u001b[0m)                    │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ concept_generators_2            │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "│ (\u001b[38;5;33mSequential\u001b[0m)                    │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ concept_generators_3            │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "│ (\u001b[38;5;33mSequential\u001b[0m)                    │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ concept_generators_4            │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "│ (\u001b[38;5;33mSequential\u001b[0m)                    │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ concept_generators_5            │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "│ (\u001b[38;5;33mSequential\u001b[0m)                    │                        │               │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">13,429</span> (52.46 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m13,429\u001b[0m (52.46 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">13,201</span> (51.57 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m13,201\u001b[0m (51.57 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">228</span> (912.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m228\u001b[0m (912.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Mask Generator Self-supervised Training\n",
    "\n",
    "# Next, we proceed to do the SELF-SUPERVISED TRAINING of the MASK\n",
    "# GENERATORS for TabCBM. For this, we will follow a similar approach\n",
    "# to that of SEFS. Our TabCBM module allows one to do this by setting\n",
    "# the self_supervised_mode flag to True before calling the .fit() method:\n",
    "\n",
    "# We can now construct our TabCBM model which we will first self-supervise!\n",
    "ss_tabcbm = TabCBM(self_supervised_mode=True,  **tab_cbm_params)\n",
    "ss_tabcbm.compile(optimizer=tf.keras.optimizers.Adam(learning_rate,))\n",
    "ss_tabcbm.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TabCBM self-supervised training stage...\n",
      "Epoch 1/50\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - avg_concept_size: 0.0000e+00 - avg_features_rec_loss: 0.5985 - avg_mask_rec_loss: 5.4125 - loss: 36.0662 - max_probability: 0.0000e+00 - mean_probability: 0.0000e+00 - min_probability: 0.0000e+00 - prob_sparsity_loss: 0.0000e+00 - reg_loss_closest: 0.0000e+00 - reg_loss_similarity: 0.0000e+00 - task_loss: 0.0000e+00 - val_avg_features_rec_loss: 0.5984 - val_avg_mask_rec_loss: 5.2966 - val_loss: 35.3697\n",
      "Epoch 2/50\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - avg_concept_size: 0.0000e+00 - avg_features_rec_loss: 0.5983 - avg_mask_rec_loss: 5.3972 - loss: 35.9729 - max_probability: 0.0000e+00 - mean_probability: 0.0000e+00 - min_probability: 0.0000e+00 - prob_sparsity_loss: 0.0000e+00 - reg_loss_closest: 0.0000e+00 - reg_loss_similarity: 0.0000e+00 - task_loss: 0.0000e+00 - val_avg_features_rec_loss: 0.5981 - val_avg_mask_rec_loss: 5.2727 - val_loss: 35.2248\n",
      "Epoch 3/50\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - avg_concept_size: 0.0000e+00 - avg_features_rec_loss: 0.5980 - avg_mask_rec_loss: 5.3847 - loss: 35.8964 - max_probability: 0.0000e+00 - mean_probability: 0.0000e+00 - min_probability: 0.0000e+00 - prob_sparsity_loss: 0.0000e+00 - reg_loss_closest: 0.0000e+00 - reg_loss_similarity: 0.0000e+00 - task_loss: 0.0000e+00 - val_avg_features_rec_loss: 0.5979 - val_avg_mask_rec_loss: 5.2728 - val_loss: 35.2242\n",
      "Epoch 4/50\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - avg_concept_size: 0.0000e+00 - avg_features_rec_loss: 0.5978 - avg_mask_rec_loss: 5.3748 - loss: 35.8359 - max_probability: 0.0000e+00 - mean_probability: 0.0000e+00 - min_probability: 0.0000e+00 - prob_sparsity_loss: 0.0000e+00 - reg_loss_closest: 0.0000e+00 - reg_loss_similarity: 0.0000e+00 - task_loss: 0.0000e+00 - val_avg_features_rec_loss: 0.5977 - val_avg_mask_rec_loss: 5.2831 - val_loss: 35.2848\n",
      "Epoch 5/50\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - avg_concept_size: 0.0000e+00 - avg_features_rec_loss: 0.5976 - avg_mask_rec_loss: 5.3603 - loss: 35.7473 - max_probability: 0.0000e+00 - mean_probability: 0.0000e+00 - min_probability: 0.0000e+00 - prob_sparsity_loss: 0.0000e+00 - reg_loss_closest: 0.0000e+00 - reg_loss_similarity: 0.0000e+00 - task_loss: 0.0000e+00 - val_avg_features_rec_loss: 0.5975 - val_avg_mask_rec_loss: 5.2662 - val_loss: 35.1823\n",
      "Epoch 6/50\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - avg_concept_size: 0.0000e+00 - avg_features_rec_loss: 0.5975 - avg_mask_rec_loss: 5.3475 - loss: 35.6699 - max_probability: 0.0000e+00 - mean_probability: 0.0000e+00 - min_probability: 0.0000e+00 - prob_sparsity_loss: 0.0000e+00 - reg_loss_closest: 0.0000e+00 - reg_loss_similarity: 0.0000e+00 - task_loss: 0.0000e+00 - val_avg_features_rec_loss: 0.5973 - val_avg_mask_rec_loss: 5.2501 - val_loss: 35.0847\n",
      "Epoch 7/50\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - avg_concept_size: 0.0000e+00 - avg_features_rec_loss: 0.5973 - avg_mask_rec_loss: 5.3344 - loss: 35.5904 - max_probability: 0.0000e+00 - mean_probability: 0.0000e+00 - min_probability: 0.0000e+00 - prob_sparsity_loss: 0.0000e+00 - reg_loss_closest: 0.0000e+00 - reg_loss_similarity: 0.0000e+00 - task_loss: 0.0000e+00 - val_avg_features_rec_loss: 0.5972 - val_avg_mask_rec_loss: 5.2268 - val_loss: 34.9439\n",
      "Epoch 8/50\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - avg_concept_size: 0.0000e+00 - avg_features_rec_loss: 0.5972 - avg_mask_rec_loss: 5.3225 - loss: 35.5182 - max_probability: 0.0000e+00 - mean_probability: 0.0000e+00 - min_probability: 0.0000e+00 - prob_sparsity_loss: 0.0000e+00 - reg_loss_closest: 0.0000e+00 - reg_loss_similarity: 0.0000e+00 - task_loss: 0.0000e+00 - val_avg_features_rec_loss: 0.5971 - val_avg_mask_rec_loss: 5.2060 - val_loss: 34.8187\n",
      "Epoch 9/50\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - avg_concept_size: 0.0000e+00 - avg_features_rec_loss: 0.5971 - avg_mask_rec_loss: 5.3154 - loss: 35.4746 - max_probability: 0.0000e+00 - mean_probability: 0.0000e+00 - min_probability: 0.0000e+00 - prob_sparsity_loss: 0.0000e+00 - reg_loss_closest: 0.0000e+00 - reg_loss_similarity: 0.0000e+00 - task_loss: 0.0000e+00 - val_avg_features_rec_loss: 0.5970 - val_avg_mask_rec_loss: 5.2224 - val_loss: 34.9162\n",
      "Epoch 10/50\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - avg_concept_size: 0.0000e+00 - avg_features_rec_loss: 0.5970 - avg_mask_rec_loss: 5.3007 - loss: 35.3864 - max_probability: 0.0000e+00 - mean_probability: 0.0000e+00 - min_probability: 0.0000e+00 - prob_sparsity_loss: 0.0000e+00 - reg_loss_closest: 0.0000e+00 - reg_loss_similarity: 0.0000e+00 - task_loss: 0.0000e+00 - val_avg_features_rec_loss: 0.5970 - val_avg_mask_rec_loss: 5.1805 - val_loss: 34.6648\n",
      "Epoch 11/50\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - avg_concept_size: 0.0000e+00 - avg_features_rec_loss: 0.5970 - avg_mask_rec_loss: 5.2820 - loss: 35.2739 - max_probability: 0.0000e+00 - mean_probability: 0.0000e+00 - min_probability: 0.0000e+00 - prob_sparsity_loss: 0.0000e+00 - reg_loss_closest: 0.0000e+00 - reg_loss_similarity: 0.0000e+00 - task_loss: 0.0000e+00 - val_avg_features_rec_loss: 0.5970 - val_avg_mask_rec_loss: 5.1672 - val_loss: 34.5849\n",
      "Epoch 12/50\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - avg_concept_size: 0.0000e+00 - avg_features_rec_loss: 0.5970 - avg_mask_rec_loss: 5.2777 - loss: 35.2482 - max_probability: 0.0000e+00 - mean_probability: 0.0000e+00 - min_probability: 0.0000e+00 - prob_sparsity_loss: 0.0000e+00 - reg_loss_closest: 0.0000e+00 - reg_loss_similarity: 0.0000e+00 - task_loss: 0.0000e+00 - val_avg_features_rec_loss: 0.5970 - val_avg_mask_rec_loss: 5.1470 - val_loss: 34.4641\n",
      "Epoch 13/50\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - avg_concept_size: 0.0000e+00 - avg_features_rec_loss: 0.5970 - avg_mask_rec_loss: 5.2693 - loss: 35.1979 - max_probability: 0.0000e+00 - mean_probability: 0.0000e+00 - min_probability: 0.0000e+00 - prob_sparsity_loss: 0.0000e+00 - reg_loss_closest: 0.0000e+00 - reg_loss_similarity: 0.0000e+00 - task_loss: 0.0000e+00 - val_avg_features_rec_loss: 0.5970 - val_avg_mask_rec_loss: 5.1764 - val_loss: 34.6409\n",
      "Epoch 14/50\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - avg_concept_size: 0.0000e+00 - avg_features_rec_loss: 0.5971 - avg_mask_rec_loss: 5.2630 - loss: 35.1605 - max_probability: 0.0000e+00 - mean_probability: 0.0000e+00 - min_probability: 0.0000e+00 - prob_sparsity_loss: 0.0000e+00 - reg_loss_closest: 0.0000e+00 - reg_loss_similarity: 0.0000e+00 - task_loss: 0.0000e+00 - val_avg_features_rec_loss: 0.5971 - val_avg_mask_rec_loss: 5.1785 - val_loss: 34.6535\n",
      "Epoch 15/50\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - avg_concept_size: 0.0000e+00 - avg_features_rec_loss: 0.5971 - avg_mask_rec_loss: 5.2615 - loss: 35.1520 - max_probability: 0.0000e+00 - mean_probability: 0.0000e+00 - min_probability: 0.0000e+00 - prob_sparsity_loss: 0.0000e+00 - reg_loss_closest: 0.0000e+00 - reg_loss_similarity: 0.0000e+00 - task_loss: 0.0000e+00 - val_avg_features_rec_loss: 0.5972 - val_avg_mask_rec_loss: 5.1547 - val_loss: 34.5110\n",
      "Epoch 16/50\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - avg_concept_size: 0.0000e+00 - avg_features_rec_loss: 0.5972 - avg_mask_rec_loss: 5.2559 - loss: 35.1184 - max_probability: 0.0000e+00 - mean_probability: 0.0000e+00 - min_probability: 0.0000e+00 - prob_sparsity_loss: 0.0000e+00 - reg_loss_closest: 0.0000e+00 - reg_loss_similarity: 0.0000e+00 - task_loss: 0.0000e+00 - val_avg_features_rec_loss: 0.5972 - val_avg_mask_rec_loss: 5.1839 - val_loss: 34.6868\n",
      "Epoch 17/50\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - avg_concept_size: 0.0000e+00 - avg_features_rec_loss: 0.5972 - avg_mask_rec_loss: 5.2510 - loss: 35.0896 - max_probability: 0.0000e+00 - mean_probability: 0.0000e+00 - min_probability: 0.0000e+00 - prob_sparsity_loss: 0.0000e+00 - reg_loss_closest: 0.0000e+00 - reg_loss_similarity: 0.0000e+00 - task_loss: 0.0000e+00 - val_avg_features_rec_loss: 0.5973 - val_avg_mask_rec_loss: 5.1574 - val_loss: 34.5286\n",
      "Epoch 18/50\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - avg_concept_size: 0.0000e+00 - avg_features_rec_loss: 0.5973 - avg_mask_rec_loss: 5.2494 - loss: 35.0803 - max_probability: 0.0000e+00 - mean_probability: 0.0000e+00 - min_probability: 0.0000e+00 - prob_sparsity_loss: 0.0000e+00 - reg_loss_closest: 0.0000e+00 - reg_loss_similarity: 0.0000e+00 - task_loss: 0.0000e+00 - val_avg_features_rec_loss: 0.5974 - val_avg_mask_rec_loss: 5.1448 - val_loss: 34.4534\n",
      "Epoch 19/50\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - avg_concept_size: 0.0000e+00 - avg_features_rec_loss: 0.5974 - avg_mask_rec_loss: 5.2489 - loss: 35.0777 - max_probability: 0.0000e+00 - mean_probability: 0.0000e+00 - min_probability: 0.0000e+00 - prob_sparsity_loss: 0.0000e+00 - reg_loss_closest: 0.0000e+00 - reg_loss_similarity: 0.0000e+00 - task_loss: 0.0000e+00 - val_avg_features_rec_loss: 0.5975 - val_avg_mask_rec_loss: 5.1385 - val_loss: 34.4156\n",
      "Epoch 20/50\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - avg_concept_size: 0.0000e+00 - avg_features_rec_loss: 0.5975 - avg_mask_rec_loss: 5.2463 - loss: 35.0628 - max_probability: 0.0000e+00 - mean_probability: 0.0000e+00 - min_probability: 0.0000e+00 - prob_sparsity_loss: 0.0000e+00 - reg_loss_closest: 0.0000e+00 - reg_loss_similarity: 0.0000e+00 - task_loss: 0.0000e+00 - val_avg_features_rec_loss: 0.5975 - val_avg_mask_rec_loss: 5.1091 - val_loss: 34.2400\n",
      "Epoch 21/50\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - avg_concept_size: 0.0000e+00 - avg_features_rec_loss: 0.5976 - avg_mask_rec_loss: 5.2422 - loss: 35.0387 - max_probability: 0.0000e+00 - mean_probability: 0.0000e+00 - min_probability: 0.0000e+00 - prob_sparsity_loss: 0.0000e+00 - reg_loss_closest: 0.0000e+00 - reg_loss_similarity: 0.0000e+00 - task_loss: 0.0000e+00 - val_avg_features_rec_loss: 0.5976 - val_avg_mask_rec_loss: 5.1256 - val_loss: 34.3393\n",
      "Epoch 22/50\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - avg_concept_size: 0.0000e+00 - avg_features_rec_loss: 0.5976 - avg_mask_rec_loss: 5.2395 - loss: 35.0224 - max_probability: 0.0000e+00 - mean_probability: 0.0000e+00 - min_probability: 0.0000e+00 - prob_sparsity_loss: 0.0000e+00 - reg_loss_closest: 0.0000e+00 - reg_loss_similarity: 0.0000e+00 - task_loss: 0.0000e+00 - val_avg_features_rec_loss: 0.5977 - val_avg_mask_rec_loss: 5.1084 - val_loss: 34.2366\n",
      "Epoch 23/50\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - avg_concept_size: 0.0000e+00 - avg_features_rec_loss: 0.5977 - avg_mask_rec_loss: 5.2388 - loss: 35.0188 - max_probability: 0.0000e+00 - mean_probability: 0.0000e+00 - min_probability: 0.0000e+00 - prob_sparsity_loss: 0.0000e+00 - reg_loss_closest: 0.0000e+00 - reg_loss_similarity: 0.0000e+00 - task_loss: 0.0000e+00 - val_avg_features_rec_loss: 0.5978 - val_avg_mask_rec_loss: 5.1408 - val_loss: 34.4315\n",
      "Epoch 24/50\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - avg_concept_size: 0.0000e+00 - avg_features_rec_loss: 0.5978 - avg_mask_rec_loss: 5.2339 - loss: 34.9902 - max_probability: 0.0000e+00 - mean_probability: 0.0000e+00 - min_probability: 0.0000e+00 - prob_sparsity_loss: 0.0000e+00 - reg_loss_closest: 0.0000e+00 - reg_loss_similarity: 0.0000e+00 - task_loss: 0.0000e+00 - val_avg_features_rec_loss: 0.5978 - val_avg_mask_rec_loss: 5.1219 - val_loss: 34.3180\n",
      "Epoch 25/50\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - avg_concept_size: 0.0000e+00 - avg_features_rec_loss: 0.5978 - avg_mask_rec_loss: 5.2361 - loss: 35.0032 - max_probability: 0.0000e+00 - mean_probability: 0.0000e+00 - min_probability: 0.0000e+00 - prob_sparsity_loss: 0.0000e+00 - reg_loss_closest: 0.0000e+00 - reg_loss_similarity: 0.0000e+00 - task_loss: 0.0000e+00 - val_avg_features_rec_loss: 0.5979 - val_avg_mask_rec_loss: 5.1301 - val_loss: 34.3680\n",
      "Epoch 26/50\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - avg_concept_size: 0.0000e+00 - avg_features_rec_loss: 0.5979 - avg_mask_rec_loss: 5.2330 - loss: 34.9854 - max_probability: 0.0000e+00 - mean_probability: 0.0000e+00 - min_probability: 0.0000e+00 - prob_sparsity_loss: 0.0000e+00 - reg_loss_closest: 0.0000e+00 - reg_loss_similarity: 0.0000e+00 - task_loss: 0.0000e+00 - val_avg_features_rec_loss: 0.5979 - val_avg_mask_rec_loss: 5.1277 - val_loss: 34.3536\n",
      "Epoch 27/50\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - avg_concept_size: 0.0000e+00 - avg_features_rec_loss: 0.5979 - avg_mask_rec_loss: 5.2239 - loss: 34.9310 - max_probability: 0.0000e+00 - mean_probability: 0.0000e+00 - min_probability: 0.0000e+00 - prob_sparsity_loss: 0.0000e+00 - reg_loss_closest: 0.0000e+00 - reg_loss_similarity: 0.0000e+00 - task_loss: 0.0000e+00 - val_avg_features_rec_loss: 0.5980 - val_avg_mask_rec_loss: 5.1524 - val_loss: 34.5022\n",
      "Epoch 28/50\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - avg_concept_size: 0.0000e+00 - avg_features_rec_loss: 0.5980 - avg_mask_rec_loss: 5.2279 - loss: 34.9549 - max_probability: 0.0000e+00 - mean_probability: 0.0000e+00 - min_probability: 0.0000e+00 - prob_sparsity_loss: 0.0000e+00 - reg_loss_closest: 0.0000e+00 - reg_loss_similarity: 0.0000e+00 - task_loss: 0.0000e+00 - val_avg_features_rec_loss: 0.5980 - val_avg_mask_rec_loss: 5.1058 - val_loss: 34.2228\n",
      "Epoch 29/50\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - avg_concept_size: 0.0000e+00 - avg_features_rec_loss: 0.5980 - avg_mask_rec_loss: 5.2227 - loss: 34.9242 - max_probability: 0.0000e+00 - mean_probability: 0.0000e+00 - min_probability: 0.0000e+00 - prob_sparsity_loss: 0.0000e+00 - reg_loss_closest: 0.0000e+00 - reg_loss_similarity: 0.0000e+00 - task_loss: 0.0000e+00 - val_avg_features_rec_loss: 0.5980 - val_avg_mask_rec_loss: 5.1305 - val_loss: 34.3715\n",
      "Epoch 30/50\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - avg_concept_size: 0.0000e+00 - avg_features_rec_loss: 0.5980 - avg_mask_rec_loss: 5.2238 - loss: 34.9308 - max_probability: 0.0000e+00 - mean_probability: 0.0000e+00 - min_probability: 0.0000e+00 - prob_sparsity_loss: 0.0000e+00 - reg_loss_closest: 0.0000e+00 - reg_loss_similarity: 0.0000e+00 - task_loss: 0.0000e+00 - val_avg_features_rec_loss: 0.5981 - val_avg_mask_rec_loss: 5.1284 - val_loss: 34.3590\n",
      "Epoch 31/50\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - avg_concept_size: 0.0000e+00 - avg_features_rec_loss: 0.5981 - avg_mask_rec_loss: 5.2205 - loss: 34.9113 - max_probability: 0.0000e+00 - mean_probability: 0.0000e+00 - min_probability: 0.0000e+00 - prob_sparsity_loss: 0.0000e+00 - reg_loss_closest: 0.0000e+00 - reg_loss_similarity: 0.0000e+00 - task_loss: 0.0000e+00 - val_avg_features_rec_loss: 0.5981 - val_avg_mask_rec_loss: 5.1196 - val_loss: 34.3060\n",
      "Epoch 32/50\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - avg_concept_size: 0.0000e+00 - avg_features_rec_loss: 0.5981 - avg_mask_rec_loss: 5.2193 - loss: 34.9040 - max_probability: 0.0000e+00 - mean_probability: 0.0000e+00 - min_probability: 0.0000e+00 - prob_sparsity_loss: 0.0000e+00 - reg_loss_closest: 0.0000e+00 - reg_loss_similarity: 0.0000e+00 - task_loss: 0.0000e+00 - val_avg_features_rec_loss: 0.5981 - val_avg_mask_rec_loss: 5.1248 - val_loss: 34.3377\n",
      "Epoch 33/50\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - avg_concept_size: 0.0000e+00 - avg_features_rec_loss: 0.5981 - avg_mask_rec_loss: 5.2176 - loss: 34.8944 - max_probability: 0.0000e+00 - mean_probability: 0.0000e+00 - min_probability: 0.0000e+00 - prob_sparsity_loss: 0.0000e+00 - reg_loss_closest: 0.0000e+00 - reg_loss_similarity: 0.0000e+00 - task_loss: 0.0000e+00 - val_avg_features_rec_loss: 0.5981 - val_avg_mask_rec_loss: 5.1236 - val_loss: 34.3302\n",
      "Epoch 34/50\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - avg_concept_size: 0.0000e+00 - avg_features_rec_loss: 0.5981 - avg_mask_rec_loss: 5.2197 - loss: 34.9069 - max_probability: 0.0000e+00 - mean_probability: 0.0000e+00 - min_probability: 0.0000e+00 - prob_sparsity_loss: 0.0000e+00 - reg_loss_closest: 0.0000e+00 - reg_loss_similarity: 0.0000e+00 - task_loss: 0.0000e+00 - val_avg_features_rec_loss: 0.5981 - val_avg_mask_rec_loss: 5.1032 - val_loss: 34.2077\n",
      "Epoch 35/50\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - avg_concept_size: 0.0000e+00 - avg_features_rec_loss: 0.5981 - avg_mask_rec_loss: 5.2087 - loss: 34.8409 - max_probability: 0.0000e+00 - mean_probability: 0.0000e+00 - min_probability: 0.0000e+00 - prob_sparsity_loss: 0.0000e+00 - reg_loss_closest: 0.0000e+00 - reg_loss_similarity: 0.0000e+00 - task_loss: 0.0000e+00 - val_avg_features_rec_loss: 0.5981 - val_avg_mask_rec_loss: 5.1057 - val_loss: 34.2229\n",
      "Epoch 36/50\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - avg_concept_size: 0.0000e+00 - avg_features_rec_loss: 0.5981 - avg_mask_rec_loss: 5.2131 - loss: 34.8674 - max_probability: 0.0000e+00 - mean_probability: 0.0000e+00 - min_probability: 0.0000e+00 - prob_sparsity_loss: 0.0000e+00 - reg_loss_closest: 0.0000e+00 - reg_loss_similarity: 0.0000e+00 - task_loss: 0.0000e+00 - val_avg_features_rec_loss: 0.5981 - val_avg_mask_rec_loss: 5.1651 - val_loss: 34.5789\n",
      "Epoch 37/50\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - avg_concept_size: 0.0000e+00 - avg_features_rec_loss: 0.5981 - avg_mask_rec_loss: 5.2166 - loss: 34.8881 - max_probability: 0.0000e+00 - mean_probability: 0.0000e+00 - min_probability: 0.0000e+00 - prob_sparsity_loss: 0.0000e+00 - reg_loss_closest: 0.0000e+00 - reg_loss_similarity: 0.0000e+00 - task_loss: 0.0000e+00 - val_avg_features_rec_loss: 0.5981 - val_avg_mask_rec_loss: 5.1040 - val_loss: 34.2127\n",
      "Epoch 38/50\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - avg_concept_size: 0.0000e+00 - avg_features_rec_loss: 0.5981 - avg_mask_rec_loss: 5.2084 - loss: 34.8387 - max_probability: 0.0000e+00 - mean_probability: 0.0000e+00 - min_probability: 0.0000e+00 - prob_sparsity_loss: 0.0000e+00 - reg_loss_closest: 0.0000e+00 - reg_loss_similarity: 0.0000e+00 - task_loss: 0.0000e+00 - val_avg_features_rec_loss: 0.5981 - val_avg_mask_rec_loss: 5.0677 - val_loss: 33.9949\n",
      "Epoch 39/50\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - avg_concept_size: 0.0000e+00 - avg_features_rec_loss: 0.5981 - avg_mask_rec_loss: 5.2109 - loss: 34.8539 - max_probability: 0.0000e+00 - mean_probability: 0.0000e+00 - min_probability: 0.0000e+00 - prob_sparsity_loss: 0.0000e+00 - reg_loss_closest: 0.0000e+00 - reg_loss_similarity: 0.0000e+00 - task_loss: 0.0000e+00 - val_avg_features_rec_loss: 0.5981 - val_avg_mask_rec_loss: 5.0791 - val_loss: 34.0631\n",
      "Epoch 40/50\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - avg_concept_size: 0.0000e+00 - avg_features_rec_loss: 0.5981 - avg_mask_rec_loss: 5.2172 - loss: 34.8916 - max_probability: 0.0000e+00 - mean_probability: 0.0000e+00 - min_probability: 0.0000e+00 - prob_sparsity_loss: 0.0000e+00 - reg_loss_closest: 0.0000e+00 - reg_loss_similarity: 0.0000e+00 - task_loss: 0.0000e+00 - val_avg_features_rec_loss: 0.5981 - val_avg_mask_rec_loss: 5.1141 - val_loss: 34.2729\n",
      "Epoch 41/50\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - avg_concept_size: 0.0000e+00 - avg_features_rec_loss: 0.5980 - avg_mask_rec_loss: 5.2055 - loss: 34.8210 - max_probability: 0.0000e+00 - mean_probability: 0.0000e+00 - min_probability: 0.0000e+00 - prob_sparsity_loss: 0.0000e+00 - reg_loss_closest: 0.0000e+00 - reg_loss_similarity: 0.0000e+00 - task_loss: 0.0000e+00 - val_avg_features_rec_loss: 0.5980 - val_avg_mask_rec_loss: 5.1064 - val_loss: 34.2264\n",
      "Epoch 42/50\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - avg_concept_size: 0.0000e+00 - avg_features_rec_loss: 0.5980 - avg_mask_rec_loss: 5.2010 - loss: 34.7942 - max_probability: 0.0000e+00 - mean_probability: 0.0000e+00 - min_probability: 0.0000e+00 - prob_sparsity_loss: 0.0000e+00 - reg_loss_closest: 0.0000e+00 - reg_loss_similarity: 0.0000e+00 - task_loss: 0.0000e+00 - val_avg_features_rec_loss: 0.5980 - val_avg_mask_rec_loss: 5.0921 - val_loss: 34.1408\n",
      "Epoch 43/50\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - avg_concept_size: 0.0000e+00 - avg_features_rec_loss: 0.5980 - avg_mask_rec_loss: 5.2036 - loss: 34.8094 - max_probability: 0.0000e+00 - mean_probability: 0.0000e+00 - min_probability: 0.0000e+00 - prob_sparsity_loss: 0.0000e+00 - reg_loss_closest: 0.0000e+00 - reg_loss_similarity: 0.0000e+00 - task_loss: 0.0000e+00 - val_avg_features_rec_loss: 0.5980 - val_avg_mask_rec_loss: 5.0745 - val_loss: 34.0348\n",
      "Epoch 44/50\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - avg_concept_size: 0.0000e+00 - avg_features_rec_loss: 0.5980 - avg_mask_rec_loss: 5.2006 - loss: 34.7914 - max_probability: 0.0000e+00 - mean_probability: 0.0000e+00 - min_probability: 0.0000e+00 - prob_sparsity_loss: 0.0000e+00 - reg_loss_closest: 0.0000e+00 - reg_loss_similarity: 0.0000e+00 - task_loss: 0.0000e+00 - val_avg_features_rec_loss: 0.5980 - val_avg_mask_rec_loss: 5.0860 - val_loss: 34.1036\n",
      "Epoch 45/50\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - avg_concept_size: 0.0000e+00 - avg_features_rec_loss: 0.5979 - avg_mask_rec_loss: 5.2016 - loss: 34.7969 - max_probability: 0.0000e+00 - mean_probability: 0.0000e+00 - min_probability: 0.0000e+00 - prob_sparsity_loss: 0.0000e+00 - reg_loss_closest: 0.0000e+00 - reg_loss_similarity: 0.0000e+00 - task_loss: 0.0000e+00 - val_avg_features_rec_loss: 0.5979 - val_avg_mask_rec_loss: 5.0870 - val_loss: 34.1093\n",
      "Epoch 46/50\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - avg_concept_size: 0.0000e+00 - avg_features_rec_loss: 0.5979 - avg_mask_rec_loss: 5.1998 - loss: 34.7864 - max_probability: 0.0000e+00 - mean_probability: 0.0000e+00 - min_probability: 0.0000e+00 - prob_sparsity_loss: 0.0000e+00 - reg_loss_closest: 0.0000e+00 - reg_loss_similarity: 0.0000e+00 - task_loss: 0.0000e+00 - val_avg_features_rec_loss: 0.5979 - val_avg_mask_rec_loss: 5.1006 - val_loss: 34.1909\n",
      "Epoch 47/50\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - avg_concept_size: 0.0000e+00 - avg_features_rec_loss: 0.5978 - avg_mask_rec_loss: 5.1969 - loss: 34.7682 - max_probability: 0.0000e+00 - mean_probability: 0.0000e+00 - min_probability: 0.0000e+00 - prob_sparsity_loss: 0.0000e+00 - reg_loss_closest: 0.0000e+00 - reg_loss_similarity: 0.0000e+00 - task_loss: 0.0000e+00 - val_avg_features_rec_loss: 0.5978 - val_avg_mask_rec_loss: 5.1255 - val_loss: 34.3401\n",
      "Epoch 48/50\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - avg_concept_size: 0.0000e+00 - avg_features_rec_loss: 0.5978 - avg_mask_rec_loss: 5.1951 - loss: 34.7574 - max_probability: 0.0000e+00 - mean_probability: 0.0000e+00 - min_probability: 0.0000e+00 - prob_sparsity_loss: 0.0000e+00 - reg_loss_closest: 0.0000e+00 - reg_loss_similarity: 0.0000e+00 - task_loss: 0.0000e+00 - val_avg_features_rec_loss: 0.5977 - val_avg_mask_rec_loss: 5.0558 - val_loss: 33.9214\n",
      "Epoch 49/50\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - avg_concept_size: 0.0000e+00 - avg_features_rec_loss: 0.5977 - avg_mask_rec_loss: 5.1984 - loss: 34.7766 - max_probability: 0.0000e+00 - mean_probability: 0.0000e+00 - min_probability: 0.0000e+00 - prob_sparsity_loss: 0.0000e+00 - reg_loss_closest: 0.0000e+00 - reg_loss_similarity: 0.0000e+00 - task_loss: 0.0000e+00 - val_avg_features_rec_loss: 0.5977 - val_avg_mask_rec_loss: 5.0911 - val_loss: 34.1326\n",
      "Epoch 50/50\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.0000e+00 - avg_concept_size: 0.0000e+00 - avg_features_rec_loss: 0.5977 - avg_mask_rec_loss: 5.1948 - loss: 34.7545 - max_probability: 0.0000e+00 - mean_probability: 0.0000e+00 - min_probability: 0.0000e+00 - prob_sparsity_loss: 0.0000e+00 - reg_loss_closest: 0.0000e+00 - reg_loss_similarity: 0.0000e+00 - task_loss: 0.0000e+00 - val_avg_features_rec_loss: 0.5976 - val_avg_mask_rec_loss: 5.1127 - val_loss: 34.2621\n",
      "\tTabCBM self-supervised training completed\n"
     ]
    }
   ],
   "source": [
    "self_supervised_train_epochs = 50\n",
    "print(\"TabCBM self-supervised training stage...\")\n",
    "ss_tabcbm_hist = ss_tabcbm.fit(\n",
    "    x=x_train,\n",
    "    y=y_train,\n",
    "    validation_split=validation_size,\n",
    "    epochs=self_supervised_train_epochs,\n",
    "    batch_size=batch_size,\n",
    "    verbose=1,\n",
    ")\n",
    "\n",
    "print(\"\\tTabCBM self-supervised training completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARNING] Assuming independence between features in TabCBM training.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PycharmProjects\\AMMISproject\\venv\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"tab_cbm_5\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"tab_cbm_5\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ decoder (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">289</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ encoder (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,168</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ sequential_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">11,516</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ concept_generators_0            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">3,536</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)                    │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ concept_generators_1            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">3,536</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)                    │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ concept_generators_2            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">3,536</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)                    │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ concept_generators_3            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">3,536</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)                    │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ concept_generators_4            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">3,536</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)                    │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ concept_generators_5            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">3,536</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)                    │                        │               │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ decoder (\u001b[38;5;33mFunctional\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │           \u001b[38;5;34m289\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ encoder (\u001b[38;5;33mFunctional\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │         \u001b[38;5;34m1,168\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ sequential_9 (\u001b[38;5;33mSequential\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │        \u001b[38;5;34m11,516\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ concept_generators_0            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │         \u001b[38;5;34m3,536\u001b[0m │\n",
       "│ (\u001b[38;5;33mSequential\u001b[0m)                    │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ concept_generators_1            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │         \u001b[38;5;34m3,536\u001b[0m │\n",
       "│ (\u001b[38;5;33mSequential\u001b[0m)                    │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ concept_generators_2            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │         \u001b[38;5;34m3,536\u001b[0m │\n",
       "│ (\u001b[38;5;33mSequential\u001b[0m)                    │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ concept_generators_3            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │         \u001b[38;5;34m3,536\u001b[0m │\n",
       "│ (\u001b[38;5;33mSequential\u001b[0m)                    │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ concept_generators_4            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │         \u001b[38;5;34m3,536\u001b[0m │\n",
       "│ (\u001b[38;5;33mSequential\u001b[0m)                    │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ concept_generators_5            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │         \u001b[38;5;34m3,536\u001b[0m │\n",
       "│ (\u001b[38;5;33mSequential\u001b[0m)                    │                        │               │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">34,645</span> (135.33 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m34,645\u001b[0m (135.33 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">34,417</span> (134.44 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m34,417\u001b[0m (134.44 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">228</span> (912.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m228\u001b[0m (912.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# First we will instantiate a new TabCBM that is NOT in self-supervised mode,\n",
    "# and we will load its weights so that they are the same as the model whose\n",
    "# mask generators have been pre-trained using the SS loss.\n",
    "tabcbm_supervised = TabCBM(\n",
    "    self_supervised_mode=False,\n",
    "    # Notice how we provide as concept generators the concept generators of the\n",
    "    # SS TabCBM:\n",
    "    concept_generators=ss_tabcbm.concept_generators,\n",
    "    # as well as the feature probability masks:\n",
    "    prior_masks=ss_tabcbm.feature_probabilities,\n",
    "    **tab_cbm_params,\n",
    ")\n",
    "tabcbm_supervised.compile(optimizer=tf.keras.optimizers.Adam(learning_rate))\n",
    "tabcbm_supervised.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TabCBM self-supervised training stage...\n",
      "Epoch 1/150\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - accuracy: 0.5552 - avg_concept_size: 17.8135 - avg_features_rec_loss: 0.0000e+00 - avg_mask_rec_loss: 0.0000e+00 - loss: 3.4177 - max_probability: 0.7191 - mean_probability: 0.4824 - min_probability: 0.2608 - prob_sparsity_loss: 2.4122 - reg_loss_closest: 0.0067 - reg_loss_similarity: 0.4374 - task_loss: 0.5747 - val_accuracy: 0.0000e+00 - val_loss: 3.2120 - val_prob_sparsity_loss: 2.2557 - val_reg_loss_closest: 0.0053 - val_reg_loss_similarity: 0.2762 - val_task_loss: 0.6854\n",
      "Epoch 2/150\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.5559 - avg_concept_size: 13.4423 - avg_features_rec_loss: 0.0000e+00 - avg_mask_rec_loss: 0.0000e+00 - loss: 2.9965 - max_probability: 0.6792 - mean_probability: 0.4408 - min_probability: 0.2282 - prob_sparsity_loss: 2.2039 - reg_loss_closest: 0.0118 - reg_loss_similarity: 0.2703 - task_loss: 0.5340 - val_accuracy: 0.0000e+00 - val_loss: 2.9962 - val_prob_sparsity_loss: 2.0502 - val_reg_loss_closest: 0.0064 - val_reg_loss_similarity: 0.2571 - val_task_loss: 0.6953\n",
      "Epoch 3/150\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.5563 - avg_concept_size: 9.4059 - avg_features_rec_loss: 0.0000e+00 - avg_mask_rec_loss: 0.0000e+00 - loss: 2.7767 - max_probability: 0.6359 - mean_probability: 0.4000 - min_probability: 0.1998 - prob_sparsity_loss: 2.0002 - reg_loss_closest: 0.0133 - reg_loss_similarity: 0.2543 - task_loss: 0.5355 - val_accuracy: 0.0000e+00 - val_loss: 2.7534 - val_prob_sparsity_loss: 1.8526 - val_reg_loss_closest: 0.0068 - val_reg_loss_similarity: 0.2484 - val_task_loss: 0.6593\n",
      "Epoch 4/150\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.5549 - avg_concept_size: 6.0557 - avg_features_rec_loss: 0.0000e+00 - avg_mask_rec_loss: 0.0000e+00 - loss: 2.5722 - max_probability: 0.5896 - mean_probability: 0.3610 - min_probability: 0.1752 - prob_sparsity_loss: 1.8051 - reg_loss_closest: 0.0137 - reg_loss_similarity: 0.2470 - task_loss: 0.5338 - val_accuracy: 0.0000e+00 - val_loss: 2.5122 - val_prob_sparsity_loss: 1.6660 - val_reg_loss_closest: 0.0066 - val_reg_loss_similarity: 0.2433 - val_task_loss: 0.6095\n",
      "Epoch 5/150\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.5577 - avg_concept_size: 3.6342 - avg_features_rec_loss: 0.0000e+00 - avg_mask_rec_loss: 0.0000e+00 - loss: 2.3816 - max_probability: 0.5414 - mean_probability: 0.3243 - min_probability: 0.1541 - prob_sparsity_loss: 1.6217 - reg_loss_closest: 0.0140 - reg_loss_similarity: 0.2423 - task_loss: 0.5315 - val_accuracy: 0.0000e+00 - val_loss: 2.3582 - val_prob_sparsity_loss: 1.4927 - val_reg_loss_closest: 0.0069 - val_reg_loss_similarity: 0.2397 - val_task_loss: 0.6327\n",
      "Epoch 6/150\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.5540 - avg_concept_size: 0.1553 - avg_features_rec_loss: 0.0000e+00 - avg_mask_rec_loss: 0.0000e+00 - loss: 2.2092 - max_probability: 0.4929 - mean_probability: 0.2904 - min_probability: 0.1360 - prob_sparsity_loss: 1.4519 - reg_loss_closest: 0.0141 - reg_loss_similarity: 0.2390 - task_loss: 0.5324 - val_accuracy: 0.0000e+00 - val_loss: 2.2758 - val_prob_sparsity_loss: 1.3339 - val_reg_loss_closest: 0.0068 - val_reg_loss_similarity: 0.2375 - val_task_loss: 0.7112\n",
      "Epoch 7/150\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.5540 - avg_concept_size: 0.0000e+00 - avg_features_rec_loss: 0.0000e+00 - avg_mask_rec_loss: 0.0000e+00 - loss: 2.0522 - max_probability: 0.4455 - mean_probability: 0.2594 - min_probability: 0.1204 - prob_sparsity_loss: 1.2970 - reg_loss_closest: 0.0143 - reg_loss_similarity: 0.2369 - task_loss: 0.5326 - val_accuracy: 0.0000e+00 - val_loss: 2.1195 - val_prob_sparsity_loss: 1.1904 - val_reg_loss_closest: 0.0070 - val_reg_loss_similarity: 0.2357 - val_task_loss: 0.7005\n",
      "Epoch 8/150\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.5554 - avg_concept_size: 0.0000e+00 - avg_features_rec_loss: 0.0000e+00 - avg_mask_rec_loss: 0.0000e+00 - loss: 1.9108 - max_probability: 0.4003 - mean_probability: 0.2314 - min_probability: 0.1070 - prob_sparsity_loss: 1.1572 - reg_loss_closest: 0.0143 - reg_loss_similarity: 0.2355 - task_loss: 0.5324 - val_accuracy: 0.0000e+00 - val_loss: 2.0160 - val_prob_sparsity_loss: 1.0618 - val_reg_loss_closest: 0.0072 - val_reg_loss_similarity: 0.2346 - val_task_loss: 0.7267\n",
      "Epoch 9/150\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.5563 - avg_concept_size: 0.0000e+00 - avg_features_rec_loss: 0.0000e+00 - avg_mask_rec_loss: 0.0000e+00 - loss: 1.7858 - max_probability: 0.3582 - mean_probability: 0.2064 - min_probability: 0.0953 - prob_sparsity_loss: 1.0322 - reg_loss_closest: 0.0145 - reg_loss_similarity: 0.2346 - task_loss: 0.5335 - val_accuracy: 0.0000e+00 - val_loss: 1.8466 - val_prob_sparsity_loss: 0.9474 - val_reg_loss_closest: 0.0073 - val_reg_loss_similarity: 0.2340 - val_task_loss: 0.6726\n",
      "Epoch 10/150\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.5518 - avg_concept_size: 0.0000e+00 - avg_features_rec_loss: 0.0000e+00 - avg_mask_rec_loss: 0.0000e+00 - loss: 1.6714 - max_probability: 0.3197 - mean_probability: 0.1842 - min_probability: 0.0852 - prob_sparsity_loss: 0.9212 - reg_loss_closest: 0.0146 - reg_loss_similarity: 0.2339 - task_loss: 0.5308 - val_accuracy: 0.0000e+00 - val_loss: 1.7958 - val_prob_sparsity_loss: 0.8461 - val_reg_loss_closest: 0.0071 - val_reg_loss_similarity: 0.2336 - val_task_loss: 0.7232\n",
      "Epoch 11/150\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.5569 - avg_concept_size: 0.0000e+00 - avg_features_rec_loss: 0.0000e+00 - avg_mask_rec_loss: 0.0000e+00 - loss: 1.5720 - max_probability: 0.2849 - mean_probability: 0.1646 - min_probability: 0.0763 - prob_sparsity_loss: 0.8230 - reg_loss_closest: 0.0147 - reg_loss_similarity: 0.2335 - task_loss: 0.5301 - val_accuracy: 0.0000e+00 - val_loss: 1.6083 - val_prob_sparsity_loss: 0.7568 - val_reg_loss_closest: 0.0069 - val_reg_loss_similarity: 0.2334 - val_task_loss: 0.6250\n",
      "Epoch 12/150\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.5566 - avg_concept_size: 0.0000e+00 - avg_features_rec_loss: 0.0000e+00 - avg_mask_rec_loss: 0.0000e+00 - loss: 1.4853 - max_probability: 0.2539 - mean_probability: 0.1473 - min_probability: 0.0685 - prob_sparsity_loss: 0.7364 - reg_loss_closest: 0.0148 - reg_loss_similarity: 0.2332 - task_loss: 0.5304 - val_accuracy: 0.0000e+00 - val_loss: 1.5656 - val_prob_sparsity_loss: 0.6780 - val_reg_loss_closest: 0.0070 - val_reg_loss_similarity: 0.2332 - val_task_loss: 0.6614\n",
      "Epoch 13/150\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.5512 - avg_concept_size: 0.0000e+00 - avg_features_rec_loss: 0.0000e+00 - avg_mask_rec_loss: 0.0000e+00 - loss: 1.4117 - max_probability: 0.2265 - mean_probability: 0.1320 - min_probability: 0.0617 - prob_sparsity_loss: 0.6601 - reg_loss_closest: 0.0149 - reg_loss_similarity: 0.2330 - task_loss: 0.5335 - val_accuracy: 0.0000e+00 - val_loss: 1.5023 - val_prob_sparsity_loss: 0.6086 - val_reg_loss_closest: 0.0070 - val_reg_loss_similarity: 0.2328 - val_task_loss: 0.6679\n",
      "Epoch 14/150\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.5545 - avg_concept_size: 0.0000e+00 - avg_features_rec_loss: 0.0000e+00 - avg_mask_rec_loss: 0.0000e+00 - loss: 1.3426 - max_probability: 0.2024 - mean_probability: 0.1186 - min_probability: 0.0557 - prob_sparsity_loss: 0.5928 - reg_loss_closest: 0.0150 - reg_loss_similarity: 0.2328 - task_loss: 0.5320 - val_accuracy: 0.0000e+00 - val_loss: 1.4232 - val_prob_sparsity_loss: 0.5474 - val_reg_loss_closest: 0.0068 - val_reg_loss_similarity: 0.2325 - val_task_loss: 0.6500\n",
      "Epoch 15/150\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.5529 - avg_concept_size: 0.0000e+00 - avg_features_rec_loss: 0.0000e+00 - avg_mask_rec_loss: 0.0000e+00 - loss: 1.2846 - max_probability: 0.1810 - mean_probability: 0.1067 - min_probability: 0.0503 - prob_sparsity_loss: 0.5335 - reg_loss_closest: 0.0150 - reg_loss_similarity: 0.2327 - task_loss: 0.5334 - val_accuracy: 0.0000e+00 - val_loss: 1.3716 - val_prob_sparsity_loss: 0.4934 - val_reg_loss_closest: 0.0068 - val_reg_loss_similarity: 0.2327 - val_task_loss: 0.6523\n",
      "Epoch 16/150\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.5564 - avg_concept_size: 0.0000e+00 - avg_features_rec_loss: 0.0000e+00 - avg_mask_rec_loss: 0.0000e+00 - loss: 1.2292 - max_probability: 0.1623 - mean_probability: 0.0962 - min_probability: 0.0456 - prob_sparsity_loss: 0.4811 - reg_loss_closest: 0.0150 - reg_loss_similarity: 0.2327 - task_loss: 0.5305 - val_accuracy: 0.0000e+00 - val_loss: 1.3471 - val_prob_sparsity_loss: 0.4456 - val_reg_loss_closest: 0.0070 - val_reg_loss_similarity: 0.2324 - val_task_loss: 0.6760\n",
      "Epoch 17/150\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.5549 - avg_concept_size: 0.0000e+00 - avg_features_rec_loss: 0.0000e+00 - avg_mask_rec_loss: 0.0000e+00 - loss: 1.1826 - max_probability: 0.1457 - mean_probability: 0.0869 - min_probability: 0.0414 - prob_sparsity_loss: 0.4347 - reg_loss_closest: 0.0151 - reg_loss_similarity: 0.2324 - task_loss: 0.5307 - val_accuracy: 0.0000e+00 - val_loss: 1.3050 - val_prob_sparsity_loss: 0.4032 - val_reg_loss_closest: 0.0071 - val_reg_loss_similarity: 0.2323 - val_task_loss: 0.6765\n",
      "Epoch 18/150\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.5532 - avg_concept_size: 0.0000e+00 - avg_features_rec_loss: 0.0000e+00 - avg_mask_rec_loss: 0.0000e+00 - loss: 1.1438 - max_probability: 0.1311 - mean_probability: 0.0787 - min_probability: 0.0376 - prob_sparsity_loss: 0.3935 - reg_loss_closest: 0.0151 - reg_loss_similarity: 0.2324 - task_loss: 0.5331 - val_accuracy: 0.0000e+00 - val_loss: 1.2425 - val_prob_sparsity_loss: 0.3655 - val_reg_loss_closest: 0.0064 - val_reg_loss_similarity: 0.2323 - val_task_loss: 0.6511\n",
      "Epoch 19/150\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.5577 - avg_concept_size: 0.0000e+00 - avg_features_rec_loss: 0.0000e+00 - avg_mask_rec_loss: 0.0000e+00 - loss: 1.1049 - max_probability: 0.1185 - mean_probability: 0.0714 - min_probability: 0.0342 - prob_sparsity_loss: 0.3568 - reg_loss_closest: 0.0152 - reg_loss_similarity: 0.2324 - task_loss: 0.5309 - val_accuracy: 0.0000e+00 - val_loss: 1.2190 - val_prob_sparsity_loss: 0.3319 - val_reg_loss_closest: 0.0072 - val_reg_loss_similarity: 0.2326 - val_task_loss: 0.6617\n",
      "Epoch 20/150\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.5558 - avg_concept_size: 0.0000e+00 - avg_features_rec_loss: 0.0000e+00 - avg_mask_rec_loss: 0.0000e+00 - loss: 1.0726 - max_probability: 0.1070 - mean_probability: 0.0648 - min_probability: 0.0312 - prob_sparsity_loss: 0.3242 - reg_loss_closest: 0.0152 - reg_loss_similarity: 0.2325 - task_loss: 0.5311 - val_accuracy: 0.0000e+00 - val_loss: 1.2063 - val_prob_sparsity_loss: 0.3019 - val_reg_loss_closest: 0.0072 - val_reg_loss_similarity: 0.2327 - val_task_loss: 0.6789\n",
      "Epoch 21/150\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.5550 - avg_concept_size: 0.0000e+00 - avg_features_rec_loss: 0.0000e+00 - avg_mask_rec_loss: 0.0000e+00 - loss: 1.0435 - max_probability: 0.0971 - mean_probability: 0.0590 - min_probability: 0.0285 - prob_sparsity_loss: 0.2950 - reg_loss_closest: 0.0153 - reg_loss_similarity: 0.2324 - task_loss: 0.5315 - val_accuracy: 0.0000e+00 - val_loss: 1.1657 - val_prob_sparsity_loss: 0.2750 - val_reg_loss_closest: 0.0065 - val_reg_loss_similarity: 0.2326 - val_task_loss: 0.6646\n",
      "Epoch 22/150\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.5571 - avg_concept_size: 0.0000e+00 - avg_features_rec_loss: 0.0000e+00 - avg_mask_rec_loss: 0.0000e+00 - loss: 1.0166 - max_probability: 0.0884 - mean_probability: 0.0538 - min_probability: 0.0261 - prob_sparsity_loss: 0.2688 - reg_loss_closest: 0.0153 - reg_loss_similarity: 0.2324 - task_loss: 0.5307 - val_accuracy: 0.0000e+00 - val_loss: 1.1225 - val_prob_sparsity_loss: 0.2509 - val_reg_loss_closest: 0.0067 - val_reg_loss_similarity: 0.2322 - val_task_loss: 0.6460\n",
      "Epoch 23/150\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.5573 - avg_concept_size: 0.0000e+00 - avg_features_rec_loss: 0.0000e+00 - avg_mask_rec_loss: 0.0000e+00 - loss: 0.9939 - max_probability: 0.0807 - mean_probability: 0.0491 - min_probability: 0.0238 - prob_sparsity_loss: 0.2453 - reg_loss_closest: 0.0154 - reg_loss_similarity: 0.2324 - task_loss: 0.5316 - val_accuracy: 0.0000e+00 - val_loss: 1.0823 - val_prob_sparsity_loss: 0.2292 - val_reg_loss_closest: 0.0066 - val_reg_loss_similarity: 0.2325 - val_task_loss: 0.6272\n",
      "Epoch 24/150\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.5567 - avg_concept_size: 0.0000e+00 - avg_features_rec_loss: 0.0000e+00 - avg_mask_rec_loss: 0.0000e+00 - loss: 0.9715 - max_probability: 0.0734 - mean_probability: 0.0448 - min_probability: 0.0218 - prob_sparsity_loss: 0.2242 - reg_loss_closest: 0.0153 - reg_loss_similarity: 0.2323 - task_loss: 0.5303 - val_accuracy: 0.0000e+00 - val_loss: 1.0646 - val_prob_sparsity_loss: 0.2097 - val_reg_loss_closest: 0.0066 - val_reg_loss_similarity: 0.2325 - val_task_loss: 0.6291\n",
      "Epoch 25/150\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.5574 - avg_concept_size: 0.0000e+00 - avg_features_rec_loss: 0.0000e+00 - avg_mask_rec_loss: 0.0000e+00 - loss: 0.9533 - max_probability: 0.0673 - mean_probability: 0.0410 - min_probability: 0.0200 - prob_sparsity_loss: 0.2052 - reg_loss_closest: 0.0153 - reg_loss_similarity: 0.2322 - task_loss: 0.5312 - val_accuracy: 0.0000e+00 - val_loss: 1.0643 - val_prob_sparsity_loss: 0.1921 - val_reg_loss_closest: 0.0068 - val_reg_loss_similarity: 0.2328 - val_task_loss: 0.6462\n",
      "Epoch 26/150\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.5528 - avg_concept_size: 0.0000e+00 - avg_features_rec_loss: 0.0000e+00 - avg_mask_rec_loss: 0.0000e+00 - loss: 0.9379 - max_probability: 0.0622 - mean_probability: 0.0376 - min_probability: 0.0184 - prob_sparsity_loss: 0.1880 - reg_loss_closest: 0.0154 - reg_loss_similarity: 0.2324 - task_loss: 0.5329 - val_accuracy: 0.0000e+00 - val_loss: 1.0614 - val_prob_sparsity_loss: 0.1761 - val_reg_loss_closest: 0.0067 - val_reg_loss_similarity: 0.2323 - val_task_loss: 0.6598\n",
      "Epoch 27/150\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.5543 - avg_concept_size: 0.0000e+00 - avg_features_rec_loss: 0.0000e+00 - avg_mask_rec_loss: 0.0000e+00 - loss: 0.9226 - max_probability: 0.0568 - mean_probability: 0.0345 - min_probability: 0.0169 - prob_sparsity_loss: 0.1724 - reg_loss_closest: 0.0155 - reg_loss_similarity: 0.2323 - task_loss: 0.5333 - val_accuracy: 0.0000e+00 - val_loss: 1.0752 - val_prob_sparsity_loss: 0.1616 - val_reg_loss_closest: 0.0067 - val_reg_loss_similarity: 0.2321 - val_task_loss: 0.6882\n",
      "Epoch 28/150\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.5585 - avg_concept_size: 0.0000e+00 - avg_features_rec_loss: 0.0000e+00 - avg_mask_rec_loss: 0.0000e+00 - loss: 0.9045 - max_probability: 0.0524 - mean_probability: 0.0317 - min_probability: 0.0155 - prob_sparsity_loss: 0.1583 - reg_loss_closest: 0.0153 - reg_loss_similarity: 0.2322 - task_loss: 0.5294 - val_accuracy: 0.0000e+00 - val_loss: 1.0643 - val_prob_sparsity_loss: 0.1485 - val_reg_loss_closest: 0.0068 - val_reg_loss_similarity: 0.2322 - val_task_loss: 0.6904\n",
      "Epoch 29/150\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.5573 - avg_concept_size: 0.0000e+00 - avg_features_rec_loss: 0.0000e+00 - avg_mask_rec_loss: 0.0000e+00 - loss: 0.8906 - max_probability: 0.0486 - mean_probability: 0.0291 - min_probability: 0.0142 - prob_sparsity_loss: 0.1454 - reg_loss_closest: 0.0155 - reg_loss_similarity: 0.2323 - task_loss: 0.5284 - val_accuracy: 0.0000e+00 - val_loss: 0.9802 - val_prob_sparsity_loss: 0.1365 - val_reg_loss_closest: 0.0064 - val_reg_loss_similarity: 0.2322 - val_task_loss: 0.6178\n",
      "Epoch 30/150\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.5579 - avg_concept_size: 0.0000e+00 - avg_features_rec_loss: 0.0000e+00 - avg_mask_rec_loss: 0.0000e+00 - loss: 0.8821 - max_probability: 0.0451 - mean_probability: 0.0267 - min_probability: 0.0131 - prob_sparsity_loss: 0.1337 - reg_loss_closest: 0.0155 - reg_loss_similarity: 0.2323 - task_loss: 0.5316 - val_accuracy: 0.0000e+00 - val_loss: 1.0373 - val_prob_sparsity_loss: 0.1256 - val_reg_loss_closest: 0.0070 - val_reg_loss_similarity: 0.2323 - val_task_loss: 0.6864\n",
      "Epoch 31/150\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.5572 - avg_concept_size: 0.0000e+00 - avg_features_rec_loss: 0.0000e+00 - avg_mask_rec_loss: 0.0000e+00 - loss: 0.8703 - max_probability: 0.0420 - mean_probability: 0.0246 - min_probability: 0.0120 - prob_sparsity_loss: 0.1231 - reg_loss_closest: 0.0154 - reg_loss_similarity: 0.2323 - task_loss: 0.5304 - val_accuracy: 0.0000e+00 - val_loss: 1.0303 - val_prob_sparsity_loss: 0.1157 - val_reg_loss_closest: 0.0069 - val_reg_loss_similarity: 0.2325 - val_task_loss: 0.6889\n",
      "Epoch 32/150\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.5542 - avg_concept_size: 0.0000e+00 - avg_features_rec_loss: 0.0000e+00 - avg_mask_rec_loss: 0.0000e+00 - loss: 0.8600 - max_probability: 0.0389 - mean_probability: 0.0227 - min_probability: 0.0110 - prob_sparsity_loss: 0.1134 - reg_loss_closest: 0.0155 - reg_loss_similarity: 0.2324 - task_loss: 0.5297 - val_accuracy: 0.0000e+00 - val_loss: 1.0193 - val_prob_sparsity_loss: 0.1067 - val_reg_loss_closest: 0.0062 - val_reg_loss_similarity: 0.2323 - val_task_loss: 0.6865\n",
      "Epoch 33/150\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.5564 - avg_concept_size: 0.0000e+00 - avg_features_rec_loss: 0.0000e+00 - avg_mask_rec_loss: 0.0000e+00 - loss: 0.8532 - max_probability: 0.0361 - mean_probability: 0.0209 - min_probability: 0.0102 - prob_sparsity_loss: 0.1045 - reg_loss_closest: 0.0155 - reg_loss_similarity: 0.2323 - task_loss: 0.5318 - val_accuracy: 0.0000e+00 - val_loss: 0.9883 - val_prob_sparsity_loss: 0.0984 - val_reg_loss_closest: 0.0065 - val_reg_loss_similarity: 0.2324 - val_task_loss: 0.6640\n",
      "Epoch 34/150\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.5547 - avg_concept_size: 0.0000e+00 - avg_features_rec_loss: 0.0000e+00 - avg_mask_rec_loss: 0.0000e+00 - loss: 0.8446 - max_probability: 0.0337 - mean_probability: 0.0193 - min_probability: 0.0093 - prob_sparsity_loss: 0.0964 - reg_loss_closest: 0.0155 - reg_loss_similarity: 0.2324 - task_loss: 0.5312 - val_accuracy: 0.0000e+00 - val_loss: 0.9467 - val_prob_sparsity_loss: 0.0908 - val_reg_loss_closest: 0.0069 - val_reg_loss_similarity: 0.2326 - val_task_loss: 0.6302\n",
      "Epoch 35/150\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.5562 - avg_concept_size: 0.0000e+00 - avg_features_rec_loss: 0.0000e+00 - avg_mask_rec_loss: 0.0000e+00 - loss: 0.8377 - max_probability: 0.0315 - mean_probability: 0.0178 - min_probability: 0.0086 - prob_sparsity_loss: 0.0890 - reg_loss_closest: 0.0155 - reg_loss_similarity: 0.2325 - task_loss: 0.5317 - val_accuracy: 0.0000e+00 - val_loss: 0.9870 - val_prob_sparsity_loss: 0.0839 - val_reg_loss_closest: 0.0063 - val_reg_loss_similarity: 0.2326 - val_task_loss: 0.6769\n",
      "Epoch 36/150\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.5541 - avg_concept_size: 0.0000e+00 - avg_features_rec_loss: 0.0000e+00 - avg_mask_rec_loss: 0.0000e+00 - loss: 0.8285 - max_probability: 0.0298 - mean_probability: 0.0164 - min_probability: 0.0078 - prob_sparsity_loss: 0.0822 - reg_loss_closest: 0.0155 - reg_loss_similarity: 0.2324 - task_loss: 0.5294 - val_accuracy: 0.0000e+00 - val_loss: 0.9262 - val_prob_sparsity_loss: 0.0775 - val_reg_loss_closest: 0.0064 - val_reg_loss_similarity: 0.2325 - val_task_loss: 0.6226\n",
      "Epoch 37/150\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.5551 - avg_concept_size: 0.0000e+00 - avg_features_rec_loss: 0.0000e+00 - avg_mask_rec_loss: 0.0000e+00 - loss: 0.8256 - max_probability: 0.0280 - mean_probability: 0.0152 - min_probability: 0.0072 - prob_sparsity_loss: 0.0760 - reg_loss_closest: 0.0155 - reg_loss_similarity: 0.2323 - task_loss: 0.5328 - val_accuracy: 0.0000e+00 - val_loss: 0.9577 - val_prob_sparsity_loss: 0.0717 - val_reg_loss_closest: 0.0063 - val_reg_loss_similarity: 0.2322 - val_task_loss: 0.6602\n",
      "Epoch 38/150\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.5562 - avg_concept_size: 0.0000e+00 - avg_features_rec_loss: 0.0000e+00 - avg_mask_rec_loss: 0.0000e+00 - loss: 0.8183 - max_probability: 0.0263 - mean_probability: 0.0141 - min_probability: 0.0066 - prob_sparsity_loss: 0.0703 - reg_loss_closest: 0.0155 - reg_loss_similarity: 0.2323 - task_loss: 0.5312 - val_accuracy: 0.0000e+00 - val_loss: 0.9470 - val_prob_sparsity_loss: 0.0663 - val_reg_loss_closest: 0.0065 - val_reg_loss_similarity: 0.2327 - val_task_loss: 0.6546\n",
      "Epoch 39/150\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.5582 - avg_concept_size: 0.0000e+00 - avg_features_rec_loss: 0.0000e+00 - avg_mask_rec_loss: 0.0000e+00 - loss: 0.8108 - max_probability: 0.0247 - mean_probability: 0.0130 - min_probability: 0.0061 - prob_sparsity_loss: 0.0651 - reg_loss_closest: 0.0155 - reg_loss_similarity: 0.2324 - task_loss: 0.5288 - val_accuracy: 0.0000e+00 - val_loss: 0.9397 - val_prob_sparsity_loss: 0.0614 - val_reg_loss_closest: 0.0060 - val_reg_loss_similarity: 0.2324 - val_task_loss: 0.6519\n",
      "Epoch 40/150\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.5540 - avg_concept_size: 0.0000e+00 - avg_features_rec_loss: 0.0000e+00 - avg_mask_rec_loss: 0.0000e+00 - loss: 0.8092 - max_probability: 0.0231 - mean_probability: 0.0121 - min_probability: 0.0056 - prob_sparsity_loss: 0.0603 - reg_loss_closest: 0.0155 - reg_loss_similarity: 0.2323 - task_loss: 0.5321 - val_accuracy: 0.0000e+00 - val_loss: 0.9752 - val_prob_sparsity_loss: 0.0569 - val_reg_loss_closest: 0.0062 - val_reg_loss_similarity: 0.2322 - val_task_loss: 0.6924\n",
      "Epoch 41/150\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.5527 - avg_concept_size: 0.0000e+00 - avg_features_rec_loss: 0.0000e+00 - avg_mask_rec_loss: 0.0000e+00 - loss: 0.8032 - max_probability: 0.0215 - mean_probability: 0.0112 - min_probability: 0.0052 - prob_sparsity_loss: 0.0558 - reg_loss_closest: 0.0155 - reg_loss_similarity: 0.2324 - task_loss: 0.5305 - val_accuracy: 0.0000e+00 - val_loss: 0.9459 - val_prob_sparsity_loss: 0.0527 - val_reg_loss_closest: 0.0066 - val_reg_loss_similarity: 0.2326 - val_task_loss: 0.6671\n",
      "Epoch 42/150\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.5554 - avg_concept_size: 0.0000e+00 - avg_features_rec_loss: 0.0000e+00 - avg_mask_rec_loss: 0.0000e+00 - loss: 0.7991 - max_probability: 0.0205 - mean_probability: 0.0103 - min_probability: 0.0047 - prob_sparsity_loss: 0.0517 - reg_loss_closest: 0.0155 - reg_loss_similarity: 0.2325 - task_loss: 0.5304 - val_accuracy: 0.0000e+00 - val_loss: 0.9299 - val_prob_sparsity_loss: 0.0489 - val_reg_loss_closest: 0.0065 - val_reg_loss_similarity: 0.2323 - val_task_loss: 0.6552\n",
      "Epoch 43/150\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.5551 - avg_concept_size: 0.0000e+00 - avg_features_rec_loss: 0.0000e+00 - avg_mask_rec_loss: 0.0000e+00 - loss: 0.7978 - max_probability: 0.0194 - mean_probability: 0.0096 - min_probability: 0.0043 - prob_sparsity_loss: 0.0480 - reg_loss_closest: 0.0155 - reg_loss_similarity: 0.2323 - task_loss: 0.5330 - val_accuracy: 0.0000e+00 - val_loss: 0.9428 - val_prob_sparsity_loss: 0.0454 - val_reg_loss_closest: 0.0062 - val_reg_loss_similarity: 0.2324 - val_task_loss: 0.6712\n",
      "Epoch 44/150\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.5538 - avg_concept_size: 0.0000e+00 - avg_features_rec_loss: 0.0000e+00 - avg_mask_rec_loss: 0.0000e+00 - loss: 0.7938 - max_probability: 0.0187 - mean_probability: 0.0089 - min_probability: 0.0040 - prob_sparsity_loss: 0.0446 - reg_loss_closest: 0.0156 - reg_loss_similarity: 0.2324 - task_loss: 0.5324 - val_accuracy: 0.0000e+00 - val_loss: 0.9305 - val_prob_sparsity_loss: 0.0422 - val_reg_loss_closest: 0.0068 - val_reg_loss_similarity: 0.2325 - val_task_loss: 0.6626\n",
      "Epoch 45/150\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.5549 - avg_concept_size: 0.0000e+00 - avg_features_rec_loss: 0.0000e+00 - avg_mask_rec_loss: 0.0000e+00 - loss: 0.7889 - max_probability: 0.0178 - mean_probability: 0.0083 - min_probability: 0.0037 - prob_sparsity_loss: 0.0414 - reg_loss_closest: 0.0157 - reg_loss_similarity: 0.2324 - task_loss: 0.5308 - val_accuracy: 0.0000e+00 - val_loss: 0.9012 - val_prob_sparsity_loss: 0.0392 - val_reg_loss_closest: 0.0062 - val_reg_loss_similarity: 0.2327 - val_task_loss: 0.6356\n",
      "Epoch 46/150\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.5552 - avg_concept_size: 0.0000e+00 - avg_features_rec_loss: 0.0000e+00 - avg_mask_rec_loss: 0.0000e+00 - loss: 0.7859 - max_probability: 0.0170 - mean_probability: 0.0077 - min_probability: 0.0034 - prob_sparsity_loss: 0.0385 - reg_loss_closest: 0.0156 - reg_loss_similarity: 0.2324 - task_loss: 0.5306 - val_accuracy: 0.0000e+00 - val_loss: 0.9221 - val_prob_sparsity_loss: 0.0364 - val_reg_loss_closest: 0.0063 - val_reg_loss_similarity: 0.2323 - val_task_loss: 0.6596\n",
      "Epoch 47/150\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.5560 - avg_concept_size: 0.0000e+00 - avg_features_rec_loss: 0.0000e+00 - avg_mask_rec_loss: 0.0000e+00 - loss: 0.7836 - max_probability: 0.0162 - mean_probability: 0.0072 - min_probability: 0.0031 - prob_sparsity_loss: 0.0358 - reg_loss_closest: 0.0157 - reg_loss_similarity: 0.2325 - task_loss: 0.5310 - val_accuracy: 0.0000e+00 - val_loss: 0.9509 - val_prob_sparsity_loss: 0.0339 - val_reg_loss_closest: 0.0065 - val_reg_loss_similarity: 0.2323 - val_task_loss: 0.6912\n",
      "Epoch 48/150\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.5561 - avg_concept_size: 0.0000e+00 - avg_features_rec_loss: 0.0000e+00 - avg_mask_rec_loss: 0.0000e+00 - loss: 0.7822 - max_probability: 0.0155 - mean_probability: 0.0067 - min_probability: 0.0029 - prob_sparsity_loss: 0.0333 - reg_loss_closest: 0.0156 - reg_loss_similarity: 0.2323 - task_loss: 0.5322 - val_accuracy: 0.0000e+00 - val_loss: 0.8780 - val_prob_sparsity_loss: 0.0315 - val_reg_loss_closest: 0.0064 - val_reg_loss_similarity: 0.2324 - val_task_loss: 0.6205\n",
      "Epoch 49/150\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.5581 - avg_concept_size: 0.0000e+00 - avg_features_rec_loss: 0.0000e+00 - avg_mask_rec_loss: 0.0000e+00 - loss: 0.7783 - max_probability: 0.0149 - mean_probability: 0.0062 - min_probability: 0.0027 - prob_sparsity_loss: 0.0310 - reg_loss_closest: 0.0156 - reg_loss_similarity: 0.2323 - task_loss: 0.5306 - val_accuracy: 0.0000e+00 - val_loss: 0.9225 - val_prob_sparsity_loss: 0.0294 - val_reg_loss_closest: 0.0066 - val_reg_loss_similarity: 0.2323 - val_task_loss: 0.6674\n",
      "Epoch 50/150\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.5542 - avg_concept_size: 0.0000e+00 - avg_features_rec_loss: 0.0000e+00 - avg_mask_rec_loss: 0.0000e+00 - loss: 0.7782 - max_probability: 0.0143 - mean_probability: 0.0058 - min_probability: 0.0025 - prob_sparsity_loss: 0.0289 - reg_loss_closest: 0.0156 - reg_loss_similarity: 0.2324 - task_loss: 0.5325 - val_accuracy: 0.0000e+00 - val_loss: 0.9290 - val_prob_sparsity_loss: 0.0275 - val_reg_loss_closest: 0.0064 - val_reg_loss_similarity: 0.2323 - val_task_loss: 0.6756\n",
      "Epoch 51/150\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.5534 - avg_concept_size: 0.0000e+00 - avg_features_rec_loss: 0.0000e+00 - avg_mask_rec_loss: 0.0000e+00 - loss: 0.7762 - max_probability: 0.0138 - mean_probability: 0.0054 - min_probability: 0.0023 - prob_sparsity_loss: 0.0270 - reg_loss_closest: 0.0158 - reg_loss_similarity: 0.2326 - task_loss: 0.5324 - val_accuracy: 0.0000e+00 - val_loss: 0.9178 - val_prob_sparsity_loss: 0.0256 - val_reg_loss_closest: 0.0063 - val_reg_loss_similarity: 0.2325 - val_task_loss: 0.6660\n",
      "Epoch 52/150\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.5570 - avg_concept_size: 0.0000e+00 - avg_features_rec_loss: 0.0000e+00 - avg_mask_rec_loss: 0.0000e+00 - loss: 0.7738 - max_probability: 0.0133 - mean_probability: 0.0050 - min_probability: 0.0021 - prob_sparsity_loss: 0.0252 - reg_loss_closest: 0.0157 - reg_loss_similarity: 0.2324 - task_loss: 0.5318 - val_accuracy: 0.0000e+00 - val_loss: 0.8932 - val_prob_sparsity_loss: 0.0240 - val_reg_loss_closest: 0.0068 - val_reg_loss_similarity: 0.2322 - val_task_loss: 0.6438\n",
      "Epoch 53/150\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.5577 - avg_concept_size: 0.0000e+00 - avg_features_rec_loss: 0.0000e+00 - avg_mask_rec_loss: 0.0000e+00 - loss: 0.7730 - max_probability: 0.0130 - mean_probability: 0.0047 - min_probability: 0.0019 - prob_sparsity_loss: 0.0236 - reg_loss_closest: 0.0158 - reg_loss_similarity: 0.2324 - task_loss: 0.5328 - val_accuracy: 0.0000e+00 - val_loss: 0.9273 - val_prob_sparsity_loss: 0.0224 - val_reg_loss_closest: 0.0063 - val_reg_loss_similarity: 0.2323 - val_task_loss: 0.6788\n",
      "Epoch 54/150\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.5570 - avg_concept_size: 0.0000e+00 - avg_features_rec_loss: 0.0000e+00 - avg_mask_rec_loss: 0.0000e+00 - loss: 0.7705 - max_probability: 0.0125 - mean_probability: 0.0044 - min_probability: 0.0018 - prob_sparsity_loss: 0.0221 - reg_loss_closest: 0.0159 - reg_loss_similarity: 0.2324 - task_loss: 0.5319 - val_accuracy: 0.0000e+00 - val_loss: 0.8908 - val_prob_sparsity_loss: 0.0210 - val_reg_loss_closest: 0.0069 - val_reg_loss_similarity: 0.2326 - val_task_loss: 0.6441\n",
      "Epoch 55/150\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.5553 - avg_concept_size: 0.0000e+00 - avg_features_rec_loss: 0.0000e+00 - avg_mask_rec_loss: 0.0000e+00 - loss: 0.7699 - max_probability: 0.0119 - mean_probability: 0.0041 - min_probability: 0.0016 - prob_sparsity_loss: 0.0207 - reg_loss_closest: 0.0157 - reg_loss_similarity: 0.2325 - task_loss: 0.5324 - val_accuracy: 0.0000e+00 - val_loss: 0.9157 - val_prob_sparsity_loss: 0.0197 - val_reg_loss_closest: 0.0059 - val_reg_loss_similarity: 0.2327 - val_task_loss: 0.6693\n",
      "Epoch 56/150\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.5563 - avg_concept_size: 0.0000e+00 - avg_features_rec_loss: 0.0000e+00 - avg_mask_rec_loss: 0.0000e+00 - loss: 0.7661 - max_probability: 0.0114 - mean_probability: 0.0039 - min_probability: 0.0015 - prob_sparsity_loss: 0.0194 - reg_loss_closest: 0.0158 - reg_loss_similarity: 0.2325 - task_loss: 0.5301 - val_accuracy: 0.0000e+00 - val_loss: 0.9074 - val_prob_sparsity_loss: 0.0185 - val_reg_loss_closest: 0.0069 - val_reg_loss_similarity: 0.2323 - val_task_loss: 0.6635\n",
      "Epoch 57/150\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.5543 - avg_concept_size: 0.0000e+00 - avg_features_rec_loss: 0.0000e+00 - avg_mask_rec_loss: 0.0000e+00 - loss: 0.7659 - max_probability: 0.0112 - mean_probability: 0.0036 - min_probability: 0.0014 - prob_sparsity_loss: 0.0182 - reg_loss_closest: 0.0160 - reg_loss_similarity: 0.2325 - task_loss: 0.5312 - val_accuracy: 0.0000e+00 - val_loss: 0.9213 - val_prob_sparsity_loss: 0.0173 - val_reg_loss_closest: 0.0070 - val_reg_loss_similarity: 0.2324 - val_task_loss: 0.6785\n",
      "Epoch 58/150\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.5539 - avg_concept_size: 0.0000e+00 - avg_features_rec_loss: 0.0000e+00 - avg_mask_rec_loss: 0.0000e+00 - loss: 0.7642 - max_probability: 0.0112 - mean_probability: 0.0034 - min_probability: 0.0013 - prob_sparsity_loss: 0.0170 - reg_loss_closest: 0.0157 - reg_loss_similarity: 0.2325 - task_loss: 0.5303 - val_accuracy: 0.0000e+00 - val_loss: 0.9163 - val_prob_sparsity_loss: 0.0163 - val_reg_loss_closest: 0.0068 - val_reg_loss_similarity: 0.2323 - val_task_loss: 0.6745\n",
      "Epoch 59/150\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.5529 - avg_concept_size: 0.0000e+00 - avg_features_rec_loss: 0.0000e+00 - avg_mask_rec_loss: 0.0000e+00 - loss: 0.7616 - max_probability: 0.0113 - mean_probability: 0.0032 - min_probability: 0.0012 - prob_sparsity_loss: 0.0160 - reg_loss_closest: 0.0161 - reg_loss_similarity: 0.2325 - task_loss: 0.5293 - val_accuracy: 0.0000e+00 - val_loss: 0.9081 - val_prob_sparsity_loss: 0.0153 - val_reg_loss_closest: 0.0065 - val_reg_loss_similarity: 0.2321 - val_task_loss: 0.6671\n",
      "Epoch 60/150\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.5579 - avg_concept_size: 0.0000e+00 - avg_features_rec_loss: 0.0000e+00 - avg_mask_rec_loss: 0.0000e+00 - loss: 0.7617 - max_probability: 0.0112 - mean_probability: 0.0030 - min_probability: 0.0011 - prob_sparsity_loss: 0.0151 - reg_loss_closest: 0.0162 - reg_loss_similarity: 0.2324 - task_loss: 0.5305 - val_accuracy: 0.0000e+00 - val_loss: 0.8652 - val_prob_sparsity_loss: 0.0144 - val_reg_loss_closest: 0.0067 - val_reg_loss_similarity: 0.2326 - val_task_loss: 0.6249\n",
      "Epoch 61/150\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.5549 - avg_concept_size: 0.0000e+00 - avg_features_rec_loss: 0.0000e+00 - avg_mask_rec_loss: 0.0000e+00 - loss: 0.7614 - max_probability: 0.0111 - mean_probability: 0.0028 - min_probability: 9.8681e-04 - prob_sparsity_loss: 0.0142 - reg_loss_closest: 0.0163 - reg_loss_similarity: 0.2324 - task_loss: 0.5311 - val_accuracy: 0.0000e+00 - val_loss: 0.9043 - val_prob_sparsity_loss: 0.0136 - val_reg_loss_closest: 0.0065 - val_reg_loss_similarity: 0.2324 - val_task_loss: 0.6649\n",
      "Epoch 62/150\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.5557 - avg_concept_size: 0.0000e+00 - avg_features_rec_loss: 0.0000e+00 - avg_mask_rec_loss: 0.0000e+00 - loss: 0.7580 - max_probability: 0.0110 - mean_probability: 0.0027 - min_probability: 9.1992e-04 - prob_sparsity_loss: 0.0134 - reg_loss_closest: 0.0165 - reg_loss_similarity: 0.2325 - task_loss: 0.5286 - val_accuracy: 0.0000e+00 - val_loss: 0.8947 - val_prob_sparsity_loss: 0.0128 - val_reg_loss_closest: 0.0066 - val_reg_loss_similarity: 0.2326 - val_task_loss: 0.6559\n",
      "Epoch 63/150\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.5565 - avg_concept_size: 0.0000e+00 - avg_features_rec_loss: 0.0000e+00 - avg_mask_rec_loss: 0.0000e+00 - loss: 0.7605 - max_probability: 0.0110 - mean_probability: 0.0025 - min_probability: 8.3365e-04 - prob_sparsity_loss: 0.0126 - reg_loss_closest: 0.0164 - reg_loss_similarity: 0.2326 - task_loss: 0.5317 - val_accuracy: 0.0000e+00 - val_loss: 0.8903 - val_prob_sparsity_loss: 0.0122 - val_reg_loss_closest: 0.0061 - val_reg_loss_similarity: 0.2327 - val_task_loss: 0.6516\n",
      "Epoch 64/150\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.5553 - avg_concept_size: 0.0000e+00 - avg_features_rec_loss: 0.0000e+00 - avg_mask_rec_loss: 0.0000e+00 - loss: 0.7596 - max_probability: 0.0111 - mean_probability: 0.0024 - min_probability: 7.4699e-04 - prob_sparsity_loss: 0.0120 - reg_loss_closest: 0.0166 - reg_loss_similarity: 0.2324 - task_loss: 0.5317 - val_accuracy: 0.0000e+00 - val_loss: 0.9165 - val_prob_sparsity_loss: 0.0115 - val_reg_loss_closest: 0.0057 - val_reg_loss_similarity: 0.2325 - val_task_loss: 0.6782\n",
      "Epoch 65/150\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.5581 - avg_concept_size: 0.0000e+00 - avg_features_rec_loss: 0.0000e+00 - avg_mask_rec_loss: 0.0000e+00 - loss: 0.7574 - max_probability: 0.0110 - mean_probability: 0.0023 - min_probability: 6.7371e-04 - prob_sparsity_loss: 0.0114 - reg_loss_closest: 0.0164 - reg_loss_similarity: 0.2325 - task_loss: 0.5299 - val_accuracy: 0.0000e+00 - val_loss: 0.8969 - val_prob_sparsity_loss: 0.0109 - val_reg_loss_closest: 0.0073 - val_reg_loss_similarity: 0.2325 - val_task_loss: 0.6608\n",
      "Epoch 66/150\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.5556 - avg_concept_size: 0.0000e+00 - avg_features_rec_loss: 0.0000e+00 - avg_mask_rec_loss: 0.0000e+00 - loss: 0.7566 - max_probability: 0.0110 - mean_probability: 0.0022 - min_probability: 6.0446e-04 - prob_sparsity_loss: 0.0108 - reg_loss_closest: 0.0168 - reg_loss_similarity: 0.2325 - task_loss: 0.5302 - val_accuracy: 0.0000e+00 - val_loss: 0.9009 - val_prob_sparsity_loss: 0.0103 - val_reg_loss_closest: 0.0068 - val_reg_loss_similarity: 0.2325 - val_task_loss: 0.6649\n",
      "Epoch 67/150\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.5534 - avg_concept_size: 0.0000e+00 - avg_features_rec_loss: 0.0000e+00 - avg_mask_rec_loss: 0.0000e+00 - loss: 0.7558 - max_probability: 0.0109 - mean_probability: 0.0020 - min_probability: 5.4058e-04 - prob_sparsity_loss: 0.0102 - reg_loss_closest: 0.0169 - reg_loss_similarity: 0.2324 - task_loss: 0.5301 - val_accuracy: 0.0000e+00 - val_loss: 0.9033 - val_prob_sparsity_loss: 0.0098 - val_reg_loss_closest: 0.0069 - val_reg_loss_similarity: 0.2323 - val_task_loss: 0.6680\n",
      "Epoch 68/150\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.5563 - avg_concept_size: 0.0000e+00 - avg_features_rec_loss: 0.0000e+00 - avg_mask_rec_loss: 0.0000e+00 - loss: 0.7550 - max_probability: 0.0107 - mean_probability: 0.0019 - min_probability: 4.8710e-04 - prob_sparsity_loss: 0.0097 - reg_loss_closest: 0.0171 - reg_loss_similarity: 0.2324 - task_loss: 0.5299 - val_accuracy: 0.0000e+00 - val_loss: 0.8912 - val_prob_sparsity_loss: 0.0094 - val_reg_loss_closest: 0.0062 - val_reg_loss_similarity: 0.2325 - val_task_loss: 0.6556\n",
      "Epoch 69/150\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.5578 - avg_concept_size: 0.0000e+00 - avg_features_rec_loss: 0.0000e+00 - avg_mask_rec_loss: 0.0000e+00 - loss: 0.7536 - max_probability: 0.0106 - mean_probability: 0.0019 - min_probability: 4.3525e-04 - prob_sparsity_loss: 0.0093 - reg_loss_closest: 0.0173 - reg_loss_similarity: 0.2323 - task_loss: 0.5293 - val_accuracy: 0.0000e+00 - val_loss: 0.8813 - val_prob_sparsity_loss: 0.0089 - val_reg_loss_closest: 0.0075 - val_reg_loss_similarity: 0.2324 - val_task_loss: 0.6475\n",
      "Epoch 70/150\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.5551 - avg_concept_size: 0.0000e+00 - avg_features_rec_loss: 0.0000e+00 - avg_mask_rec_loss: 0.0000e+00 - loss: 0.7554 - max_probability: 0.0103 - mean_probability: 0.0018 - min_probability: 3.8993e-04 - prob_sparsity_loss: 0.0088 - reg_loss_closest: 0.0174 - reg_loss_similarity: 0.2325 - task_loss: 0.5315 - val_accuracy: 0.0000e+00 - val_loss: 0.8916 - val_prob_sparsity_loss: 0.0085 - val_reg_loss_closest: 0.0067 - val_reg_loss_similarity: 0.2325 - val_task_loss: 0.6573\n",
      "Epoch 71/150\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.5585 - avg_concept_size: 0.0000e+00 - avg_features_rec_loss: 0.0000e+00 - avg_mask_rec_loss: 0.0000e+00 - loss: 0.7556 - max_probability: 0.0102 - mean_probability: 0.0017 - min_probability: 3.5113e-04 - prob_sparsity_loss: 0.0084 - reg_loss_closest: 0.0172 - reg_loss_similarity: 0.2325 - task_loss: 0.5319 - val_accuracy: 0.0000e+00 - val_loss: 0.8615 - val_prob_sparsity_loss: 0.0082 - val_reg_loss_closest: 0.0078 - val_reg_loss_similarity: 0.2329 - val_task_loss: 0.6282\n",
      "Epoch 72/150\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.5551 - avg_concept_size: 0.0000e+00 - avg_features_rec_loss: 0.0000e+00 - avg_mask_rec_loss: 0.0000e+00 - loss: 0.7538 - max_probability: 0.0101 - mean_probability: 0.0016 - min_probability: 3.2327e-04 - prob_sparsity_loss: 0.0081 - reg_loss_closest: 0.0176 - reg_loss_similarity: 0.2325 - task_loss: 0.5307 - val_accuracy: 0.0000e+00 - val_loss: 0.9141 - val_prob_sparsity_loss: 0.0079 - val_reg_loss_closest: 0.0069 - val_reg_loss_similarity: 0.2325 - val_task_loss: 0.6806\n",
      "Epoch 73/150\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.5559 - avg_concept_size: 0.0000e+00 - avg_features_rec_loss: 0.0000e+00 - avg_mask_rec_loss: 0.0000e+00 - loss: 0.7564 - max_probability: 0.0099 - mean_probability: 0.0016 - min_probability: 2.9520e-04 - prob_sparsity_loss: 0.0078 - reg_loss_closest: 0.0177 - reg_loss_similarity: 0.2326 - task_loss: 0.5337 - val_accuracy: 0.0000e+00 - val_loss: 0.8949 - val_prob_sparsity_loss: 0.0075 - val_reg_loss_closest: 0.0073 - val_reg_loss_similarity: 0.2323 - val_task_loss: 0.6624\n",
      "Epoch 74/150\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.5542 - avg_concept_size: 0.0000e+00 - avg_features_rec_loss: 0.0000e+00 - avg_mask_rec_loss: 0.0000e+00 - loss: 0.7555 - max_probability: 0.0098 - mean_probability: 0.0015 - min_probability: 2.6557e-04 - prob_sparsity_loss: 0.0074 - reg_loss_closest: 0.0176 - reg_loss_similarity: 0.2324 - task_loss: 0.5332 - val_accuracy: 0.0000e+00 - val_loss: 0.9044 - val_prob_sparsity_loss: 0.0072 - val_reg_loss_closest: 0.0077 - val_reg_loss_similarity: 0.2326 - val_task_loss: 0.6722\n",
      "Epoch 75/150\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.5543 - avg_concept_size: 0.0000e+00 - avg_features_rec_loss: 0.0000e+00 - avg_mask_rec_loss: 0.0000e+00 - loss: 0.7532 - max_probability: 0.0096 - mean_probability: 0.0014 - min_probability: 2.4167e-04 - prob_sparsity_loss: 0.0071 - reg_loss_closest: 0.0178 - reg_loss_similarity: 0.2326 - task_loss: 0.5313 - val_accuracy: 0.0000e+00 - val_loss: 0.8986 - val_prob_sparsity_loss: 0.0069 - val_reg_loss_closest: 0.0077 - val_reg_loss_similarity: 0.2324 - val_task_loss: 0.6670\n",
      "Epoch 76/150\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.5563 - avg_concept_size: 0.0000e+00 - avg_features_rec_loss: 0.0000e+00 - avg_mask_rec_loss: 0.0000e+00 - loss: 0.7528 - max_probability: 0.0094 - mean_probability: 0.0014 - min_probability: 2.2359e-04 - prob_sparsity_loss: 0.0069 - reg_loss_closest: 0.0178 - reg_loss_similarity: 0.2325 - task_loss: 0.5312 - val_accuracy: 0.0000e+00 - val_loss: 0.8888 - val_prob_sparsity_loss: 0.0067 - val_reg_loss_closest: 0.0077 - val_reg_loss_similarity: 0.2329 - val_task_loss: 0.6569\n",
      "Epoch 77/150\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.5561 - avg_concept_size: 0.0000e+00 - avg_features_rec_loss: 0.0000e+00 - avg_mask_rec_loss: 0.0000e+00 - loss: 0.7514 - max_probability: 0.0093 - mean_probability: 0.0013 - min_probability: 2.0761e-04 - prob_sparsity_loss: 0.0066 - reg_loss_closest: 0.0181 - reg_loss_similarity: 0.2326 - task_loss: 0.5304 - val_accuracy: 0.0000e+00 - val_loss: 0.8890 - val_prob_sparsity_loss: 0.0064 - val_reg_loss_closest: 0.0070 - val_reg_loss_similarity: 0.2325 - val_task_loss: 0.6571\n",
      "Epoch 78/150\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.5549 - avg_concept_size: 0.0000e+00 - avg_features_rec_loss: 0.0000e+00 - avg_mask_rec_loss: 0.0000e+00 - loss: 0.7514 - max_probability: 0.0091 - mean_probability: 0.0013 - min_probability: 1.9072e-04 - prob_sparsity_loss: 0.0063 - reg_loss_closest: 0.0180 - reg_loss_similarity: 0.2327 - task_loss: 0.5304 - val_accuracy: 0.0000e+00 - val_loss: 0.8841 - val_prob_sparsity_loss: 0.0062 - val_reg_loss_closest: 0.0080 - val_reg_loss_similarity: 0.2330 - val_task_loss: 0.6530\n",
      "Epoch 79/150\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.5563 - avg_concept_size: 0.0000e+00 - avg_features_rec_loss: 0.0000e+00 - avg_mask_rec_loss: 0.0000e+00 - loss: 0.7496 - max_probability: 0.0089 - mean_probability: 0.0012 - min_probability: 1.7418e-04 - prob_sparsity_loss: 0.0061 - reg_loss_closest: 0.0183 - reg_loss_similarity: 0.2324 - task_loss: 0.5293 - val_accuracy: 0.0000e+00 - val_loss: 0.8962 - val_prob_sparsity_loss: 0.0060 - val_reg_loss_closest: 0.0076 - val_reg_loss_similarity: 0.2327 - val_task_loss: 0.6652\n",
      "Epoch 80/150\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.5553 - avg_concept_size: 0.0000e+00 - avg_features_rec_loss: 0.0000e+00 - avg_mask_rec_loss: 0.0000e+00 - loss: 0.7507 - max_probability: 0.0087 - mean_probability: 0.0012 - min_probability: 1.5844e-04 - prob_sparsity_loss: 0.0059 - reg_loss_closest: 0.0184 - reg_loss_similarity: 0.2325 - task_loss: 0.5308 - val_accuracy: 0.0000e+00 - val_loss: 0.8812 - val_prob_sparsity_loss: 0.0057 - val_reg_loss_closest: 0.0080 - val_reg_loss_similarity: 0.2325 - val_task_loss: 0.6509\n",
      "Epoch 81/150\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.5555 - avg_concept_size: 0.0000e+00 - avg_features_rec_loss: 0.0000e+00 - avg_mask_rec_loss: 0.0000e+00 - loss: 0.7501 - max_probability: 0.0086 - mean_probability: 0.0011 - min_probability: 1.4560e-04 - prob_sparsity_loss: 0.0057 - reg_loss_closest: 0.0185 - reg_loss_similarity: 0.2326 - task_loss: 0.5304 - val_accuracy: 0.0000e+00 - val_loss: 0.8988 - val_prob_sparsity_loss: 0.0055 - val_reg_loss_closest: 0.0077 - val_reg_loss_similarity: 0.2329 - val_task_loss: 0.6681\n",
      "Epoch 82/150\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.5556 - avg_concept_size: 0.0000e+00 - avg_features_rec_loss: 0.0000e+00 - avg_mask_rec_loss: 0.0000e+00 - loss: 0.7501 - max_probability: 0.0084 - mean_probability: 0.0011 - min_probability: 1.3567e-04 - prob_sparsity_loss: 0.0055 - reg_loss_closest: 0.0185 - reg_loss_similarity: 0.2326 - task_loss: 0.5305 - val_accuracy: 0.0000e+00 - val_loss: 0.8947 - val_prob_sparsity_loss: 0.0053 - val_reg_loss_closest: 0.0074 - val_reg_loss_similarity: 0.2324 - val_task_loss: 0.6643\n",
      "Epoch 83/150\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.5531 - avg_concept_size: 0.0000e+00 - avg_features_rec_loss: 0.0000e+00 - avg_mask_rec_loss: 0.0000e+00 - loss: 0.7517 - max_probability: 0.0083 - mean_probability: 0.0011 - min_probability: 1.2659e-04 - prob_sparsity_loss: 0.0053 - reg_loss_closest: 0.0182 - reg_loss_similarity: 0.2326 - task_loss: 0.5319 - val_accuracy: 0.0000e+00 - val_loss: 0.8939 - val_prob_sparsity_loss: 0.0052 - val_reg_loss_closest: 0.0080 - val_reg_loss_similarity: 0.2323 - val_task_loss: 0.6644\n",
      "Epoch 84/150\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.5571 - avg_concept_size: 0.0000e+00 - avg_features_rec_loss: 0.0000e+00 - avg_mask_rec_loss: 0.0000e+00 - loss: 0.7488 - max_probability: 0.0081 - mean_probability: 0.0010 - min_probability: 1.1854e-04 - prob_sparsity_loss: 0.0051 - reg_loss_closest: 0.0187 - reg_loss_similarity: 0.2326 - task_loss: 0.5297 - val_accuracy: 0.0000e+00 - val_loss: 0.8910 - val_prob_sparsity_loss: 0.0050 - val_reg_loss_closest: 0.0077 - val_reg_loss_similarity: 0.2323 - val_task_loss: 0.6614\n",
      "Epoch 85/150\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.5544 - avg_concept_size: 0.0000e+00 - avg_features_rec_loss: 0.0000e+00 - avg_mask_rec_loss: 0.0000e+00 - loss: 0.7489 - max_probability: 0.0079 - mean_probability: 9.9529e-04 - min_probability: 1.1009e-04 - prob_sparsity_loss: 0.0050 - reg_loss_closest: 0.0187 - reg_loss_similarity: 0.2325 - task_loss: 0.5301 - val_accuracy: 0.0000e+00 - val_loss: 0.8959 - val_prob_sparsity_loss: 0.0049 - val_reg_loss_closest: 0.0079 - val_reg_loss_similarity: 0.2325 - val_task_loss: 0.6665\n",
      "Epoch 86/150\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.5560 - avg_concept_size: 0.0000e+00 - avg_features_rec_loss: 0.0000e+00 - avg_mask_rec_loss: 0.0000e+00 - loss: 0.7498 - max_probability: 0.0078 - mean_probability: 9.6531e-04 - min_probability: 1.0202e-04 - prob_sparsity_loss: 0.0048 - reg_loss_closest: 0.0185 - reg_loss_similarity: 0.2326 - task_loss: 0.5310 - val_accuracy: 0.0000e+00 - val_loss: 0.8729 - val_prob_sparsity_loss: 0.0047 - val_reg_loss_closest: 0.0080 - val_reg_loss_similarity: 0.2326 - val_task_loss: 0.6436\n",
      "Epoch 87/150\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.5531 - avg_concept_size: 0.0000e+00 - avg_features_rec_loss: 0.0000e+00 - avg_mask_rec_loss: 0.0000e+00 - loss: 0.7496 - max_probability: 0.0077 - mean_probability: 9.4023e-04 - min_probability: 9.6142e-05 - prob_sparsity_loss: 0.0047 - reg_loss_closest: 0.0185 - reg_loss_similarity: 0.2326 - task_loss: 0.5308 - val_accuracy: 0.0000e+00 - val_loss: 0.8913 - val_prob_sparsity_loss: 0.0046 - val_reg_loss_closest: 0.0077 - val_reg_loss_similarity: 0.2325 - val_task_loss: 0.6619\n",
      "Epoch 88/150\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.5524 - avg_concept_size: 0.0000e+00 - avg_features_rec_loss: 0.0000e+00 - avg_mask_rec_loss: 0.0000e+00 - loss: 0.7470 - max_probability: 0.0076 - mean_probability: 9.1312e-04 - min_probability: 8.9359e-05 - prob_sparsity_loss: 0.0046 - reg_loss_closest: 0.0191 - reg_loss_similarity: 0.2325 - task_loss: 0.5289 - val_accuracy: 0.0000e+00 - val_loss: 0.9079 - val_prob_sparsity_loss: 0.0045 - val_reg_loss_closest: 0.0072 - val_reg_loss_similarity: 0.2323 - val_task_loss: 0.6784\n",
      "Epoch 89/150\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.5544 - avg_concept_size: 0.0000e+00 - avg_features_rec_loss: 0.0000e+00 - avg_mask_rec_loss: 0.0000e+00 - loss: 0.7489 - max_probability: 0.0074 - mean_probability: 8.8774e-04 - min_probability: 8.2592e-05 - prob_sparsity_loss: 0.0044 - reg_loss_closest: 0.0186 - reg_loss_similarity: 0.2325 - task_loss: 0.5306 - val_accuracy: 0.0000e+00 - val_loss: 0.8777 - val_prob_sparsity_loss: 0.0044 - val_reg_loss_closest: 0.0081 - val_reg_loss_similarity: 0.2324 - val_task_loss: 0.6491\n",
      "Epoch 90/150\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.5574 - avg_concept_size: 0.0000e+00 - avg_features_rec_loss: 0.0000e+00 - avg_mask_rec_loss: 0.0000e+00 - loss: 0.7488 - max_probability: 0.0074 - mean_probability: 8.6966e-04 - min_probability: 7.7011e-05 - prob_sparsity_loss: 0.0043 - reg_loss_closest: 0.0189 - reg_loss_similarity: 0.2326 - task_loss: 0.5307 - val_accuracy: 0.0000e+00 - val_loss: 0.8787 - val_prob_sparsity_loss: 0.0043 - val_reg_loss_closest: 0.0080 - val_reg_loss_similarity: 0.2323 - val_task_loss: 0.6500\n",
      "Epoch 91/150\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.5531 - avg_concept_size: 0.0000e+00 - avg_features_rec_loss: 0.0000e+00 - avg_mask_rec_loss: 0.0000e+00 - loss: 0.7505 - max_probability: 0.0073 - mean_probability: 8.4766e-04 - min_probability: 7.0641e-05 - prob_sparsity_loss: 0.0042 - reg_loss_closest: 0.0191 - reg_loss_similarity: 0.2326 - task_loss: 0.5328 - val_accuracy: 0.0000e+00 - val_loss: 0.9039 - val_prob_sparsity_loss: 0.0042 - val_reg_loss_closest: 0.0073 - val_reg_loss_similarity: 0.2325 - val_task_loss: 0.6745\n",
      "Epoch 92/150\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.5579 - avg_concept_size: 0.0000e+00 - avg_features_rec_loss: 0.0000e+00 - avg_mask_rec_loss: 0.0000e+00 - loss: 0.7476 - max_probability: 0.0073 - mean_probability: 8.2792e-04 - min_probability: 6.6070e-05 - prob_sparsity_loss: 0.0041 - reg_loss_closest: 0.0193 - reg_loss_similarity: 0.2325 - task_loss: 0.5302 - val_accuracy: 0.0000e+00 - val_loss: 0.9074 - val_prob_sparsity_loss: 0.0041 - val_reg_loss_closest: 0.0083 - val_reg_loss_similarity: 0.2327 - val_task_loss: 0.6790\n",
      "Epoch 93/150\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.5554 - avg_concept_size: 0.0000e+00 - avg_features_rec_loss: 0.0000e+00 - avg_mask_rec_loss: 0.0000e+00 - loss: 0.7495 - max_probability: 0.0070 - mean_probability: 8.0630e-04 - min_probability: 6.0986e-05 - prob_sparsity_loss: 0.0040 - reg_loss_closest: 0.0193 - reg_loss_similarity: 0.2325 - task_loss: 0.5322 - val_accuracy: 0.0000e+00 - val_loss: 0.8898 - val_prob_sparsity_loss: 0.0040 - val_reg_loss_closest: 0.0084 - val_reg_loss_similarity: 0.2325 - val_task_loss: 0.6617\n",
      "Epoch 94/150\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.5564 - avg_concept_size: 0.0000e+00 - avg_features_rec_loss: 0.0000e+00 - avg_mask_rec_loss: 0.0000e+00 - loss: 0.7466 - max_probability: 0.0069 - mean_probability: 7.9296e-04 - min_probability: 5.5838e-05 - prob_sparsity_loss: 0.0040 - reg_loss_closest: 0.0194 - reg_loss_similarity: 0.2325 - task_loss: 0.5295 - val_accuracy: 0.0000e+00 - val_loss: 0.9017 - val_prob_sparsity_loss: 0.0039 - val_reg_loss_closest: 0.0087 - val_reg_loss_similarity: 0.2326 - val_task_loss: 0.6739\n",
      "Epoch 95/150\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.5540 - avg_concept_size: 0.0000e+00 - avg_features_rec_loss: 0.0000e+00 - avg_mask_rec_loss: 0.0000e+00 - loss: 0.7483 - max_probability: 0.0066 - mean_probability: 7.7786e-04 - min_probability: 5.1307e-05 - prob_sparsity_loss: 0.0039 - reg_loss_closest: 0.0197 - reg_loss_similarity: 0.2325 - task_loss: 0.5316 - val_accuracy: 0.0000e+00 - val_loss: 0.8922 - val_prob_sparsity_loss: 0.0038 - val_reg_loss_closest: 0.0083 - val_reg_loss_similarity: 0.2323 - val_task_loss: 0.6643\n",
      "Epoch 96/150\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.5533 - avg_concept_size: 0.0000e+00 - avg_features_rec_loss: 0.0000e+00 - avg_mask_rec_loss: 0.0000e+00 - loss: 0.7487 - max_probability: 0.0064 - mean_probability: 7.6361e-04 - min_probability: 4.6368e-05 - prob_sparsity_loss: 0.0038 - reg_loss_closest: 0.0199 - reg_loss_similarity: 0.2325 - task_loss: 0.5323 - val_accuracy: 0.0000e+00 - val_loss: 0.8684 - val_prob_sparsity_loss: 0.0038 - val_reg_loss_closest: 0.0085 - val_reg_loss_similarity: 0.2326 - val_task_loss: 0.6406\n",
      "Epoch 97/150\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.5583 - avg_concept_size: 0.0000e+00 - avg_features_rec_loss: 0.0000e+00 - avg_mask_rec_loss: 0.0000e+00 - loss: 0.7466 - max_probability: 0.0063 - mean_probability: 7.5013e-04 - min_probability: 4.2667e-05 - prob_sparsity_loss: 0.0038 - reg_loss_closest: 0.0201 - reg_loss_similarity: 0.2325 - task_loss: 0.5305 - val_accuracy: 0.0000e+00 - val_loss: 0.8957 - val_prob_sparsity_loss: 0.0037 - val_reg_loss_closest: 0.0090 - val_reg_loss_similarity: 0.2323 - val_task_loss: 0.6687\n",
      "Epoch 98/150\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.5561 - avg_concept_size: 0.0000e+00 - avg_features_rec_loss: 0.0000e+00 - avg_mask_rec_loss: 0.0000e+00 - loss: 0.7457 - max_probability: 0.0063 - mean_probability: 7.4117e-04 - min_probability: 3.9689e-05 - prob_sparsity_loss: 0.0037 - reg_loss_closest: 0.0204 - reg_loss_similarity: 0.2324 - task_loss: 0.5299 - val_accuracy: 0.0000e+00 - val_loss: 0.8944 - val_prob_sparsity_loss: 0.0037 - val_reg_loss_closest: 0.0091 - val_reg_loss_similarity: 0.2323 - val_task_loss: 0.6676\n",
      "Epoch 99/150\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.5557 - avg_concept_size: 0.0000e+00 - avg_features_rec_loss: 0.0000e+00 - avg_mask_rec_loss: 0.0000e+00 - loss: 0.7470 - max_probability: 0.0062 - mean_probability: 7.3121e-04 - min_probability: 3.5581e-05 - prob_sparsity_loss: 0.0037 - reg_loss_closest: 0.0208 - reg_loss_similarity: 0.2325 - task_loss: 0.5315 - val_accuracy: 0.0000e+00 - val_loss: 0.8802 - val_prob_sparsity_loss: 0.0036 - val_reg_loss_closest: 0.0095 - val_reg_loss_similarity: 0.2325 - val_task_loss: 0.6535\n",
      "Epoch 100/150\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.5552 - avg_concept_size: 0.0000e+00 - avg_features_rec_loss: 0.0000e+00 - avg_mask_rec_loss: 0.0000e+00 - loss: 0.7469 - max_probability: 0.0061 - mean_probability: 7.2471e-04 - min_probability: 3.2999e-05 - prob_sparsity_loss: 0.0036 - reg_loss_closest: 0.0209 - reg_loss_similarity: 0.2325 - task_loss: 0.5316 - val_accuracy: 0.0000e+00 - val_loss: 0.8860 - val_prob_sparsity_loss: 0.0036 - val_reg_loss_closest: 0.0090 - val_reg_loss_similarity: 0.2327 - val_task_loss: 0.6587\n",
      "Epoch 101/150\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.5523 - avg_concept_size: 0.0000e+00 - avg_features_rec_loss: 0.0000e+00 - avg_mask_rec_loss: 0.0000e+00 - loss: 0.7472 - max_probability: 0.0060 - mean_probability: 7.1484e-04 - min_probability: 3.0785e-05 - prob_sparsity_loss: 0.0036 - reg_loss_closest: 0.0208 - reg_loss_similarity: 0.2325 - task_loss: 0.5318 - val_accuracy: 0.0000e+00 - val_loss: 0.8845 - val_prob_sparsity_loss: 0.0035 - val_reg_loss_closest: 0.0089 - val_reg_loss_similarity: 0.2326 - val_task_loss: 0.6573\n",
      "Epoch 102/150\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.5538 - avg_concept_size: 0.0000e+00 - avg_features_rec_loss: 0.0000e+00 - avg_mask_rec_loss: 0.0000e+00 - loss: 0.7457 - max_probability: 0.0061 - mean_probability: 7.0856e-04 - min_probability: 2.9370e-05 - prob_sparsity_loss: 0.0035 - reg_loss_closest: 0.0206 - reg_loss_similarity: 0.2325 - task_loss: 0.5303 - val_accuracy: 0.0000e+00 - val_loss: 0.8933 - val_prob_sparsity_loss: 0.0035 - val_reg_loss_closest: 0.0086 - val_reg_loss_similarity: 0.2325 - val_task_loss: 0.6658\n",
      "Epoch 103/150\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.5546 - avg_concept_size: 0.0000e+00 - avg_features_rec_loss: 0.0000e+00 - avg_mask_rec_loss: 0.0000e+00 - loss: 0.7438 - max_probability: 0.0063 - mean_probability: 7.0447e-04 - min_probability: 2.7609e-05 - prob_sparsity_loss: 0.0035 - reg_loss_closest: 0.0214 - reg_loss_similarity: 0.2325 - task_loss: 0.5291 - val_accuracy: 0.0000e+00 - val_loss: 0.9003 - val_prob_sparsity_loss: 0.0035 - val_reg_loss_closest: 0.0096 - val_reg_loss_similarity: 0.2324 - val_task_loss: 0.6740\n",
      "Epoch 104/150\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.5521 - avg_concept_size: 0.0000e+00 - avg_features_rec_loss: 0.0000e+00 - avg_mask_rec_loss: 0.0000e+00 - loss: 0.7458 - max_probability: 0.0064 - mean_probability: 6.9229e-04 - min_probability: 2.5761e-05 - prob_sparsity_loss: 0.0035 - reg_loss_closest: 0.0212 - reg_loss_similarity: 0.2325 - task_loss: 0.5311 - val_accuracy: 0.0000e+00 - val_loss: 0.8868 - val_prob_sparsity_loss: 0.0034 - val_reg_loss_closest: 0.0090 - val_reg_loss_similarity: 0.2326 - val_task_loss: 0.6597\n",
      "Epoch 105/150\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.5569 - avg_concept_size: 0.0000e+00 - avg_features_rec_loss: 0.0000e+00 - avg_mask_rec_loss: 0.0000e+00 - loss: 0.7452 - max_probability: 0.0068 - mean_probability: 6.8590e-04 - min_probability: 2.4440e-05 - prob_sparsity_loss: 0.0034 - reg_loss_closest: 0.0209 - reg_loss_similarity: 0.2325 - task_loss: 0.5301 - val_accuracy: 0.0000e+00 - val_loss: 0.8805 - val_prob_sparsity_loss: 0.0034 - val_reg_loss_closest: 0.0097 - val_reg_loss_similarity: 0.2325 - val_task_loss: 0.6543\n",
      "Epoch 106/150\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.5564 - avg_concept_size: 0.0000e+00 - avg_features_rec_loss: 0.0000e+00 - avg_mask_rec_loss: 0.0000e+00 - loss: 0.7451 - max_probability: 0.0068 - mean_probability: 6.7463e-04 - min_probability: 2.2926e-05 - prob_sparsity_loss: 0.0034 - reg_loss_closest: 0.0214 - reg_loss_similarity: 0.2324 - task_loss: 0.5307 - val_accuracy: 0.0000e+00 - val_loss: 0.8918 - val_prob_sparsity_loss: 0.0033 - val_reg_loss_closest: 0.0090 - val_reg_loss_similarity: 0.2323 - val_task_loss: 0.6652\n",
      "Epoch 107/150\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.5557 - avg_concept_size: 0.0000e+00 - avg_features_rec_loss: 0.0000e+00 - avg_mask_rec_loss: 0.0000e+00 - loss: 0.7452 - max_probability: 0.0069 - mean_probability: 6.6513e-04 - min_probability: 2.1696e-05 - prob_sparsity_loss: 0.0033 - reg_loss_closest: 0.0218 - reg_loss_similarity: 0.2325 - task_loss: 0.5312 - val_accuracy: 0.0000e+00 - val_loss: 0.9081 - val_prob_sparsity_loss: 0.0033 - val_reg_loss_closest: 0.0097 - val_reg_loss_similarity: 0.2323 - val_task_loss: 0.6822\n",
      "Epoch 108/150\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.5546 - avg_concept_size: 0.0000e+00 - avg_features_rec_loss: 0.0000e+00 - avg_mask_rec_loss: 0.0000e+00 - loss: 0.7463 - max_probability: 0.0067 - mean_probability: 6.5239e-04 - min_probability: 2.0327e-05 - prob_sparsity_loss: 0.0033 - reg_loss_closest: 0.0216 - reg_loss_similarity: 0.2326 - task_loss: 0.5320 - val_accuracy: 0.0000e+00 - val_loss: 0.9169 - val_prob_sparsity_loss: 0.0032 - val_reg_loss_closest: 0.0090 - val_reg_loss_similarity: 0.2327 - val_task_loss: 0.6899\n",
      "Epoch 109/150\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - accuracy: 0.5556 - avg_concept_size: 0.0000e+00 - avg_features_rec_loss: 0.0000e+00 - avg_mask_rec_loss: 0.0000e+00 - loss: 0.7443 - max_probability: 0.0069 - mean_probability: 6.4616e-04 - min_probability: 1.9248e-05 - prob_sparsity_loss: 0.0032 - reg_loss_closest: 0.0216 - reg_loss_similarity: 0.2326 - task_loss: 0.5301 - val_accuracy: 0.0000e+00 - val_loss: 0.9079 - val_prob_sparsity_loss: 0.0032 - val_reg_loss_closest: 0.0093 - val_reg_loss_similarity: 0.2325 - val_task_loss: 0.6816\n",
      "Epoch 110/150\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.5568 - avg_concept_size: 0.0000e+00 - avg_features_rec_loss: 0.0000e+00 - avg_mask_rec_loss: 0.0000e+00 - loss: 0.7454 - max_probability: 0.0067 - mean_probability: 6.3154e-04 - min_probability: 1.8237e-05 - prob_sparsity_loss: 0.0032 - reg_loss_closest: 0.0218 - reg_loss_similarity: 0.2326 - task_loss: 0.5314 - val_accuracy: 0.0000e+00 - val_loss: 0.8840 - val_prob_sparsity_loss: 0.0032 - val_reg_loss_closest: 0.0094 - val_reg_loss_similarity: 0.2324 - val_task_loss: 0.6578\n",
      "Epoch 111/150\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.5565 - avg_concept_size: 0.0000e+00 - avg_features_rec_loss: 0.0000e+00 - avg_mask_rec_loss: 0.0000e+00 - loss: 0.7446 - max_probability: 0.0071 - mean_probability: 6.3179e-04 - min_probability: 1.7288e-05 - prob_sparsity_loss: 0.0032 - reg_loss_closest: 0.0217 - reg_loss_similarity: 0.2325 - task_loss: 0.5307 - val_accuracy: 0.0000e+00 - val_loss: 0.9170 - val_prob_sparsity_loss: 0.0031 - val_reg_loss_closest: 0.0092 - val_reg_loss_similarity: 0.2324 - val_task_loss: 0.6906\n",
      "Epoch 112/150\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.5548 - avg_concept_size: 0.0000e+00 - avg_features_rec_loss: 0.0000e+00 - avg_mask_rec_loss: 0.0000e+00 - loss: 0.7420 - max_probability: 0.0070 - mean_probability: 6.2291e-04 - min_probability: 1.6524e-05 - prob_sparsity_loss: 0.0031 - reg_loss_closest: 0.0217 - reg_loss_similarity: 0.2326 - task_loss: 0.5281 - val_accuracy: 0.0000e+00 - val_loss: 0.8827 - val_prob_sparsity_loss: 0.0031 - val_reg_loss_closest: 0.0100 - val_reg_loss_similarity: 0.2330 - val_task_loss: 0.6566\n",
      "Epoch 113/150\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.5540 - avg_concept_size: 0.0000e+00 - avg_features_rec_loss: 0.0000e+00 - avg_mask_rec_loss: 0.0000e+00 - loss: 0.7441 - max_probability: 0.0068 - mean_probability: 6.1165e-04 - min_probability: 1.5541e-05 - prob_sparsity_loss: 0.0031 - reg_loss_closest: 0.0218 - reg_loss_similarity: 0.2326 - task_loss: 0.5303 - val_accuracy: 0.0000e+00 - val_loss: 0.9195 - val_prob_sparsity_loss: 0.0030 - val_reg_loss_closest: 0.0093 - val_reg_loss_similarity: 0.2329 - val_task_loss: 0.6929\n",
      "Epoch 114/150\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.5579 - avg_concept_size: 0.0000e+00 - avg_features_rec_loss: 0.0000e+00 - avg_mask_rec_loss: 0.0000e+00 - loss: 0.7430 - max_probability: 0.0067 - mean_probability: 6.0323e-04 - min_probability: 1.4870e-05 - prob_sparsity_loss: 0.0030 - reg_loss_closest: 0.0216 - reg_loss_similarity: 0.2325 - task_loss: 0.5290 - val_accuracy: 0.0000e+00 - val_loss: 0.8786 - val_prob_sparsity_loss: 0.0030 - val_reg_loss_closest: 0.0097 - val_reg_loss_similarity: 0.2328 - val_task_loss: 0.6526\n",
      "Epoch 115/150\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.5569 - avg_concept_size: 0.0000e+00 - avg_features_rec_loss: 0.0000e+00 - avg_mask_rec_loss: 0.0000e+00 - loss: 0.7444 - max_probability: 0.0066 - mean_probability: 5.9341e-04 - min_probability: 1.4270e-05 - prob_sparsity_loss: 0.0030 - reg_loss_closest: 0.0216 - reg_loss_similarity: 0.2325 - task_loss: 0.5305 - val_accuracy: 0.0000e+00 - val_loss: 0.8957 - val_prob_sparsity_loss: 0.0030 - val_reg_loss_closest: 0.0099 - val_reg_loss_similarity: 0.2323 - val_task_loss: 0.6704\n",
      "Epoch 116/150\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.5568 - avg_concept_size: 0.0000e+00 - avg_features_rec_loss: 0.0000e+00 - avg_mask_rec_loss: 0.0000e+00 - loss: 0.7432 - max_probability: 0.0067 - mean_probability: 5.8751e-04 - min_probability: 1.3610e-05 - prob_sparsity_loss: 0.0029 - reg_loss_closest: 0.0220 - reg_loss_similarity: 0.2325 - task_loss: 0.5298 - val_accuracy: 0.0000e+00 - val_loss: 0.8883 - val_prob_sparsity_loss: 0.0029 - val_reg_loss_closest: 0.0103 - val_reg_loss_similarity: 0.2325 - val_task_loss: 0.6632\n",
      "Epoch 117/150\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.5592 - avg_concept_size: 0.0000e+00 - avg_features_rec_loss: 0.0000e+00 - avg_mask_rec_loss: 0.0000e+00 - loss: 0.7431 - max_probability: 0.0065 - mean_probability: 5.7899e-04 - min_probability: 1.2993e-05 - prob_sparsity_loss: 0.0029 - reg_loss_closest: 0.0220 - reg_loss_similarity: 0.2325 - task_loss: 0.5297 - val_accuracy: 0.0000e+00 - val_loss: 0.8757 - val_prob_sparsity_loss: 0.0029 - val_reg_loss_closest: 0.0098 - val_reg_loss_similarity: 0.2326 - val_task_loss: 0.6500\n",
      "Epoch 118/150\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.5579 - avg_concept_size: 0.0000e+00 - avg_features_rec_loss: 0.0000e+00 - avg_mask_rec_loss: 0.0000e+00 - loss: 0.7432 - max_probability: 0.0063 - mean_probability: 5.6912e-04 - min_probability: 1.2293e-05 - prob_sparsity_loss: 0.0028 - reg_loss_closest: 0.0219 - reg_loss_similarity: 0.2326 - task_loss: 0.5297 - val_accuracy: 0.0000e+00 - val_loss: 0.8827 - val_prob_sparsity_loss: 0.0028 - val_reg_loss_closest: 0.0099 - val_reg_loss_similarity: 0.2327 - val_task_loss: 0.6572\n",
      "Epoch 119/150\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.5563 - avg_concept_size: 0.0000e+00 - avg_features_rec_loss: 0.0000e+00 - avg_mask_rec_loss: 0.0000e+00 - loss: 0.7445 - max_probability: 0.0061 - mean_probability: 5.5991e-04 - min_probability: 1.1564e-05 - prob_sparsity_loss: 0.0028 - reg_loss_closest: 0.0217 - reg_loss_similarity: 0.2327 - task_loss: 0.5307 - val_accuracy: 0.0000e+00 - val_loss: 0.8837 - val_prob_sparsity_loss: 0.0028 - val_reg_loss_closest: 0.0099 - val_reg_loss_similarity: 0.2323 - val_task_loss: 0.6586\n",
      "Epoch 120/150\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.5557 - avg_concept_size: 0.0000e+00 - avg_features_rec_loss: 0.0000e+00 - avg_mask_rec_loss: 0.0000e+00 - loss: 0.7445 - max_probability: 0.0061 - mean_probability: 5.5277e-04 - min_probability: 1.1057e-05 - prob_sparsity_loss: 0.0028 - reg_loss_closest: 0.0221 - reg_loss_similarity: 0.2324 - task_loss: 0.5315 - val_accuracy: 0.0000e+00 - val_loss: 0.8979 - val_prob_sparsity_loss: 0.0027 - val_reg_loss_closest: 0.0098 - val_reg_loss_similarity: 0.2326 - val_task_loss: 0.6723\n",
      "Epoch 121/150\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.5562 - avg_concept_size: 0.0000e+00 - avg_features_rec_loss: 0.0000e+00 - avg_mask_rec_loss: 0.0000e+00 - loss: 0.7443 - max_probability: 0.0060 - mean_probability: 5.4290e-04 - min_probability: 1.0436e-05 - prob_sparsity_loss: 0.0027 - reg_loss_closest: 0.0220 - reg_loss_similarity: 0.2325 - task_loss: 0.5311 - val_accuracy: 0.0000e+00 - val_loss: 0.8754 - val_prob_sparsity_loss: 0.0027 - val_reg_loss_closest: 0.0100 - val_reg_loss_similarity: 0.2326 - val_task_loss: 0.6501\n",
      "Epoch 122/150\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.5545 - avg_concept_size: 0.0000e+00 - avg_features_rec_loss: 0.0000e+00 - avg_mask_rec_loss: 0.0000e+00 - loss: 0.7445 - max_probability: 0.0060 - mean_probability: 5.3717e-04 - min_probability: 9.8588e-06 - prob_sparsity_loss: 0.0027 - reg_loss_closest: 0.0220 - reg_loss_similarity: 0.2325 - task_loss: 0.5313 - val_accuracy: 0.0000e+00 - val_loss: 0.8662 - val_prob_sparsity_loss: 0.0026 - val_reg_loss_closest: 0.0099 - val_reg_loss_similarity: 0.2325 - val_task_loss: 0.6409\n",
      "Epoch 123/150\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.5550 - avg_concept_size: 0.0000e+00 - avg_features_rec_loss: 0.0000e+00 - avg_mask_rec_loss: 0.0000e+00 - loss: 0.7435 - max_probability: 0.0059 - mean_probability: 5.2822e-04 - min_probability: 9.3976e-06 - prob_sparsity_loss: 0.0026 - reg_loss_closest: 0.0220 - reg_loss_similarity: 0.2325 - task_loss: 0.5304 - val_accuracy: 0.0000e+00 - val_loss: 0.8823 - val_prob_sparsity_loss: 0.0026 - val_reg_loss_closest: 0.0101 - val_reg_loss_similarity: 0.2323 - val_task_loss: 0.6575\n",
      "Epoch 124/150\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.5579 - avg_concept_size: 0.0000e+00 - avg_features_rec_loss: 0.0000e+00 - avg_mask_rec_loss: 0.0000e+00 - loss: 0.7434 - max_probability: 0.0058 - mean_probability: 5.2091e-04 - min_probability: 8.9740e-06 - prob_sparsity_loss: 0.0026 - reg_loss_closest: 0.0219 - reg_loss_similarity: 0.2324 - task_loss: 0.5302 - val_accuracy: 0.0000e+00 - val_loss: 0.8642 - val_prob_sparsity_loss: 0.0026 - val_reg_loss_closest: 0.0105 - val_reg_loss_similarity: 0.2327 - val_task_loss: 0.6393\n",
      "Epoch 125/150\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.5574 - avg_concept_size: 0.0000e+00 - avg_features_rec_loss: 0.0000e+00 - avg_mask_rec_loss: 0.0000e+00 - loss: 0.7452 - max_probability: 0.0059 - mean_probability: 5.1934e-04 - min_probability: 8.7287e-06 - prob_sparsity_loss: 0.0026 - reg_loss_closest: 0.0220 - reg_loss_similarity: 0.2325 - task_loss: 0.5322 - val_accuracy: 0.0000e+00 - val_loss: 0.9126 - val_prob_sparsity_loss: 0.0026 - val_reg_loss_closest: 0.0098 - val_reg_loss_similarity: 0.2325 - val_task_loss: 0.6873\n",
      "Epoch 126/150\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.5574 - avg_concept_size: 0.0000e+00 - avg_features_rec_loss: 0.0000e+00 - avg_mask_rec_loss: 0.0000e+00 - loss: 0.7438 - max_probability: 0.0059 - mean_probability: 5.1277e-04 - min_probability: 8.5543e-06 - prob_sparsity_loss: 0.0026 - reg_loss_closest: 0.0220 - reg_loss_similarity: 0.2326 - task_loss: 0.5308 - val_accuracy: 0.0000e+00 - val_loss: 0.8805 - val_prob_sparsity_loss: 0.0026 - val_reg_loss_closest: 0.0096 - val_reg_loss_similarity: 0.2327 - val_task_loss: 0.6548\n",
      "Epoch 127/150\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.5560 - avg_concept_size: 0.0000e+00 - avg_features_rec_loss: 0.0000e+00 - avg_mask_rec_loss: 0.0000e+00 - loss: 0.7440 - max_probability: 0.0060 - mean_probability: 5.1815e-04 - min_probability: 8.0519e-06 - prob_sparsity_loss: 0.0026 - reg_loss_closest: 0.0219 - reg_loss_similarity: 0.2326 - task_loss: 0.5307 - val_accuracy: 0.0000e+00 - val_loss: 0.8903 - val_prob_sparsity_loss: 0.0026 - val_reg_loss_closest: 0.0102 - val_reg_loss_similarity: 0.2328 - val_task_loss: 0.6651\n",
      "Epoch 128/150\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.5542 - avg_concept_size: 0.0000e+00 - avg_features_rec_loss: 0.0000e+00 - avg_mask_rec_loss: 0.0000e+00 - loss: 0.7452 - max_probability: 0.0059 - mean_probability: 5.1396e-04 - min_probability: 7.9040e-06 - prob_sparsity_loss: 0.0026 - reg_loss_closest: 0.0223 - reg_loss_similarity: 0.2326 - task_loss: 0.5323 - val_accuracy: 0.0000e+00 - val_loss: 0.9008 - val_prob_sparsity_loss: 0.0026 - val_reg_loss_closest: 0.0093 - val_reg_loss_similarity: 0.2324 - val_task_loss: 0.6751\n",
      "Epoch 129/150\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.5568 - avg_concept_size: 0.0000e+00 - avg_features_rec_loss: 0.0000e+00 - avg_mask_rec_loss: 0.0000e+00 - loss: 0.7463 - max_probability: 0.0060 - mean_probability: 5.0976e-04 - min_probability: 7.6059e-06 - prob_sparsity_loss: 0.0025 - reg_loss_closest: 0.0217 - reg_loss_similarity: 0.2324 - task_loss: 0.5331 - val_accuracy: 0.0000e+00 - val_loss: 0.8749 - val_prob_sparsity_loss: 0.0025 - val_reg_loss_closest: 0.0103 - val_reg_loss_similarity: 0.2327 - val_task_loss: 0.6501\n",
      "Epoch 130/150\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.5544 - avg_concept_size: 0.0000e+00 - avg_features_rec_loss: 0.0000e+00 - avg_mask_rec_loss: 0.0000e+00 - loss: 0.7444 - max_probability: 0.0059 - mean_probability: 5.0106e-04 - min_probability: 7.4161e-06 - prob_sparsity_loss: 0.0025 - reg_loss_closest: 0.0224 - reg_loss_similarity: 0.2324 - task_loss: 0.5319 - val_accuracy: 0.0000e+00 - val_loss: 0.8943 - val_prob_sparsity_loss: 0.0025 - val_reg_loss_closest: 0.0096 - val_reg_loss_similarity: 0.2325 - val_task_loss: 0.6689\n",
      "Epoch 131/150\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.5585 - avg_concept_size: 0.0000e+00 - avg_features_rec_loss: 0.0000e+00 - avg_mask_rec_loss: 0.0000e+00 - loss: 0.7414 - max_probability: 0.0059 - mean_probability: 4.9215e-04 - min_probability: 7.1460e-06 - prob_sparsity_loss: 0.0025 - reg_loss_closest: 0.0224 - reg_loss_similarity: 0.2324 - task_loss: 0.5290 - val_accuracy: 0.0000e+00 - val_loss: 0.8816 - val_prob_sparsity_loss: 0.0024 - val_reg_loss_closest: 0.0102 - val_reg_loss_similarity: 0.2326 - val_task_loss: 0.6567\n",
      "Epoch 132/150\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.5585 - avg_concept_size: 0.0000e+00 - avg_features_rec_loss: 0.0000e+00 - avg_mask_rec_loss: 0.0000e+00 - loss: 0.7420 - max_probability: 0.0059 - mean_probability: 4.8383e-04 - min_probability: 6.9021e-06 - prob_sparsity_loss: 0.0024 - reg_loss_closest: 0.0220 - reg_loss_similarity: 0.2325 - task_loss: 0.5291 - val_accuracy: 0.0000e+00 - val_loss: 0.8735 - val_prob_sparsity_loss: 0.0024 - val_reg_loss_closest: 0.0099 - val_reg_loss_similarity: 0.2323 - val_task_loss: 0.6487\n",
      "Epoch 133/150\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.5564 - avg_concept_size: 0.0000e+00 - avg_features_rec_loss: 0.0000e+00 - avg_mask_rec_loss: 0.0000e+00 - loss: 0.7441 - max_probability: 0.0060 - mean_probability: 4.8092e-04 - min_probability: 6.6172e-06 - prob_sparsity_loss: 0.0024 - reg_loss_closest: 0.0222 - reg_loss_similarity: 0.2326 - task_loss: 0.5314 - val_accuracy: 0.0000e+00 - val_loss: 0.8885 - val_prob_sparsity_loss: 0.0024 - val_reg_loss_closest: 0.0102 - val_reg_loss_similarity: 0.2326 - val_task_loss: 0.6637\n",
      "Epoch 134/150\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.5563 - avg_concept_size: 0.0000e+00 - avg_features_rec_loss: 0.0000e+00 - avg_mask_rec_loss: 0.0000e+00 - loss: 0.7435 - max_probability: 0.0060 - mean_probability: 4.7434e-04 - min_probability: 6.5104e-06 - prob_sparsity_loss: 0.0024 - reg_loss_closest: 0.0223 - reg_loss_similarity: 0.2325 - task_loss: 0.5310 - val_accuracy: 0.0000e+00 - val_loss: 0.8653 - val_prob_sparsity_loss: 0.0024 - val_reg_loss_closest: 0.0100 - val_reg_loss_similarity: 0.2322 - val_task_loss: 0.6408\n",
      "Epoch 135/150\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.5553 - avg_concept_size: 0.0000e+00 - avg_features_rec_loss: 0.0000e+00 - avg_mask_rec_loss: 0.0000e+00 - loss: 0.7422 - max_probability: 0.0060 - mean_probability: 4.6878e-04 - min_probability: 6.2391e-06 - prob_sparsity_loss: 0.0023 - reg_loss_closest: 0.0224 - reg_loss_similarity: 0.2324 - task_loss: 0.5299 - val_accuracy: 0.0000e+00 - val_loss: 0.8889 - val_prob_sparsity_loss: 0.0023 - val_reg_loss_closest: 0.0097 - val_reg_loss_similarity: 0.2324 - val_task_loss: 0.6639\n",
      "Epoch 136/150\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.5548 - avg_concept_size: 0.0000e+00 - avg_features_rec_loss: 0.0000e+00 - avg_mask_rec_loss: 0.0000e+00 - loss: 0.7434 - max_probability: 0.0060 - mean_probability: 4.6098e-04 - min_probability: 6.0191e-06 - prob_sparsity_loss: 0.0023 - reg_loss_closest: 0.0222 - reg_loss_similarity: 0.2324 - task_loss: 0.5309 - val_accuracy: 0.0000e+00 - val_loss: 0.8984 - val_prob_sparsity_loss: 0.0023 - val_reg_loss_closest: 0.0101 - val_reg_loss_similarity: 0.2323 - val_task_loss: 0.6739\n",
      "Epoch 137/150\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.5557 - avg_concept_size: 0.0000e+00 - avg_features_rec_loss: 0.0000e+00 - avg_mask_rec_loss: 0.0000e+00 - loss: 0.7411 - max_probability: 0.0060 - mean_probability: 4.5692e-04 - min_probability: 5.8078e-06 - prob_sparsity_loss: 0.0023 - reg_loss_closest: 0.0225 - reg_loss_similarity: 0.2324 - task_loss: 0.5289 - val_accuracy: 0.0000e+00 - val_loss: 0.8838 - val_prob_sparsity_loss: 0.0023 - val_reg_loss_closest: 0.0101 - val_reg_loss_similarity: 0.2321 - val_task_loss: 0.6595\n",
      "Epoch 138/150\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.5580 - avg_concept_size: 0.0000e+00 - avg_features_rec_loss: 0.0000e+00 - avg_mask_rec_loss: 0.0000e+00 - loss: 0.7426 - max_probability: 0.0061 - mean_probability: 4.5420e-04 - min_probability: 5.5305e-06 - prob_sparsity_loss: 0.0023 - reg_loss_closest: 0.0219 - reg_loss_similarity: 0.2323 - task_loss: 0.5300 - val_accuracy: 0.0000e+00 - val_loss: 0.8714 - val_prob_sparsity_loss: 0.0023 - val_reg_loss_closest: 0.0100 - val_reg_loss_similarity: 0.2324 - val_task_loss: 0.6467\n",
      "Epoch 139/150\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.5572 - avg_concept_size: 0.0000e+00 - avg_features_rec_loss: 0.0000e+00 - avg_mask_rec_loss: 0.0000e+00 - loss: 0.7428 - max_probability: 0.0062 - mean_probability: 4.5588e-04 - min_probability: 5.3048e-06 - prob_sparsity_loss: 0.0023 - reg_loss_closest: 0.0224 - reg_loss_similarity: 0.2324 - task_loss: 0.5306 - val_accuracy: 0.0000e+00 - val_loss: 0.8732 - val_prob_sparsity_loss: 0.0023 - val_reg_loss_closest: 0.0097 - val_reg_loss_similarity: 0.2323 - val_task_loss: 0.6483\n",
      "Epoch 140/150\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.5522 - avg_concept_size: 0.0000e+00 - avg_features_rec_loss: 0.0000e+00 - avg_mask_rec_loss: 0.0000e+00 - loss: 0.7439 - max_probability: 0.0063 - mean_probability: 4.5395e-04 - min_probability: 5.0789e-06 - prob_sparsity_loss: 0.0023 - reg_loss_closest: 0.0224 - reg_loss_similarity: 0.2324 - task_loss: 0.5317 - val_accuracy: 0.0000e+00 - val_loss: 0.9022 - val_prob_sparsity_loss: 0.0023 - val_reg_loss_closest: 0.0107 - val_reg_loss_similarity: 0.2323 - val_task_loss: 0.6783\n",
      "Epoch 141/150\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.5550 - avg_concept_size: 0.0000e+00 - avg_features_rec_loss: 0.0000e+00 - avg_mask_rec_loss: 0.0000e+00 - loss: 0.7441 - max_probability: 0.0064 - mean_probability: 4.5256e-04 - min_probability: 4.9955e-06 - prob_sparsity_loss: 0.0023 - reg_loss_closest: 0.0226 - reg_loss_similarity: 0.2324 - task_loss: 0.5321 - val_accuracy: 0.0000e+00 - val_loss: 0.9119 - val_prob_sparsity_loss: 0.0022 - val_reg_loss_closest: 0.0103 - val_reg_loss_similarity: 0.2327 - val_task_loss: 0.6873\n",
      "Epoch 142/150\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.5578 - avg_concept_size: 0.0000e+00 - avg_features_rec_loss: 0.0000e+00 - avg_mask_rec_loss: 0.0000e+00 - loss: 0.7431 - max_probability: 0.0064 - mean_probability: 4.4905e-04 - min_probability: 4.8194e-06 - prob_sparsity_loss: 0.0022 - reg_loss_closest: 0.0225 - reg_loss_similarity: 0.2324 - task_loss: 0.5309 - val_accuracy: 0.0000e+00 - val_loss: 0.8950 - val_prob_sparsity_loss: 0.0022 - val_reg_loss_closest: 0.0106 - val_reg_loss_similarity: 0.2323 - val_task_loss: 0.6710\n",
      "Epoch 143/150\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.5561 - avg_concept_size: 0.0000e+00 - avg_features_rec_loss: 0.0000e+00 - avg_mask_rec_loss: 0.0000e+00 - loss: 0.7424 - max_probability: 0.0064 - mean_probability: 4.4431e-04 - min_probability: 4.5629e-06 - prob_sparsity_loss: 0.0022 - reg_loss_closest: 0.0225 - reg_loss_similarity: 0.2324 - task_loss: 0.5303 - val_accuracy: 0.0000e+00 - val_loss: 0.9202 - val_prob_sparsity_loss: 0.0022 - val_reg_loss_closest: 0.0099 - val_reg_loss_similarity: 0.2324 - val_task_loss: 0.6954\n",
      "Epoch 144/150\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.5571 - avg_concept_size: 0.0000e+00 - avg_features_rec_loss: 0.0000e+00 - avg_mask_rec_loss: 0.0000e+00 - loss: 0.7430 - max_probability: 0.0065 - mean_probability: 4.4975e-04 - min_probability: 4.3778e-06 - prob_sparsity_loss: 0.0022 - reg_loss_closest: 0.0221 - reg_loss_similarity: 0.2324 - task_loss: 0.5304 - val_accuracy: 0.0000e+00 - val_loss: 0.8789 - val_prob_sparsity_loss: 0.0023 - val_reg_loss_closest: 0.0108 - val_reg_loss_similarity: 0.2327 - val_task_loss: 0.6547\n",
      "Epoch 145/150\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.5559 - avg_concept_size: 0.0000e+00 - avg_features_rec_loss: 0.0000e+00 - avg_mask_rec_loss: 0.0000e+00 - loss: 0.7433 - max_probability: 0.0066 - mean_probability: 4.5101e-04 - min_probability: 4.2064e-06 - prob_sparsity_loss: 0.0023 - reg_loss_closest: 0.0226 - reg_loss_similarity: 0.2325 - task_loss: 0.5312 - val_accuracy: 0.0000e+00 - val_loss: 0.8733 - val_prob_sparsity_loss: 0.0022 - val_reg_loss_closest: 0.0102 - val_reg_loss_similarity: 0.2324 - val_task_loss: 0.6488\n",
      "Epoch 146/150\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.5571 - avg_concept_size: 0.0000e+00 - avg_features_rec_loss: 0.0000e+00 - avg_mask_rec_loss: 0.0000e+00 - loss: 0.7431 - max_probability: 0.0067 - mean_probability: 4.4674e-04 - min_probability: 4.0781e-06 - prob_sparsity_loss: 0.0022 - reg_loss_closest: 0.0223 - reg_loss_similarity: 0.2324 - task_loss: 0.5307 - val_accuracy: 0.0000e+00 - val_loss: 0.8628 - val_prob_sparsity_loss: 0.0022 - val_reg_loss_closest: 0.0105 - val_reg_loss_similarity: 0.2325 - val_task_loss: 0.6385\n",
      "Epoch 147/150\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.5555 - avg_concept_size: 0.0000e+00 - avg_features_rec_loss: 0.0000e+00 - avg_mask_rec_loss: 0.0000e+00 - loss: 0.7438 - max_probability: 0.0067 - mean_probability: 4.4343e-04 - min_probability: 4.0072e-06 - prob_sparsity_loss: 0.0022 - reg_loss_closest: 0.0226 - reg_loss_similarity: 0.2324 - task_loss: 0.5317 - val_accuracy: 0.0000e+00 - val_loss: 0.8889 - val_prob_sparsity_loss: 0.0022 - val_reg_loss_closest: 0.0106 - val_reg_loss_similarity: 0.2326 - val_task_loss: 0.6647\n",
      "Epoch 148/150\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.5545 - avg_concept_size: 0.0000e+00 - avg_features_rec_loss: 0.0000e+00 - avg_mask_rec_loss: 0.0000e+00 - loss: 0.7417 - max_probability: 0.0066 - mean_probability: 4.4086e-04 - min_probability: 3.8476e-06 - prob_sparsity_loss: 0.0022 - reg_loss_closest: 0.0229 - reg_loss_similarity: 0.2325 - task_loss: 0.5298 - val_accuracy: 0.0000e+00 - val_loss: 0.8867 - val_prob_sparsity_loss: 0.0022 - val_reg_loss_closest: 0.0102 - val_reg_loss_similarity: 0.2325 - val_task_loss: 0.6622\n",
      "Epoch 149/150\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.5541 - avg_concept_size: 0.0000e+00 - avg_features_rec_loss: 0.0000e+00 - avg_mask_rec_loss: 0.0000e+00 - loss: 0.7420 - max_probability: 0.0066 - mean_probability: 4.3434e-04 - min_probability: 3.7103e-06 - prob_sparsity_loss: 0.0022 - reg_loss_closest: 0.0228 - reg_loss_similarity: 0.2324 - task_loss: 0.5302 - val_accuracy: 0.0000e+00 - val_loss: 0.8948 - val_prob_sparsity_loss: 0.0022 - val_reg_loss_closest: 0.0105 - val_reg_loss_similarity: 0.2323 - val_task_loss: 0.6708\n",
      "Epoch 150/150\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.5570 - avg_concept_size: 0.0000e+00 - avg_features_rec_loss: 0.0000e+00 - avg_mask_rec_loss: 0.0000e+00 - loss: 0.7422 - max_probability: 0.0067 - mean_probability: 4.3417e-04 - min_probability: 3.6073e-06 - prob_sparsity_loss: 0.0022 - reg_loss_closest: 0.0229 - reg_loss_similarity: 0.2324 - task_loss: 0.5304 - val_accuracy: 0.0000e+00 - val_loss: 0.8947 - val_prob_sparsity_loss: 0.0022 - val_reg_loss_closest: 0.0106 - val_reg_loss_similarity: 0.2323 - val_task_loss: 0.6708\n",
      "\tTabCBM supervised training completed\n"
     ]
    }
   ],
   "source": [
    "max_epochs = 150   \n",
    "print(\"TabCBM self-supervised training stage...\")\n",
    "\n",
    "tabcbm_hist = tabcbm_supervised.fit(\n",
    "    x=x_train,\n",
    "    y=y_train,\n",
    "    validation_split=validation_size,\n",
    "    epochs=max_epochs,\n",
    "    batch_size=batch_size,\n",
    "    verbose=1,\n",
    ")\n",
    "\n",
    "print(\"\\tTabCBM supervised training completed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate TabCBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step\n"
     ]
    }
   ],
   "source": [
    "test_y_pred, test_concept_scores = tabcbm_supervised.predict(x_test, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is 69.97%\n"
     ]
    }
   ],
   "source": [
    "if np.min(test_y_pred) < 0.0 or np.max(test_y_pred) > 1:\n",
    "        # Then we assume that we have outputed logits\n",
    "        test_preds = tf.math.sigmoid(test_y_pred).numpy()\n",
    "        \n",
    "test_preds = (test_preds > 0.5).astype(np.int32)\n",
    "results['acc'] = sklearn.metrics.accuracy_score(\n",
    "    y_test,\n",
    "    test_preds,\n",
    ")\n",
    "results['auc'] = sklearn.metrics.roc_auc_score(\n",
    "    y_test,\n",
    "    test_preds,\n",
    ")\n",
    "\n",
    "print(f\"Accuracy is {results['acc']*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_concept_scores_df = pd.DataFrame(test_concept_scores, columns=list(aggregated_concepts.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the concept scores:  (51830, 6)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize concept scores\n",
    "\n",
    "print('Shape of the concept scores: ', test_concept_scores.shape)\n",
    "\n",
    "concept_scores_avg = test_concept_scores.mean(axis=0)\n",
    "concept_scores_var = test_concept_scores.std(axis=0)\n",
    "\n",
    "ax = sns.barplot(test_concept_scores_df, estimator='mean', errorbar='sd',\n",
    "                 err_kws={\"color\": \".3\", \"linewidth\": 1.5}, capsize=.1, legend=False)\n",
    "\n",
    "ax.set(xlabel='Concepts', ylabel='Concept scores')\n",
    "plt.savefig(f'tabcbm_test_concept_scores_k{n_concepts}', dpi=300)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison of the calculated and ground-truth masks "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features that correspond to the defined concepts:\n",
      "\n",
      "\t Shipment: ['Type_CASH', 'Type_DEBIT', 'Type_PAYMENT', 'Type_TRANSFER', 'Days for shipment (scheduled)', 'Shipping Mode_First Class', 'Shipping Mode_Same Day', 'Shipping Mode_Second Class', 'Shipping Mode_Standard Class']\n",
      "\t Customer: ['Customer Zipcode', 'Customer Segment_Consumer', 'Customer Segment_Corporate', 'Customer Segment_Home Office']\n",
      "\t Department: ['Department Name', 'Market_Africa', 'Market_Europe', 'Market_LATAM', 'Market_Pacific Asia', 'Market_USCA']\n",
      "\t Store: ['Store Latitude', 'Store Longitude']\n",
      "\t Order: ['Order Id', 'Order Profit Per Order', 'Order Status_CLOSED', 'Order Status_COMPLETE', 'Order Status_ON_HOLD', 'Order Status_PAYMENT_REVIEW', 'Order Status_PENDING', 'Order Status_PENDING_PAYMENT', 'Order Status_PROCESSING', 'Sales', 'Order Item Discount', 'order_year', 'order_month', 'order_day']\n",
      "\t ProductCategory: ['Category Name']\n",
      "\n",
      "Thresholded concept masks learnt by TabCBM:\n",
      "\tFor concept 0 we are selecting the following features [1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 1 1 1 0 1 0 0 0 0\n",
      " 0]\n",
      "\tThe folllowing features are masked by the model: \n",
      "\t ['Days for shipment (scheduled)', 'Type_TRANSFER', 'Shipping Mode_First Class', 'Shipping Mode_Same Day', 'Shipping Mode_Second Class', 'Shipping Mode_Standard Class', 'Order Status_COMPLETE'] \n",
      "\n",
      "\tFor concept 1 we are selecting the following features [1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 0 0 0 0 0 0\n",
      " 0]\n",
      "\tThe folllowing features are masked by the model: \n",
      "\t ['Days for shipment (scheduled)', 'Shipping Mode_First Class', 'Shipping Mode_Same Day', 'Shipping Mode_Second Class', 'Shipping Mode_Standard Class'] \n",
      "\n",
      "\tFor concept 2 we are selecting the following features [1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 1 1 1 0 1 0 0 0 0\n",
      " 0]\n",
      "\tThe folllowing features are masked by the model: \n",
      "\t ['Days for shipment (scheduled)', 'Type_TRANSFER', 'Shipping Mode_First Class', 'Shipping Mode_Same Day', 'Shipping Mode_Second Class', 'Shipping Mode_Standard Class', 'Order Status_COMPLETE'] \n",
      "\n",
      "\tFor concept 3 we are selecting the following features [0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 1 1 1 0 0 0 0 0 0 0\n",
      " 0]\n",
      "\tThe folllowing features are masked by the model: \n",
      "\t ['Customer Zipcode', 'Store Longitude', 'Customer Segment_Consumer', 'Market_Europe', 'Shipping Mode_First Class', 'Shipping Mode_Same Day', 'Shipping Mode_Second Class'] \n",
      "\n",
      "\tFor concept 4 we are selecting the following features [0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 1 1 0 0 1 0 0 0 1 0 0 1 1 1 0 0 0 0 0 0 1\n",
      " 0]\n",
      "\tThe folllowing features are masked by the model: \n",
      "\t ['Order Id', 'order_year', 'Type_DEBIT', 'Type_PAYMENT', 'Customer Segment_Corporate', 'Market_LATAM', 'Shipping Mode_First Class', 'Shipping Mode_Same Day', 'Shipping Mode_Second Class', 'Order Status_PENDING_PAYMENT'] \n",
      "\n",
      "\tFor concept 5 we are selecting the following features [0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 1 1 1 0 0 0 0 0 0 0\n",
      " 0]\n",
      "\tThe folllowing features are masked by the model: \n",
      "\t ['Customer Zipcode', 'Store Longitude', 'Customer Segment_Consumer', 'Market_Europe', 'Shipping Mode_First Class', 'Shipping Mode_Same Day', 'Shipping Mode_Second Class'] \n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "For comparison, the ground truth concept masks are\n",
      "\tFor GROUND-TRUTH concept 0  the following features are relevant\n",
      "\t [1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 0 0 0 0 0 0\n",
      " 0]\n",
      "\tFor GROUND-TRUTH concept 1  the following features are relevant\n",
      "\t [0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0]\n",
      "\tFor GROUND-TRUTH concept 2  the following features are relevant\n",
      "\t [0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0]\n",
      "\tFor GROUND-TRUTH concept 3  the following features are relevant\n",
      "\t [0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0]\n",
      "\tFor GROUND-TRUTH concept 4  the following features are relevant\n",
      "\t [0 0 0 0 0 0 1 1 1 1 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1\n",
      " 1]\n",
      "\tFor GROUND-TRUTH concept 5  the following features are relevant\n",
      "\t [0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0]\n"
     ]
    }
   ],
   "source": [
    "# The masks are stored as logits, so we need to turn them to probabilities using\n",
    "# a sigmoid\n",
    "masks = tf.sigmoid(tabcbm_supervised.feature_probabilities).numpy()\n",
    "\n",
    "print('Features that correspond to the defined concepts:\\n')\n",
    "for concept, features in extended_concepts.items():\n",
    "    print('\\t', f'{concept}: {features}' )\n",
    "\n",
    "print(\"\\nThresholded concept masks learnt by TabCBM:\")\n",
    "for i, mask in enumerate((masks>0.0005).astype(np.int32)):\n",
    "    print(\"\\tFor concept\", i, \"we are selecting the following features\", mask)\n",
    "    print(\"\\tThe folllowing features are masked by the model: \\n\\t\", [feature for feature, flag in zip(x_train_std.columns, mask) if flag == 1], \"\\n\" )\n",
    "   \n",
    "print(\"-\" * 80)\n",
    "print(\"-\" * 80)\n",
    "print(\"For comparison, the ground truth concept masks are\")\n",
    "for i, mask in enumerate(concepts_masks.to_numpy()):\n",
    "    print(\"\\tFor GROUND-TRUTH concept\", i, \" the following features are relevant\\n\\t\", mask)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features that correspond to the defined concepts:\n",
      "\n",
      "Shipment: ['Type_CASH', 'Type_DEBIT', 'Type_PAYMENT', 'Type_TRANSFER', 'Days for shipment (scheduled)', 'Shipping Mode_First Class', 'Shipping Mode_Same Day', 'Shipping Mode_Second Class', 'Shipping Mode_Standard Class']\n",
      "Customer: ['Customer Zipcode', 'Customer Segment_Consumer', 'Customer Segment_Corporate', 'Customer Segment_Home Office']\n",
      "Department: ['Department Name', 'Market_Africa', 'Market_Europe', 'Market_LATAM', 'Market_Pacific Asia', 'Market_USCA']\n",
      "Store: ['Store Latitude', 'Store Longitude']\n",
      "Order: ['Order Id', 'Order Profit Per Order', 'Order Status_CLOSED', 'Order Status_COMPLETE', 'Order Status_ON_HOLD', 'Order Status_PAYMENT_REVIEW', 'Order Status_PENDING', 'Order Status_PENDING_PAYMENT', 'Order Status_PROCESSING', 'Sales', 'Order Item Discount', 'order_year', 'order_month', 'order_day']\n",
      "ProductCategory: ['Category Name']\n",
      "\n",
      "Thresholded concept masks learnt by TabCBM:\n",
      "\tFor concept 0 we are selecting the following features [1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 1 1 1 0 1 0 0 0 0\n",
      " 0]\n",
      "\t ['Days for shipment (scheduled)', 'Type_TRANSFER', 'Shipping Mode_First Class', 'Shipping Mode_Same Day', 'Shipping Mode_Second Class', 'Shipping Mode_Standard Class', 'Order Status_COMPLETE'] \n",
      "\n",
      "\tFor concept 1 we are selecting the following features [1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 0 0 0 0 0 0\n",
      " 0]\n",
      "\t ['Days for shipment (scheduled)', 'Shipping Mode_First Class', 'Shipping Mode_Same Day', 'Shipping Mode_Second Class', 'Shipping Mode_Standard Class'] \n",
      "\n",
      "\tFor concept 2 we are selecting the following features [1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 1 1 1 0 1 0 0 0 0\n",
      " 0]\n",
      "\t ['Days for shipment (scheduled)', 'Type_TRANSFER', 'Shipping Mode_First Class', 'Shipping Mode_Same Day', 'Shipping Mode_Second Class', 'Shipping Mode_Standard Class', 'Order Status_COMPLETE'] \n",
      "\n",
      "\tFor concept 3 we are selecting the following features [0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 1 1 1 0 0 0 0 0 0 0\n",
      " 0]\n",
      "\t ['Customer Zipcode', 'Store Longitude', 'Customer Segment_Consumer', 'Market_Europe', 'Shipping Mode_First Class', 'Shipping Mode_Same Day', 'Shipping Mode_Second Class'] \n",
      "\n",
      "\tFor concept 4 we are selecting the following features [0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 1 1 0 0 1 0 0 0 1 0 0 1 1 1 0 0 0 0 0 0 1\n",
      " 0]\n",
      "\t ['Order Id', 'order_year', 'Type_DEBIT', 'Type_PAYMENT', 'Customer Segment_Corporate', 'Market_LATAM', 'Shipping Mode_First Class', 'Shipping Mode_Same Day', 'Shipping Mode_Second Class', 'Order Status_PENDING_PAYMENT'] \n",
      "\n",
      "\tFor concept 5 we are selecting the following features [0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 1 1 1 0 0 0 0 0 0 0\n",
      " 0]\n",
      "\t ['Customer Zipcode', 'Store Longitude', 'Customer Segment_Consumer', 'Market_Europe', 'Shipping Mode_First Class', 'Shipping Mode_Same Day', 'Shipping Mode_Second Class'] \n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "For comparison, the ground truth concept masks are\n",
      "\tFor GROUND-TRUTH concept 0  the following features are relevant [1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 0 0 0 0 0 0\n",
      " 0]\n",
      "\tFor GROUND-TRUTH concept 1  the following features are relevant [0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0]\n",
      "\tFor GROUND-TRUTH concept 2  the following features are relevant [0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0]\n",
      "\tFor GROUND-TRUTH concept 3  the following features are relevant [0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0]\n",
      "\tFor GROUND-TRUTH concept 4  the following features are relevant [0 0 0 0 0 0 1 1 1 1 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1\n",
      " 1]\n",
      "\tFor GROUND-TRUTH concept 5  the following features are relevant [0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0]\n"
     ]
    }
   ],
   "source": [
    "# The masks are stored as logits, so we need to turn them to probabilities using\n",
    "# a sigmoid\n",
    "masks = tf.sigmoid(tabcbm_supervised.feature_probabilities).numpy()\n",
    "\n",
    "print('Features that correspond to the defined concepts:\\n')\n",
    "for concept, features in extended_concepts.items():\n",
    "    print(f'{concept}: {features}' )\n",
    "\n",
    "print(\"\\nThresholded concept masks learnt by TabCBM:\")\n",
    "for i, mask in enumerate((masks>0.0005).astype(np.int32)):\n",
    "    print(\"\\tFor concept\", i, \"we are selecting the following features\", mask)\n",
    "\n",
    "    print(\"\\t\", [feature for feature, flag in zip(x_train_std.columns, mask) if flag == 1], \"\\n\" )\n",
    "\n",
    "print(\"-\" * 80)\n",
    "print(\"-\" * 80)\n",
    "\n",
    "print(\"For comparison, the ground truth concept masks are\")\n",
    "for i in range(n_concepts):\n",
    "    print(\"\\tFor GROUND-TRUTH concept\", i, \" the following features are relevant\", concepts_masks.iloc[i, :].values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Days for shipment (scheduled)</th>\n",
       "      <th>Category Name</th>\n",
       "      <th>Customer Zipcode</th>\n",
       "      <th>Department Name</th>\n",
       "      <th>Store Latitude</th>\n",
       "      <th>Store Longitude</th>\n",
       "      <th>Sales</th>\n",
       "      <th>Order Id</th>\n",
       "      <th>Order Item Discount</th>\n",
       "      <th>Order Profit Per Order</th>\n",
       "      <th>...</th>\n",
       "      <th>Shipping Mode_Same Day</th>\n",
       "      <th>Shipping Mode_Second Class</th>\n",
       "      <th>Shipping Mode_Standard Class</th>\n",
       "      <th>Order Status_CLOSED</th>\n",
       "      <th>Order Status_COMPLETE</th>\n",
       "      <th>Order Status_ON_HOLD</th>\n",
       "      <th>Order Status_PAYMENT_REVIEW</th>\n",
       "      <th>Order Status_PENDING</th>\n",
       "      <th>Order Status_PENDING_PAYMENT</th>\n",
       "      <th>Order Status_PROCESSING</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Days for shipment (scheduled)  Category Name  Customer Zipcode  \\\n",
       "0                              1              0                 0   \n",
       "1                              1              0                 0   \n",
       "2                              1              0                 0   \n",
       "3                              0              0                 1   \n",
       "4                              0              0                 0   \n",
       "5                              0              0                 1   \n",
       "\n",
       "   Department Name  Store Latitude  Store Longitude  Sales  Order Id  \\\n",
       "0                0               0                0      0         0   \n",
       "1                0               0                0      0         0   \n",
       "2                0               0                0      0         0   \n",
       "3                0               0                1      0         0   \n",
       "4                0               0                0      0         1   \n",
       "5                0               0                1      0         0   \n",
       "\n",
       "   Order Item Discount  Order Profit Per Order  ...  Shipping Mode_Same Day  \\\n",
       "0                    0                       0  ...                       1   \n",
       "1                    0                       0  ...                       1   \n",
       "2                    0                       0  ...                       1   \n",
       "3                    0                       0  ...                       1   \n",
       "4                    0                       0  ...                       1   \n",
       "5                    0                       0  ...                       1   \n",
       "\n",
       "   Shipping Mode_Second Class  Shipping Mode_Standard Class  \\\n",
       "0                           1                             1   \n",
       "1                           1                             1   \n",
       "2                           1                             1   \n",
       "3                           1                             0   \n",
       "4                           1                             0   \n",
       "5                           1                             0   \n",
       "\n",
       "   Order Status_CLOSED  Order Status_COMPLETE  Order Status_ON_HOLD  \\\n",
       "0                    0                      1                     0   \n",
       "1                    0                      0                     0   \n",
       "2                    0                      1                     0   \n",
       "3                    0                      0                     0   \n",
       "4                    0                      0                     0   \n",
       "5                    0                      0                     0   \n",
       "\n",
       "   Order Status_PAYMENT_REVIEW  Order Status_PENDING  \\\n",
       "0                            0                     0   \n",
       "1                            0                     0   \n",
       "2                            0                     0   \n",
       "3                            0                     0   \n",
       "4                            0                     0   \n",
       "5                            0                     0   \n",
       "\n",
       "   Order Status_PENDING_PAYMENT  Order Status_PROCESSING  \n",
       "0                             0                        0  \n",
       "1                             0                        0  \n",
       "2                             0                        0  \n",
       "3                             0                        0  \n",
       "4                             1                        0  \n",
       "5                             0                        0  \n",
       "\n",
       "[6 rows x 38 columns]"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trsh_masks = pd.DataFrame((masks>0.0005).astype(np.int32), columns=x_test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "def color_true_red(val, color):\n",
    "    return 'background-color: %s' % color if val == 1 else ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define colors for each group\n",
    "color_map = {\n",
    "    'Shipment': 'lightblue;',\n",
    "    'Customer': 'lightgreen;',\n",
    "    'Department': 'lightcoral;',\n",
    "    'Store': 'lightgoldenrodyellow;',\n",
    "    'Order': 'lightpink;',\n",
    "    'ProductCategory': 'lightcyan;'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [],
   "source": [
    "learnt_concept_masks = pd.DataFrame(columns=[f for c, fs in extended_concepts.items() for f in fs])\n",
    "for column in learnt_concept_masks.columns:\n",
    "    learnt_concept_masks[column] = trsh_masks[column]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_c0e1d th {\n",
       "  width: 10px;\n",
       "}\n",
       "#T_c0e1d th.col_heading {\n",
       "  writing-mode: vertical-rl;\n",
       "  transform: rotateZ(180deg);\n",
       "  height: 200px;\n",
       "  vertical-align: bottom;\n",
       "  width: 120px;\n",
       "}\n",
       "#T_c0e1d  {\n",
       "  border: 1px solid;\n",
       "}\n",
       "#T_c0e1d tbody td {\n",
       "  border: 1px solid;\n",
       "}\n",
       "#T_c0e1d th {\n",
       "  border: 1px solid;\n",
       "}\n",
       "#T_c0e1d_row0_col3, #T_c0e1d_row0_col4, #T_c0e1d_row0_col5, #T_c0e1d_row0_col6, #T_c0e1d_row0_col7, #T_c0e1d_row0_col8, #T_c0e1d_row1_col4, #T_c0e1d_row1_col5, #T_c0e1d_row1_col6, #T_c0e1d_row1_col7, #T_c0e1d_row1_col8, #T_c0e1d_row2_col3, #T_c0e1d_row2_col4, #T_c0e1d_row2_col5, #T_c0e1d_row2_col6, #T_c0e1d_row2_col7, #T_c0e1d_row2_col8, #T_c0e1d_row3_col5, #T_c0e1d_row3_col6, #T_c0e1d_row3_col7, #T_c0e1d_row4_col1, #T_c0e1d_row4_col2, #T_c0e1d_row4_col5, #T_c0e1d_row4_col6, #T_c0e1d_row4_col7, #T_c0e1d_row5_col5, #T_c0e1d_row5_col6, #T_c0e1d_row5_col7 {\n",
       "  background-color: lightblue;\n",
       "}\n",
       "#T_c0e1d_row0_col24, #T_c0e1d_row2_col24, #T_c0e1d_row4_col21, #T_c0e1d_row4_col28, #T_c0e1d_row4_col32 {\n",
       "  background-color: lightpink;\n",
       "}\n",
       "#T_c0e1d_row3_col9, #T_c0e1d_row3_col10, #T_c0e1d_row4_col11, #T_c0e1d_row5_col9, #T_c0e1d_row5_col10 {\n",
       "  background-color: lightgreen;\n",
       "}\n",
       "#T_c0e1d_row3_col15, #T_c0e1d_row4_col16, #T_c0e1d_row5_col15 {\n",
       "  background-color: lightcoral;\n",
       "}\n",
       "#T_c0e1d_row3_col20, #T_c0e1d_row5_col20 {\n",
       "  background-color: lightgoldenrodyellow;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_c0e1d\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_c0e1d_level0_col0\" class=\"col_heading level0 col0\" >Type_CASH</th>\n",
       "      <th id=\"T_c0e1d_level0_col1\" class=\"col_heading level0 col1\" >Type_DEBIT</th>\n",
       "      <th id=\"T_c0e1d_level0_col2\" class=\"col_heading level0 col2\" >Type_PAYMENT</th>\n",
       "      <th id=\"T_c0e1d_level0_col3\" class=\"col_heading level0 col3\" >Type_TRANSFER</th>\n",
       "      <th id=\"T_c0e1d_level0_col4\" class=\"col_heading level0 col4\" >Days for shipment (scheduled)</th>\n",
       "      <th id=\"T_c0e1d_level0_col5\" class=\"col_heading level0 col5\" >Shipping Mode_First Class</th>\n",
       "      <th id=\"T_c0e1d_level0_col6\" class=\"col_heading level0 col6\" >Shipping Mode_Same Day</th>\n",
       "      <th id=\"T_c0e1d_level0_col7\" class=\"col_heading level0 col7\" >Shipping Mode_Second Class</th>\n",
       "      <th id=\"T_c0e1d_level0_col8\" class=\"col_heading level0 col8\" >Shipping Mode_Standard Class</th>\n",
       "      <th id=\"T_c0e1d_level0_col9\" class=\"col_heading level0 col9\" >Customer Zipcode</th>\n",
       "      <th id=\"T_c0e1d_level0_col10\" class=\"col_heading level0 col10\" >Customer Segment_Consumer</th>\n",
       "      <th id=\"T_c0e1d_level0_col11\" class=\"col_heading level0 col11\" >Customer Segment_Corporate</th>\n",
       "      <th id=\"T_c0e1d_level0_col12\" class=\"col_heading level0 col12\" >Customer Segment_Home Office</th>\n",
       "      <th id=\"T_c0e1d_level0_col13\" class=\"col_heading level0 col13\" >Department Name</th>\n",
       "      <th id=\"T_c0e1d_level0_col14\" class=\"col_heading level0 col14\" >Market_Africa</th>\n",
       "      <th id=\"T_c0e1d_level0_col15\" class=\"col_heading level0 col15\" >Market_Europe</th>\n",
       "      <th id=\"T_c0e1d_level0_col16\" class=\"col_heading level0 col16\" >Market_LATAM</th>\n",
       "      <th id=\"T_c0e1d_level0_col17\" class=\"col_heading level0 col17\" >Market_Pacific Asia</th>\n",
       "      <th id=\"T_c0e1d_level0_col18\" class=\"col_heading level0 col18\" >Market_USCA</th>\n",
       "      <th id=\"T_c0e1d_level0_col19\" class=\"col_heading level0 col19\" >Store Latitude</th>\n",
       "      <th id=\"T_c0e1d_level0_col20\" class=\"col_heading level0 col20\" >Store Longitude</th>\n",
       "      <th id=\"T_c0e1d_level0_col21\" class=\"col_heading level0 col21\" >Order Id</th>\n",
       "      <th id=\"T_c0e1d_level0_col22\" class=\"col_heading level0 col22\" >Order Profit Per Order</th>\n",
       "      <th id=\"T_c0e1d_level0_col23\" class=\"col_heading level0 col23\" >Order Status_CLOSED</th>\n",
       "      <th id=\"T_c0e1d_level0_col24\" class=\"col_heading level0 col24\" >Order Status_COMPLETE</th>\n",
       "      <th id=\"T_c0e1d_level0_col25\" class=\"col_heading level0 col25\" >Order Status_ON_HOLD</th>\n",
       "      <th id=\"T_c0e1d_level0_col26\" class=\"col_heading level0 col26\" >Order Status_PAYMENT_REVIEW</th>\n",
       "      <th id=\"T_c0e1d_level0_col27\" class=\"col_heading level0 col27\" >Order Status_PENDING</th>\n",
       "      <th id=\"T_c0e1d_level0_col28\" class=\"col_heading level0 col28\" >Order Status_PENDING_PAYMENT</th>\n",
       "      <th id=\"T_c0e1d_level0_col29\" class=\"col_heading level0 col29\" >Order Status_PROCESSING</th>\n",
       "      <th id=\"T_c0e1d_level0_col30\" class=\"col_heading level0 col30\" >Sales</th>\n",
       "      <th id=\"T_c0e1d_level0_col31\" class=\"col_heading level0 col31\" >Order Item Discount</th>\n",
       "      <th id=\"T_c0e1d_level0_col32\" class=\"col_heading level0 col32\" >order_year</th>\n",
       "      <th id=\"T_c0e1d_level0_col33\" class=\"col_heading level0 col33\" >order_month</th>\n",
       "      <th id=\"T_c0e1d_level0_col34\" class=\"col_heading level0 col34\" >order_day</th>\n",
       "      <th id=\"T_c0e1d_level0_col35\" class=\"col_heading level0 col35\" >Category Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_c0e1d_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_c0e1d_row0_col0\" class=\"data row0 col0\" >0</td>\n",
       "      <td id=\"T_c0e1d_row0_col1\" class=\"data row0 col1\" >0</td>\n",
       "      <td id=\"T_c0e1d_row0_col2\" class=\"data row0 col2\" >0</td>\n",
       "      <td id=\"T_c0e1d_row0_col3\" class=\"data row0 col3\" >1</td>\n",
       "      <td id=\"T_c0e1d_row0_col4\" class=\"data row0 col4\" >1</td>\n",
       "      <td id=\"T_c0e1d_row0_col5\" class=\"data row0 col5\" >1</td>\n",
       "      <td id=\"T_c0e1d_row0_col6\" class=\"data row0 col6\" >1</td>\n",
       "      <td id=\"T_c0e1d_row0_col7\" class=\"data row0 col7\" >1</td>\n",
       "      <td id=\"T_c0e1d_row0_col8\" class=\"data row0 col8\" >1</td>\n",
       "      <td id=\"T_c0e1d_row0_col9\" class=\"data row0 col9\" >0</td>\n",
       "      <td id=\"T_c0e1d_row0_col10\" class=\"data row0 col10\" >0</td>\n",
       "      <td id=\"T_c0e1d_row0_col11\" class=\"data row0 col11\" >0</td>\n",
       "      <td id=\"T_c0e1d_row0_col12\" class=\"data row0 col12\" >0</td>\n",
       "      <td id=\"T_c0e1d_row0_col13\" class=\"data row0 col13\" >0</td>\n",
       "      <td id=\"T_c0e1d_row0_col14\" class=\"data row0 col14\" >0</td>\n",
       "      <td id=\"T_c0e1d_row0_col15\" class=\"data row0 col15\" >0</td>\n",
       "      <td id=\"T_c0e1d_row0_col16\" class=\"data row0 col16\" >0</td>\n",
       "      <td id=\"T_c0e1d_row0_col17\" class=\"data row0 col17\" >0</td>\n",
       "      <td id=\"T_c0e1d_row0_col18\" class=\"data row0 col18\" >0</td>\n",
       "      <td id=\"T_c0e1d_row0_col19\" class=\"data row0 col19\" >0</td>\n",
       "      <td id=\"T_c0e1d_row0_col20\" class=\"data row0 col20\" >0</td>\n",
       "      <td id=\"T_c0e1d_row0_col21\" class=\"data row0 col21\" >0</td>\n",
       "      <td id=\"T_c0e1d_row0_col22\" class=\"data row0 col22\" >0</td>\n",
       "      <td id=\"T_c0e1d_row0_col23\" class=\"data row0 col23\" >0</td>\n",
       "      <td id=\"T_c0e1d_row0_col24\" class=\"data row0 col24\" >1</td>\n",
       "      <td id=\"T_c0e1d_row0_col25\" class=\"data row0 col25\" >0</td>\n",
       "      <td id=\"T_c0e1d_row0_col26\" class=\"data row0 col26\" >0</td>\n",
       "      <td id=\"T_c0e1d_row0_col27\" class=\"data row0 col27\" >0</td>\n",
       "      <td id=\"T_c0e1d_row0_col28\" class=\"data row0 col28\" >0</td>\n",
       "      <td id=\"T_c0e1d_row0_col29\" class=\"data row0 col29\" >0</td>\n",
       "      <td id=\"T_c0e1d_row0_col30\" class=\"data row0 col30\" >0</td>\n",
       "      <td id=\"T_c0e1d_row0_col31\" class=\"data row0 col31\" >0</td>\n",
       "      <td id=\"T_c0e1d_row0_col32\" class=\"data row0 col32\" >0</td>\n",
       "      <td id=\"T_c0e1d_row0_col33\" class=\"data row0 col33\" >0</td>\n",
       "      <td id=\"T_c0e1d_row0_col34\" class=\"data row0 col34\" >0</td>\n",
       "      <td id=\"T_c0e1d_row0_col35\" class=\"data row0 col35\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c0e1d_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_c0e1d_row1_col0\" class=\"data row1 col0\" >0</td>\n",
       "      <td id=\"T_c0e1d_row1_col1\" class=\"data row1 col1\" >0</td>\n",
       "      <td id=\"T_c0e1d_row1_col2\" class=\"data row1 col2\" >0</td>\n",
       "      <td id=\"T_c0e1d_row1_col3\" class=\"data row1 col3\" >0</td>\n",
       "      <td id=\"T_c0e1d_row1_col4\" class=\"data row1 col4\" >1</td>\n",
       "      <td id=\"T_c0e1d_row1_col5\" class=\"data row1 col5\" >1</td>\n",
       "      <td id=\"T_c0e1d_row1_col6\" class=\"data row1 col6\" >1</td>\n",
       "      <td id=\"T_c0e1d_row1_col7\" class=\"data row1 col7\" >1</td>\n",
       "      <td id=\"T_c0e1d_row1_col8\" class=\"data row1 col8\" >1</td>\n",
       "      <td id=\"T_c0e1d_row1_col9\" class=\"data row1 col9\" >0</td>\n",
       "      <td id=\"T_c0e1d_row1_col10\" class=\"data row1 col10\" >0</td>\n",
       "      <td id=\"T_c0e1d_row1_col11\" class=\"data row1 col11\" >0</td>\n",
       "      <td id=\"T_c0e1d_row1_col12\" class=\"data row1 col12\" >0</td>\n",
       "      <td id=\"T_c0e1d_row1_col13\" class=\"data row1 col13\" >0</td>\n",
       "      <td id=\"T_c0e1d_row1_col14\" class=\"data row1 col14\" >0</td>\n",
       "      <td id=\"T_c0e1d_row1_col15\" class=\"data row1 col15\" >0</td>\n",
       "      <td id=\"T_c0e1d_row1_col16\" class=\"data row1 col16\" >0</td>\n",
       "      <td id=\"T_c0e1d_row1_col17\" class=\"data row1 col17\" >0</td>\n",
       "      <td id=\"T_c0e1d_row1_col18\" class=\"data row1 col18\" >0</td>\n",
       "      <td id=\"T_c0e1d_row1_col19\" class=\"data row1 col19\" >0</td>\n",
       "      <td id=\"T_c0e1d_row1_col20\" class=\"data row1 col20\" >0</td>\n",
       "      <td id=\"T_c0e1d_row1_col21\" class=\"data row1 col21\" >0</td>\n",
       "      <td id=\"T_c0e1d_row1_col22\" class=\"data row1 col22\" >0</td>\n",
       "      <td id=\"T_c0e1d_row1_col23\" class=\"data row1 col23\" >0</td>\n",
       "      <td id=\"T_c0e1d_row1_col24\" class=\"data row1 col24\" >0</td>\n",
       "      <td id=\"T_c0e1d_row1_col25\" class=\"data row1 col25\" >0</td>\n",
       "      <td id=\"T_c0e1d_row1_col26\" class=\"data row1 col26\" >0</td>\n",
       "      <td id=\"T_c0e1d_row1_col27\" class=\"data row1 col27\" >0</td>\n",
       "      <td id=\"T_c0e1d_row1_col28\" class=\"data row1 col28\" >0</td>\n",
       "      <td id=\"T_c0e1d_row1_col29\" class=\"data row1 col29\" >0</td>\n",
       "      <td id=\"T_c0e1d_row1_col30\" class=\"data row1 col30\" >0</td>\n",
       "      <td id=\"T_c0e1d_row1_col31\" class=\"data row1 col31\" >0</td>\n",
       "      <td id=\"T_c0e1d_row1_col32\" class=\"data row1 col32\" >0</td>\n",
       "      <td id=\"T_c0e1d_row1_col33\" class=\"data row1 col33\" >0</td>\n",
       "      <td id=\"T_c0e1d_row1_col34\" class=\"data row1 col34\" >0</td>\n",
       "      <td id=\"T_c0e1d_row1_col35\" class=\"data row1 col35\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c0e1d_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_c0e1d_row2_col0\" class=\"data row2 col0\" >0</td>\n",
       "      <td id=\"T_c0e1d_row2_col1\" class=\"data row2 col1\" >0</td>\n",
       "      <td id=\"T_c0e1d_row2_col2\" class=\"data row2 col2\" >0</td>\n",
       "      <td id=\"T_c0e1d_row2_col3\" class=\"data row2 col3\" >1</td>\n",
       "      <td id=\"T_c0e1d_row2_col4\" class=\"data row2 col4\" >1</td>\n",
       "      <td id=\"T_c0e1d_row2_col5\" class=\"data row2 col5\" >1</td>\n",
       "      <td id=\"T_c0e1d_row2_col6\" class=\"data row2 col6\" >1</td>\n",
       "      <td id=\"T_c0e1d_row2_col7\" class=\"data row2 col7\" >1</td>\n",
       "      <td id=\"T_c0e1d_row2_col8\" class=\"data row2 col8\" >1</td>\n",
       "      <td id=\"T_c0e1d_row2_col9\" class=\"data row2 col9\" >0</td>\n",
       "      <td id=\"T_c0e1d_row2_col10\" class=\"data row2 col10\" >0</td>\n",
       "      <td id=\"T_c0e1d_row2_col11\" class=\"data row2 col11\" >0</td>\n",
       "      <td id=\"T_c0e1d_row2_col12\" class=\"data row2 col12\" >0</td>\n",
       "      <td id=\"T_c0e1d_row2_col13\" class=\"data row2 col13\" >0</td>\n",
       "      <td id=\"T_c0e1d_row2_col14\" class=\"data row2 col14\" >0</td>\n",
       "      <td id=\"T_c0e1d_row2_col15\" class=\"data row2 col15\" >0</td>\n",
       "      <td id=\"T_c0e1d_row2_col16\" class=\"data row2 col16\" >0</td>\n",
       "      <td id=\"T_c0e1d_row2_col17\" class=\"data row2 col17\" >0</td>\n",
       "      <td id=\"T_c0e1d_row2_col18\" class=\"data row2 col18\" >0</td>\n",
       "      <td id=\"T_c0e1d_row2_col19\" class=\"data row2 col19\" >0</td>\n",
       "      <td id=\"T_c0e1d_row2_col20\" class=\"data row2 col20\" >0</td>\n",
       "      <td id=\"T_c0e1d_row2_col21\" class=\"data row2 col21\" >0</td>\n",
       "      <td id=\"T_c0e1d_row2_col22\" class=\"data row2 col22\" >0</td>\n",
       "      <td id=\"T_c0e1d_row2_col23\" class=\"data row2 col23\" >0</td>\n",
       "      <td id=\"T_c0e1d_row2_col24\" class=\"data row2 col24\" >1</td>\n",
       "      <td id=\"T_c0e1d_row2_col25\" class=\"data row2 col25\" >0</td>\n",
       "      <td id=\"T_c0e1d_row2_col26\" class=\"data row2 col26\" >0</td>\n",
       "      <td id=\"T_c0e1d_row2_col27\" class=\"data row2 col27\" >0</td>\n",
       "      <td id=\"T_c0e1d_row2_col28\" class=\"data row2 col28\" >0</td>\n",
       "      <td id=\"T_c0e1d_row2_col29\" class=\"data row2 col29\" >0</td>\n",
       "      <td id=\"T_c0e1d_row2_col30\" class=\"data row2 col30\" >0</td>\n",
       "      <td id=\"T_c0e1d_row2_col31\" class=\"data row2 col31\" >0</td>\n",
       "      <td id=\"T_c0e1d_row2_col32\" class=\"data row2 col32\" >0</td>\n",
       "      <td id=\"T_c0e1d_row2_col33\" class=\"data row2 col33\" >0</td>\n",
       "      <td id=\"T_c0e1d_row2_col34\" class=\"data row2 col34\" >0</td>\n",
       "      <td id=\"T_c0e1d_row2_col35\" class=\"data row2 col35\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c0e1d_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_c0e1d_row3_col0\" class=\"data row3 col0\" >0</td>\n",
       "      <td id=\"T_c0e1d_row3_col1\" class=\"data row3 col1\" >0</td>\n",
       "      <td id=\"T_c0e1d_row3_col2\" class=\"data row3 col2\" >0</td>\n",
       "      <td id=\"T_c0e1d_row3_col3\" class=\"data row3 col3\" >0</td>\n",
       "      <td id=\"T_c0e1d_row3_col4\" class=\"data row3 col4\" >0</td>\n",
       "      <td id=\"T_c0e1d_row3_col5\" class=\"data row3 col5\" >1</td>\n",
       "      <td id=\"T_c0e1d_row3_col6\" class=\"data row3 col6\" >1</td>\n",
       "      <td id=\"T_c0e1d_row3_col7\" class=\"data row3 col7\" >1</td>\n",
       "      <td id=\"T_c0e1d_row3_col8\" class=\"data row3 col8\" >0</td>\n",
       "      <td id=\"T_c0e1d_row3_col9\" class=\"data row3 col9\" >1</td>\n",
       "      <td id=\"T_c0e1d_row3_col10\" class=\"data row3 col10\" >1</td>\n",
       "      <td id=\"T_c0e1d_row3_col11\" class=\"data row3 col11\" >0</td>\n",
       "      <td id=\"T_c0e1d_row3_col12\" class=\"data row3 col12\" >0</td>\n",
       "      <td id=\"T_c0e1d_row3_col13\" class=\"data row3 col13\" >0</td>\n",
       "      <td id=\"T_c0e1d_row3_col14\" class=\"data row3 col14\" >0</td>\n",
       "      <td id=\"T_c0e1d_row3_col15\" class=\"data row3 col15\" >1</td>\n",
       "      <td id=\"T_c0e1d_row3_col16\" class=\"data row3 col16\" >0</td>\n",
       "      <td id=\"T_c0e1d_row3_col17\" class=\"data row3 col17\" >0</td>\n",
       "      <td id=\"T_c0e1d_row3_col18\" class=\"data row3 col18\" >0</td>\n",
       "      <td id=\"T_c0e1d_row3_col19\" class=\"data row3 col19\" >0</td>\n",
       "      <td id=\"T_c0e1d_row3_col20\" class=\"data row3 col20\" >1</td>\n",
       "      <td id=\"T_c0e1d_row3_col21\" class=\"data row3 col21\" >0</td>\n",
       "      <td id=\"T_c0e1d_row3_col22\" class=\"data row3 col22\" >0</td>\n",
       "      <td id=\"T_c0e1d_row3_col23\" class=\"data row3 col23\" >0</td>\n",
       "      <td id=\"T_c0e1d_row3_col24\" class=\"data row3 col24\" >0</td>\n",
       "      <td id=\"T_c0e1d_row3_col25\" class=\"data row3 col25\" >0</td>\n",
       "      <td id=\"T_c0e1d_row3_col26\" class=\"data row3 col26\" >0</td>\n",
       "      <td id=\"T_c0e1d_row3_col27\" class=\"data row3 col27\" >0</td>\n",
       "      <td id=\"T_c0e1d_row3_col28\" class=\"data row3 col28\" >0</td>\n",
       "      <td id=\"T_c0e1d_row3_col29\" class=\"data row3 col29\" >0</td>\n",
       "      <td id=\"T_c0e1d_row3_col30\" class=\"data row3 col30\" >0</td>\n",
       "      <td id=\"T_c0e1d_row3_col31\" class=\"data row3 col31\" >0</td>\n",
       "      <td id=\"T_c0e1d_row3_col32\" class=\"data row3 col32\" >0</td>\n",
       "      <td id=\"T_c0e1d_row3_col33\" class=\"data row3 col33\" >0</td>\n",
       "      <td id=\"T_c0e1d_row3_col34\" class=\"data row3 col34\" >0</td>\n",
       "      <td id=\"T_c0e1d_row3_col35\" class=\"data row3 col35\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c0e1d_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_c0e1d_row4_col0\" class=\"data row4 col0\" >0</td>\n",
       "      <td id=\"T_c0e1d_row4_col1\" class=\"data row4 col1\" >1</td>\n",
       "      <td id=\"T_c0e1d_row4_col2\" class=\"data row4 col2\" >1</td>\n",
       "      <td id=\"T_c0e1d_row4_col3\" class=\"data row4 col3\" >0</td>\n",
       "      <td id=\"T_c0e1d_row4_col4\" class=\"data row4 col4\" >0</td>\n",
       "      <td id=\"T_c0e1d_row4_col5\" class=\"data row4 col5\" >1</td>\n",
       "      <td id=\"T_c0e1d_row4_col6\" class=\"data row4 col6\" >1</td>\n",
       "      <td id=\"T_c0e1d_row4_col7\" class=\"data row4 col7\" >1</td>\n",
       "      <td id=\"T_c0e1d_row4_col8\" class=\"data row4 col8\" >0</td>\n",
       "      <td id=\"T_c0e1d_row4_col9\" class=\"data row4 col9\" >0</td>\n",
       "      <td id=\"T_c0e1d_row4_col10\" class=\"data row4 col10\" >0</td>\n",
       "      <td id=\"T_c0e1d_row4_col11\" class=\"data row4 col11\" >1</td>\n",
       "      <td id=\"T_c0e1d_row4_col12\" class=\"data row4 col12\" >0</td>\n",
       "      <td id=\"T_c0e1d_row4_col13\" class=\"data row4 col13\" >0</td>\n",
       "      <td id=\"T_c0e1d_row4_col14\" class=\"data row4 col14\" >0</td>\n",
       "      <td id=\"T_c0e1d_row4_col15\" class=\"data row4 col15\" >0</td>\n",
       "      <td id=\"T_c0e1d_row4_col16\" class=\"data row4 col16\" >1</td>\n",
       "      <td id=\"T_c0e1d_row4_col17\" class=\"data row4 col17\" >0</td>\n",
       "      <td id=\"T_c0e1d_row4_col18\" class=\"data row4 col18\" >0</td>\n",
       "      <td id=\"T_c0e1d_row4_col19\" class=\"data row4 col19\" >0</td>\n",
       "      <td id=\"T_c0e1d_row4_col20\" class=\"data row4 col20\" >0</td>\n",
       "      <td id=\"T_c0e1d_row4_col21\" class=\"data row4 col21\" >1</td>\n",
       "      <td id=\"T_c0e1d_row4_col22\" class=\"data row4 col22\" >0</td>\n",
       "      <td id=\"T_c0e1d_row4_col23\" class=\"data row4 col23\" >0</td>\n",
       "      <td id=\"T_c0e1d_row4_col24\" class=\"data row4 col24\" >0</td>\n",
       "      <td id=\"T_c0e1d_row4_col25\" class=\"data row4 col25\" >0</td>\n",
       "      <td id=\"T_c0e1d_row4_col26\" class=\"data row4 col26\" >0</td>\n",
       "      <td id=\"T_c0e1d_row4_col27\" class=\"data row4 col27\" >0</td>\n",
       "      <td id=\"T_c0e1d_row4_col28\" class=\"data row4 col28\" >1</td>\n",
       "      <td id=\"T_c0e1d_row4_col29\" class=\"data row4 col29\" >0</td>\n",
       "      <td id=\"T_c0e1d_row4_col30\" class=\"data row4 col30\" >0</td>\n",
       "      <td id=\"T_c0e1d_row4_col31\" class=\"data row4 col31\" >0</td>\n",
       "      <td id=\"T_c0e1d_row4_col32\" class=\"data row4 col32\" >1</td>\n",
       "      <td id=\"T_c0e1d_row4_col33\" class=\"data row4 col33\" >0</td>\n",
       "      <td id=\"T_c0e1d_row4_col34\" class=\"data row4 col34\" >0</td>\n",
       "      <td id=\"T_c0e1d_row4_col35\" class=\"data row4 col35\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c0e1d_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_c0e1d_row5_col0\" class=\"data row5 col0\" >0</td>\n",
       "      <td id=\"T_c0e1d_row5_col1\" class=\"data row5 col1\" >0</td>\n",
       "      <td id=\"T_c0e1d_row5_col2\" class=\"data row5 col2\" >0</td>\n",
       "      <td id=\"T_c0e1d_row5_col3\" class=\"data row5 col3\" >0</td>\n",
       "      <td id=\"T_c0e1d_row5_col4\" class=\"data row5 col4\" >0</td>\n",
       "      <td id=\"T_c0e1d_row5_col5\" class=\"data row5 col5\" >1</td>\n",
       "      <td id=\"T_c0e1d_row5_col6\" class=\"data row5 col6\" >1</td>\n",
       "      <td id=\"T_c0e1d_row5_col7\" class=\"data row5 col7\" >1</td>\n",
       "      <td id=\"T_c0e1d_row5_col8\" class=\"data row5 col8\" >0</td>\n",
       "      <td id=\"T_c0e1d_row5_col9\" class=\"data row5 col9\" >1</td>\n",
       "      <td id=\"T_c0e1d_row5_col10\" class=\"data row5 col10\" >1</td>\n",
       "      <td id=\"T_c0e1d_row5_col11\" class=\"data row5 col11\" >0</td>\n",
       "      <td id=\"T_c0e1d_row5_col12\" class=\"data row5 col12\" >0</td>\n",
       "      <td id=\"T_c0e1d_row5_col13\" class=\"data row5 col13\" >0</td>\n",
       "      <td id=\"T_c0e1d_row5_col14\" class=\"data row5 col14\" >0</td>\n",
       "      <td id=\"T_c0e1d_row5_col15\" class=\"data row5 col15\" >1</td>\n",
       "      <td id=\"T_c0e1d_row5_col16\" class=\"data row5 col16\" >0</td>\n",
       "      <td id=\"T_c0e1d_row5_col17\" class=\"data row5 col17\" >0</td>\n",
       "      <td id=\"T_c0e1d_row5_col18\" class=\"data row5 col18\" >0</td>\n",
       "      <td id=\"T_c0e1d_row5_col19\" class=\"data row5 col19\" >0</td>\n",
       "      <td id=\"T_c0e1d_row5_col20\" class=\"data row5 col20\" >1</td>\n",
       "      <td id=\"T_c0e1d_row5_col21\" class=\"data row5 col21\" >0</td>\n",
       "      <td id=\"T_c0e1d_row5_col22\" class=\"data row5 col22\" >0</td>\n",
       "      <td id=\"T_c0e1d_row5_col23\" class=\"data row5 col23\" >0</td>\n",
       "      <td id=\"T_c0e1d_row5_col24\" class=\"data row5 col24\" >0</td>\n",
       "      <td id=\"T_c0e1d_row5_col25\" class=\"data row5 col25\" >0</td>\n",
       "      <td id=\"T_c0e1d_row5_col26\" class=\"data row5 col26\" >0</td>\n",
       "      <td id=\"T_c0e1d_row5_col27\" class=\"data row5 col27\" >0</td>\n",
       "      <td id=\"T_c0e1d_row5_col28\" class=\"data row5 col28\" >0</td>\n",
       "      <td id=\"T_c0e1d_row5_col29\" class=\"data row5 col29\" >0</td>\n",
       "      <td id=\"T_c0e1d_row5_col30\" class=\"data row5 col30\" >0</td>\n",
       "      <td id=\"T_c0e1d_row5_col31\" class=\"data row5 col31\" >0</td>\n",
       "      <td id=\"T_c0e1d_row5_col32\" class=\"data row5 col32\" >0</td>\n",
       "      <td id=\"T_c0e1d_row5_col33\" class=\"data row5 col33\" >0</td>\n",
       "      <td id=\"T_c0e1d_row5_col34\" class=\"data row5 col34\" >0</td>\n",
       "      <td id=\"T_c0e1d_row5_col35\" class=\"data row5 col35\" >0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1b75305b350>"
      ]
     },
     "execution_count": 361,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#styled_trsh_masks = trsh_masks.copy(deep=True)\n",
    "style_obj = learnt_concept_masks.style\n",
    "for concept, features in extended_concepts.items():\n",
    "    style_obj = style_obj.map(color_true_red, subset=features, color=color_map[concept])\n",
    "\n",
    "header_style = [dict(selector=\"th\", props=[('width', '10px')]),\n",
    "                dict(selector=\"th.col_heading\",\n",
    "                     props=[(\"writing-mode\", \"vertical-rl\"),\n",
    "                            ('transform', 'rotateZ(180deg)'), \n",
    "                            ('height', '200px'),\n",
    "                            ('vertical-align', 'bottom'),\n",
    "                            (\"width\", '120px')]),\n",
    "                dict(selector=\"\", props=[(\"border\", \"1px solid\")]),\n",
    "                dict(selector=\"tbody td\", props=[(\"border\", \"1px solid\")]),\n",
    "                dict(selector=\"th\", props=[(\"border\", \"1px solid\")])\n",
    "]\n",
    "\n",
    "style_obj.set_table_styles(header_style)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the styled DataFrame\n",
    "html_styled_trsh_masks = style_obj.to_html()\n",
    "with open(\"thresholded_masks.html\", \"w\") as f:\n",
    "    f.write(html_styled_trsh_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [],
   "source": [
    "style_obj.to_excel('styled_thresholded_masks.xlsx', engine='openpyxl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
